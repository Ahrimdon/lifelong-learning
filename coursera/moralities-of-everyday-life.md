# Week 1

## Introduction to the Course

Kindiness: altruism or pro-social behavior. As when, with no obvious payoff, we're nice to another individual. Without prompting, a toddler opens a cabinet when the adult can't get it opened.

There's kindness, but there's also cruelty. There's evil. There's viciousness. Think of the woman who threw the cat in the garbage can. Strangers were mad at her. They weren't involved. They weren't harmed.

And I think this sort of incident tells us something interesting about morality. Which is that morality matters. When I see something evil being done, even if I'm not involved in it, there's often a punitive impulse. There's an impulse that. The perpetrator should be punished. Justice should be done. And the question of where that comes from, how the system evolved.

How on the one hand do we have a psychology built for empathy and compassion and kindness, as in that child helping the man. And in another way have a psychology built for justice, for punishment, as in the case of the attacks on this woman.

Where does this all come from? And those are questions that occupy us. We'll also be interested, and this is my third example, in human differences. Hundreds of years ago, in the state of Conneticut in which I'm lecturing, people owned slaves. That is people owned other people.

I would imagine very few of you think slavery is right. Very few of you think slavery is moral. But hundreds of years ago people did practice slavery. And many people thought it wasn't wrong. In fact, many people thought that slavery was a moral institution justified by the Bible, justified by history.

What can we say about the psychology of the people back then who thought so differently from how we think? And what can we say about the changes that brought us form then to now? What is the proper explanation for why our views about something like slavery Have changed so radically over history.

Now moral differences aren't just a matter of history. They're not just a matter of then versus now. They're also a matter of clashes between cultures.

One view of things, the view which I actually hold is that the, the, the mass murder of Americans was a horribly immoral act. And the punishment however to punishment or murder of Bin Laden was a just retribution.

But there are many people around the world who see things very differently. They might see that hack on America as a just, reasonable, moral act and the murder of Bin Laden as a cowardly retaliation. The people who orchestrated That hacks 9/11 were not by any standard insane. They were not by any normal standard psychopaths.

Rather, they were driven by a moral vision. Now, again, some moral vision eyes see as grossly mistaken but they see mind as grossly mistaken and at the very minimum then What we need to do as scientists interested in morality is come to grips with the fact that people have such different moral views.

And understand why we have these moral views, where they come from, and possibly how we can deal with these conflicts. Now these are all examples of moral differences between different societies separated by time. Or separated by space. But we could also ask about moral differences within a society.

So in the United States, there's huge differences in how people think about the morality of same sex relationships of gay couples. Again, the point of this course is not trying to commit you to, this view is right or that view or right.

That is just out of the bounds of what we'll be doing here. But we're very interested in, why do some people think this and why do some people think that.

I think this is a question of, both, great intellectual importance, and also great practical importance. And more generally I think, this course will, will talk about specific cases like that, but also deal with foundational issues, that, that I just find incredibly interesting.

So one such foundational issue, is attention between. Moral reasoning. Deliberative conscious thought, decision making thinking things through, the head, and your gut feelings. Your compassion, your emotion, your love, your disgust, your anger, your shame, the heart. And psychologists and philosophers along with theologians and legal scholars and many others Have long tried to address the question of the relative roles of reason and the emotion. In how we le, lead our moral lives and how we come to our moral ideas.

Even more generally than that, we will address the tension between what we call humanistic views. Our humanistic conception of humanity. Which deals with notions like free will. That sees people as, as agents that can make decisions. That can be blamed, that can be praised, that can be guilty. That, that, that, that can warrant punishment or warrant reward.

A view that might see us as almost as spiritual beings. Not reducible to the physical or, or mechanistic world. Beings with, be beings with souls. Creatures capable not only of wrongness, but also capable of sin. You have that and you have that humanistic view.

And then you have a scientific view. And a scientific view tries to explain our natures in terms of the language of neuroscience, the language of neurons and dendrites, and the limbic system, and the frontal lobe. The language of genes, talks about environmental cues, talks about the effects of parenting, the effects of, of, of one's physical, and social, and emotional environment.

And the question that will occupy us that has occupied me for as, as long as I could remember, is can we reconcile these two views. By our genes and by our environment. Can we say that, and also say that people make choices. And that people should be blamed for their choices or praised for their choices. That people are moral creatures more than anything else on this planet.

Can we reconcile the humanist perspective on us in a scientific perspective? And that's something that we'll be struggling with throughout this course.

So, why would you want to take this course? One reason is the topics are just fascinating. I, Again, I'm, I'm admittedly biased, but who isn't interested in the question of why do some people become violent psychopaths. Who isn't really interested in questions of how are liberals Different from conservatives. How are the fundamentalists different from atheists? How are they better people? Are they worse people? What's the evidence?

A second reason to take the course is that, as we talk about these issues of morality, we will be discussing, and reading, and learning about different domains of both the sciences and the humanities. So a lot of the basis for this work will come from psychology. And we will read and talk about social psychology, developmental psychology, clinical psychology, neuroscience as well as other domains.

The third reason to take the course, and I'm raising this maybe most tenatively. Is that it might make us better people. I am under no illusion that after having read about the studies of morality and read the developmental work and anthropology and neuroscience, that will then be particularly well equipped to say oh now I know that's right and that's wrong. I think understanding them more has nothing but positive benefits.

Why my politics is this and my religion is that And my belief about charity is this. Why I believe these things, I think that understanding where these beliefs and behaviors come from will actually help us in a better way improve on our moral lives.

## 1.1: What is Morality?

The first is there's no definition of morality that people agree on. So the philosopher Stephen Stich points out that philosophers have deep differences over what morality is.

There was a book published in 1970 called Definitions of Morality. And in that book. 13 of the best philosopherss in the world. Philosophers like Elizabeth Anscombe, Peter Strawson and Philippa Foot provided their definitions of what morality is. And Stich points out these definitions had very little in common. People had very different views. It doesn't get any different when you look at psychologists.

So the very prominent psychologist, Elliot Turiel, who's done significant work in the psychology of morality, defines morality in a pretty narrow way in terms of justice, rights, and harm. For him, something only counts as immoral if there's a victim, if someone suffers.

In contrast, Jonathan Haidt, whose work we're going to talk about throughout this course. Has a much broader definition of morality. For him, anything that suppresses self-interest and makes cooperation possible is part of morality.

So for Haidt, a religious ritual might be part of our moral psychology, part of our moral life. For Turiel it wouldn't be. So given the sort of disagreement, it would be arbitrary for me to pick out a single definition of morality and go with that.

Also, my view is that beginning with a definition is never a good idea when you're dealing with scientific questions.

Rather what you do is you begin with a rough idea of what you're talking about, and then you're understanding what counts as falling within that domain shifts as a result of your understanding.

I think if we ever get a definition of morality, it means we're kind of finished, the study of it. And we're nowhere near that point now. We're just beginning. Still, in order to study anything, you need a rough idea what you're studying and so I want to begin with, by talking about what counts as a moral violation. What counts as something wrong?

It's related to notions of reward and punishment. Good things are rewarded and bad things are punished and it's related to emotion such as guilt, shame anger and gratitude. Wrong behavior evokes certain emotional responses. Now, this is a simple example of moral violation. Obviously not the worst thing you could imagine, but a sort of simple and direct. But, there are other moral violations that don't quite fit this mould.

So for one thing, you don't have to, make physical contact to somebody, in order to do something wrong. Most of us would believe it's wrong to shout a racist insult at somebody, or threaten to kill them, or spread lies about them. You could harm people in ways that aren't physical.

You could be immoral by negligence. So, if after the filming of this lecture I get together with the gentlemen operating the cameras, we all get roaring drunk. And I get back into my car and start to drive home. Most people say I'm doing something wrong. Not because I have any ill feelings not because I've hurt anybody, but because I'm, I'm foolishly acting in a way which could harm people.

You could be immoral in some cases by not doing anything at all. So if I choose not to feed my dog, then my dog starves to death. That's awful. If I choose not to feed my child, my baby, that's even more awful. That's murder.

Because I have obligations to those individuals that require, that morally require, that I do things. Now there are some cases where What counts as immoral is different from what counts as illegal and these cases are particularly salient with regard to issues of when you should do something.

So I'm thinking particularly of an example. A few years ago, these two guys Jeremy Strohmeyer and David Cash Jr., they go into a casino in Nevada. And Jeremy Strohmeyer sees this little girl. Gets her to come with him into the women's bathroom, and molests and murders her. He is later caught, you know, charged, sentenced.

Plainly what he did was terrible. But I'm more interested here in what his friend did, which is nothing. His friend sort of said, half-heartedly, tried to get Strohmeyer to stop, got bored, and went for a walk. Now it turns out he didn't do anything legally wrong. At the time in Nevada it's not a crime to allow somebody else to do a crime. And in fact, so, so he wasn't charged with anything. And in fact he didn't really feel wrong about what he did. He was later interviewed on the radio. And, and when he was asked his feelings, he said he said this.

The simple fact remains I don't know this little girl. And then he, he said more generally, I don't know people in Panama or Africa who are killed every day, so I can't feel remorse for them. And he went on, why should I feel remorse for this girl? I didn't do anything wrong.

Other people disagreed. And although he was never charged with a crime because he didn't commit the crime, there were protests, there were, there were people. He was a student at University of California at Berkeley, and people protested, demanded that he get thrown out of school. For what he did. And even now, years later, if you look up his name online you'll see there are people stalking him. They don't know him. But they'll stalk him. They want to make sure that, that everybody knows what he did, and that he suffers for what he did.

And this is another, this is a way in which morality can have broad scope. Another sort of example. Is that not all moral violations involve victims. Or least they don't always involve victims in clear and obvious sense. I have here a list of some things. Most of which are illegal in the United States.

> Drug use, voluntary selling of bodily organs, prostitution, homosexuality, bestiality, incest between consenting adult siblings, cannibalism

Homosexuality used to be illegal in the United States. There were sodomy laws that were applied almost exclusively to homosexuals. Now, due to a Supreme Court decision, it's no longer illegal. The rest are still, in various forms, illegal, and they're illegal in other countries as well. 

Now your mileage may vary. Some people will look at this list and say, I don't see anything wrong with all of that. I mean, I don't want to indulge in any of this, but what consenting adults do is fine. It doesn't bother me. Others will see some of these as morally wrong.

And you might see some of these as morally wrong because you believe there really is a victim. You might think that although prostitution involves, on the face of it, consenting adults and so on, Still, the institution of prostitution is coercive and really does make people's lives worse. 

Or, you might think that these are wrong, not so much because they harm somebody but simply because they're wrong. Take consensual cannibalism. Somebody dies, and in their will they say, after I'm dead someone else could eat me. It's all consent, and so on. But some people say that's just not right. I don't care if nobody's harmed. We shouldn't be doing that, to one another.

And this is part of the scope of morality. You, you also get cases where, there isn't apparent harm, and it seems wrong, even when it doesn't rise to the level, of a crime. Suppose I get together with my friends, say fellow Yale professors. Suppose we are sitting in a club, we're sipping sherry, and we're all white males. And we start enga-, telling jokes, and we say, you know, sexist jokes and racist jokes, the most foul jokes you could imagine. But still, we're telling, we're telling the jokes and we leave and we're happier than when we came in.

And nobody hurts and nobody's feelings were hurt. But still, there is the intuition in at least some of us that, that was wrong. You know, you shouldn't be doing that sort of thing. So, the scope of morality is broad. I'm trying to sort of persuade you that what counts as right and wrong has, has broad scope.

Morality is everywhere. A lot of my examples involve sex, and clearly, many, there are certain acts of sex that most everybody find wrong. You, people find it wrong, the idea of sex with a young child. Certainly sex that involves coercion is wrong. People have different attitutes about promiscuity, virginity, heterosexuality, homosexuality bisexuality. Bestiality, masturbation, fetishes. And these differences are profound.

What counts as a, a moral violation for one person could be a point of pride for another. This guy walks into a church. And he goes to a confessional booth. And he immediately says, Father, I'm 70 years old. And I have sex. I have had sex with two 20 year olds. And the priest is kind of stunned. And says, how long has it been since your last confession? And the guy says, I've never been to confession before. I'm not Catholic. And the priest says, so why are you telling me this? And the guy says, I'm telling everybody.

What could be a point of pride to one could be a point of disgust to another. Food. Most people have some moral restrictions on what to eat. For some of us, these moral restrictions are grounded in religion. Other people have more restrictions on what they can eat because of concerns about the suffering of animals. Or worries about damage to the ecosystem.

The most obvious cases of morality, involve family and friends. So, we feel moral obligation towards our family and friends, we, we feel gratitude when people do right by us, betrayed if they don't. The most obvious example is the obligation that a mother or father has towards a child. But these obligations extend. They extend towards siblings. They extend towards people who aren't related but are married, are close friends and so on.

Morality applies to strangers as well. Many of us give to charity and many of us give to charity to help people we don't know and who will never help us back. Even if you don't give this to charity, you believe you have some moral obligations to strangers. You can't kill them, for instance. You can't make them suffer.

Politics is full of morality. Now, I don't want to, I don't want to overstate this. There are some political differences that people have that aren't moral. You may, you and I may share the same goal. We agree on the morality. Now we're sort of struggling with this, with the question of how to do it?

As I'm giving this lecture, the United States is currently in, the United States Congress is currently debating over whether to allow Obama to bomb Syria. Now, there's a lot of practical issues here, but a lot of those questions fundamentally moral? Is it right? To, to, to initiate bombing of another country, an act will for surely kill innocents?

Is it right to do nothing, and then let a dictator who commits acts of chemical warfare to go free, to go unpunished? And people have very different intuitions. And again, some of the intuitions are instrumental.

Instrumental meaning that we agree on the goals, we're just trying to figure how to satisfy them. But some of them are more moral. Honest to God disagreements over what the right thing is to do.

My final example of the scope and importance of morality comes from a lovely and quite weird study done in the 1930s by the American psychologist, Thorndike. Thorndike asked people different questions about different activities.

How much money would I have to pay you to do this activity? Now some, some of the activities. They were all unpleasant. But, they were different kinds of unpleasant. So, some were unpleasant just because they were painful, or degrading, or, or, or awful in some way.

How much would I have to pay you to eat a live earthworm, was one of his questions. Or here's another one. How much would I have to pay you to have one of your front teeth removed with a pair of pliers? No anesthesia. That's one of his questions. He also asks questions about moral violations. How much would he have to pay you to do something bad? And, and it's not physically painful, but they're bad. So, one of his answers was, one of his questions was, how much would I have to pay you to strangle a cat with your bare hands? Here are his answers for those two items.

I've taken his answers, he, he got answers, of course in the 1930s dollars. I've translated them, translated them into the money that you'd have to pay now. For the tooth, its an average of 74,000 dollars. For the cat, it's 164,000 dollars. Over twice as much. And that tells us something. That tells us about the pull that morality has. 

That, that it matters so much that we want to be good people. We don’t want to do this bad thing. That, that we would have to, we would rather have an experience of excruciating pain. So, that's morality as we see it.

> Adam Smith: in treating of the principles of morality, there are two questions to be considered. Wherein does virtue consist? What is the tone of temper and tenor of conduct which constitutes the excellent and praiseworthy character? The character which is the natural object of esteem, honor, and approbation.

He's asking a question. Which we would now says is a philosophical question. A normative question. How should we live? What is it to be a good person? What is it to be a virtuous person?

Or in other words, how and by what means does it come to pass that a mind prefers one tenor of conduct to another? Denominates the one right and the other wrong. Considers the one is the object of approbation on a reward and other of blame center and punishment.

But this is a different question. Now he's not asking what is the good. Now he's asking what's going on in our minds, and our brains. That causes us to say, that's good, and that's bad. That's the right way to live, and that's the wrong way to live.

And throughout this course we're going to deal with both questions. We're mostly interested in a psychological question. We're mostly interested in how people think about morality. What, what governs people's choices? What governs people's intuitions?

## 1.2: Philosophical Approaches

What is it to be good? What distinguishes good from, from evil? Right from wrong?

#### Consequentialism

- David Hume, John Stuart Mill, Jeremy Bentham.
- Results matter. Consequences matter. You should always act in a way that's going to promote the best consequences, that's going to make the world better. What it is to do good, is to make the world better. What it is to do bad, is to make the world worse.
- Pleasure and pain. Add everything up for one option, and you add everything up for your other options. And then you choose the action that's going to produce the greatest overall amount of good.
- Bentham thinks torture is justifiable if the tortured person can set of a bomb or something which will hurt more people.
- Homosexuality, they get pleasure anyway. And these are private acts.
- Nothing was said about God. It gives up what a lot of people think is central to morality.

#### Critics of C

- It often forces us to accept as moral, things that intuitively in our gut, just awful. If torturing a child makes other people happy, then it's okay.
- There is nothing about family and friendship. If your son needs an operation to save his life, it is better to give the money to poor people to save their lives.
- It may just miss the point of morality. Cs think rape is wrong because of the suffering of the victim. But they might think that if multiple people got happy, or the victim did not feel anything, that rape is okay. This misses the point about rape or murder or torture. The point is people have a right not to be harmed. There's a wrongness to assaulting somebody, that transcends the balance of pain and pleasure.

#### Deontology

- There has to be some moral rules. Even if an action causes more pain than pleasure. 
- Immanuel Kant tried to ground his approach to morality on pure reason. He argued to forget about gut feelings and emotion.
- Hypothetical imperative: Our desires. If you want water, drink it.
- Categorical imperative: Grounded on reason. Act as if you action would become a universal law.
- Universal law: So when you decide to do, to do this versus do that. You should ask yourself, if everybody did this versus that? How would the world be? Would it demolish our way of living?
- Ex: Lying. Cs say lie only dependin on the consequence. K says you should never lie, because if everyone lied it would suck. This means you won't lie to a murderer when he asks you where his victim is.
- D theory gives you clean answers. Torture becomes wrong, even if you are able to save 100 people. So D has some sort of better moral compass than C.

#### Critics of D

- It's crazy.
- Where do the rules come from? K says reason, and critics say it's not. It's grounded on prejudices and biases. K thought homosexuality and pornography was wrong, for instance.

## 1.3: Reason vs. Emotions

- Trolley problem. Most peopel think okay to switch, but not to push the man. This means we aren't Cs. 5 > 1 in both but we don't do the same thing in both.
- Doctrine of Double Effect: There's a distinction between doing something bad, like killing or harming somebody as an unintended consequence of causing greater good to happen, and that could be the right thing to do, versus doing something bad, like killing or harming somebody in order to bring about a greater good, and that you shouldn't do. The consequences are identical. But the difference is that in one case, the bad thing is a __regrettable byproduct__. In the bad case, it's an instrument through which you act. So, this often comes up, in case, cases of just war. Or, or, or in philosophical debates and political debates over, over what's permissible in war time.
- Ex: Bomb a munitions factory to defeat the enemy, end the war, but kill the innocent workers in the factory? DoDE says that they are collateral damage. But you should do it.
- This is why we think so differently about these two cases. In the switch case, one person dies but their death is an accident and their death does nothing. In the bridge case, the person's death is necessary.
- There has been a backlash in the last decade: We should not think of people as, as these philosophical creatures doing these abstract rules, rather moral, morality is driven to a large extent by gut feelings.
- In the same way that you just know if something is disgusting or beautiful, moral judgments are rapid intuitive decisions and involve the emotional-processing parts of the brain. 
- A lot of our morality is driven by our gut.
- The idea is that if we think reason is important, we are mistaking the tail for the dog. It's, it's the motion that counts. Haidt writes, moral judge, reasoning does
not cause moral judgment; rather moral reasoning is usually a post hoc construction generated after a judgment has been reached.
- David Hume talking about moral reasoning says, look, our moral decisions, our moral understanding is not driven by reason. Rather, he says, reason is, and ought only to be, the slave of the passions.

## 1.4: The Case of Disgust

Disgust is a human universal. It shows up in every culture.  When you're disgusted by something, you don't want to touch it. You, you, you don't want to smell it, and you certainly don't want to eat it. You don't want it in your mouth.

In the extreme, something sufficiently disgusting could make you vomit, and it will, always illicit this distinctive emotion, this distinctive feeling, that we identify, as disgust.

Evolutionary psychologists, interested in emotions, have argued that this feeling evolved for a certain function. It evolved to motivate us, to avoid parasites and poisons. So you think of the things that we are disgusted by, and they share certain things in common. They could poison us, they, they have infectious properties.

But, one of the most troubling facts about disgust, is that people can be disgusting. And this was something pointed out by Charles Darwin, who was always a wonderful and acute observer of of human interaction. Whilst I felt utter disgust at my food being touched by a naked savage, though his hands did not appear dirty.

People are disgusting. Our response to strangers, our response to being touched by strangers, to, to smelling strangers and so on, is often a response of disgust. Now, there's some debate in the field as to, why people illicit disgust.

Some scholars say, people illicit disgust because people carry diseases. Strange people will carry strange diseases.

Others argue that it's not really that, rather, people are disgusting because we are fleshy things. We are made of meat. We, we, we produce feces, and urine, and other things. We, we are, we are animal like things and if you think of people in that way, you can be readily disgusted by them.

Once you are disgusted by them, it can have moral effects, it could have consequences and the consequences of being disgusted by somebody, of being disgusted by a group of people, are profoundly negative.

Every genocidal movement that, that has left a record, exhibits signs that disgust was used, to illicit hatred towards the despised group. Most movements involving prejudice and discrimination, don't just say those people, they're rotten, they're stupid, they're mean. They also say, they're disgusting.

This is an insight that the philosopher Martha Nessbaum, nicely summarizes. Throughout history, certain disgust properties, sliminess, bad smell, stickiness, decay, foulness, have repeatedly and monotonously been associated with Jews, women, homosexuals, untouchables, lower class people.

All of those are imagined as tainted, by the dirt of the body. and, and this is an example from Nazi propaganda. But there are, are countless such examples, where a despised group is described as, disgusting. There seems to be a natural connection to being disgusted by somebody and, not caring about them.

In fact, wanting them to suffer. Psychologists have studied disgust in the lab. And there's different ways to do it. So, one way to do it is, you can see how easily disgusted people are, and then see how much their disgust sensitivity, predicts other properties about them.

And it turns out that, that your disgust sensitivity is related to certain interesting facts about you. Women, on average, are more disgust sensitive, than men. There's evidence that women become particularly disgust sensitive, at a certain vulnerable point in pregnancy.

Political conservatives, tend to be more disgust sensitive, than political liberals. And most important for what we're talking about here, your disgust sensitivity corresponds to, certain moral attitudes. So for instance, in some, some research finds, that people who are very disgust sensitive, are more likely to be, express negative moral attitudes about homosexuals.

Turns out, being grossed out by this fart spray, doesn't influence your feelings about tax policy. And it doesn't influence your feelings about the environment or, or other things. But it does affect, how you think about groups like homosexuals.

It makes you harsher towards them. It also makes you harsher towards moral violations, you could called purity violations. Like consensual incest or or masturbation in an inappropriate place or stuff like that. If you're disgusted, you're more disapproving.

And these studies suggest that, your feelings about somebody or, or what somebody does, can be influenced by your emotional state. In particular, your emotional state of disgust. Now disgust can also influence certain specific moral judgments. So, so far I've been talking more or less about, moral feelings towards somebody. But what about judgments about, what's right and wrong?

Well, Jonathan Haidt thought up some very interesting examples. And he uses these examples to show that, even people who think, that they're very liberal and quite consequential, can be influenced in their judgments of morality, by whether or not, something disgusts them.

Examples

-  Julie and Mark are our sister and brother. They're adults, they travel together. They decide to have sex with one another. Now, they're very cognizant of worries of having pregnancy and so on, so they use tons of birth control. There's no chance, that, that, that she'll get pregnant. And they have sex and it's great. And they do it several times, and they just love it. And then they decide, they're not going to tell anybody, and and they're not going to do it again. Did Julie and Mark do something wrong?
- Family dog runs out in the street, gets hit by a car. Family brings the dog in, very sad. But then they realize, they have nothing planned for supper tonight. So they cook the dog and eat it. And it's delicious, and they're very happy.
-  The toilet is very dirty but this guy has run out of cleaning supplies, and wants to clean the toilet. Fortunately, he has an American flag. Takes the flag and uses it,
to scrub the toiler clean. Now he's happy, clean toilet. Has he done anything wrong?
-  The chicken case is, this guy goes to supermarket, he buys a chicken, he brings the chicken back home. It's not a live chicken, like a chicken, like you, from the supermarket, he makes love to the chicken, has sex with the chicken. And then he cooks it and eats it. Has he done something wrong?

I'm not asking you, whether he's done something which grosses you out. I, I imagine, you have an answer to that. Has he done anything wrong?

Now, what Haidt finds is, for these sorts of examples, he finds a couple of things. First thing is that, most people, almost everybody find so many things wrong, they find them morally wrong. The exceptions are liberal, highly liberal students from elite universities.

Some of them say no, those are all okay, no one's harmed. But most people, almost everybody, find them wrong. But he also finds, that people are, not usually able to explain, what they find, wrong about them. And he calls this, moral dumbfounding.

Incest: No chance to get pregnant. Other people will not find out. People struggle to find an explanation why they think it is wrong.  Rather, their reaction is because these things disgust them. And because they're disgusting, they're found to be immoral. And if he's right, this would be a case where, our emotions and not our reason, are driving moral judgment.

## 1.5: Cute and Sexy

Our gut feelings can be positive towards somebody. Babies: Very easy to feel fondly towards, that will elicit a desire to protect. It's because it's adorable, because, because of the big eyes and the round cheeks and these sort of cues that we've been wired up to respond to.

And, and, and our, the effects of these cues and how we feel towards people and how we feel towards creatures has, has real effects. Here are two animals. Now, I actually don't have a strong opinion as to which animal is smarter, which animal has a richer emotional life. Which animal feels more pain.

But, what's not a hard question is I know which animal people care about more. One animal we bring into our houses, and we we, we give treats to, and we hold birthday parties for, and we love. And, the other kind of animal we eat. And this does not have to do with the features of the animal.

It has to do with, with how they look. Kittens are cute. Pigs are not. There are other distinctions one could make, more subtle distinctions one could make, concerning sort of positive responses.

And their effects on moral reasoning. So, one research program I've been interested in is, concerns the effects of looking at people's bodies, and to what extent does looking at people's bodies affect how you judge them and think about them morally.

It turns out that when you see somebody's body, it has two effects on your reasoning about them. One is, you actually, in some way, care more about them. You think that they're more vulnerable to pain. You think they're more sensitive to, to, to, to being hurt. You worry a little bit more about them. But you also tend to deny them moral agency.

What I mean by this is that, for most of us, when you look at somebody, you say, well, there's a person that could be blamed, they could be praised, they're responsible for their own actions, they make their own decisions. But when you see somebody's body, that tendency to think of them as an agent goes down a bit. 

Now this, these pictures, the difference I'm showing you here is fairly subtle. And we thought in our experiments we'd be stuck with those sort of subtle distinctions until we found this wonderful book (30 Porn Star Portraits). And this book has photographs, side by side, of the very same men and women. But, in one picture, they're fully dressed. And in the other pictures, they're entirely naked.

We found that when people are naked, you tend, in some way, to be more concerned about them. But also, you tend to deny them moral agency. It really matters. There's something, there's some real psychological truth to the claim made by feminist scholars, that the objectification of women, thinking of women as sexual beings, as physical beings, has an effect, perhaps a pernicious effect on how you think about them and what we find in this work is, it applies to men as well as women.

If you did, you should put these two books together on your shelves separately and then people will look at them and they will wonder what kind of person you are. So, why do naked people, why do bodies, have this sort of effect on us?

One explanation is, that, they inspire lust. And lust somehow blocks certain morals. Sentiment makes you think about a person a different way. Another possibility, that is sort of separate from lust, is that if you see somebody without clothes. They're more like an animal, they lose their dignity. They lose their status. And it's that which is driving the effect.

And we actually, in our research, we don't know the answer to that. But we do know, from other work, that the feeling of lust, the feeling of sexual arousal can have an affect on your moral decision making.

Dan Ariely experiment (the masturbating thing): So you could ask people whether or not they could imagine being attracted to a 12-year-old girl. And it turns out if people were non-aroused, like, you know, a quarter say yeah. But when they're aroused, it doubles. Or or becoming sexually excited, by an animal.

The most disturbing findings involved a sort of date rapey, questions. Would you slip a woman a drug to increase the chances that she would have sex with you? When men were not aroused, 5% said yes. But this number got much, much bigger when they were aroused.

I, it tells people, that your psychology changes when you're aroused. You're no longer the same person in an important sense. Your sense of what turns you on when you're aroused is different from when you're not aroused. And it's yet another argument that our morality can be influenced by not just by reason, but by the emotions.

## 1.6: Returning to the Trolley

We said this might be because people have this abstract philosophical principle that sees, sort of, a subtle difference between these two, and for instance, the principle we talked about was, in the switch case, the guy dying is an accident, doesn't do any good.

In the bridge case the guy dying is essential. He's an instrument through which to bring about the good. And this was the analysis we had. But there's an alternative. This alternative was proposed by Joshua Green and has a lot of support. The alternative says, that's not what's happening at all.

And what he did was, he had people solve trolley problems, like reasonsabout moral problems, while they were hooked up to an fMRI. He found that the switch case activated parts of the brain in the frontal cortex, the part of the brain that's up front here. And these are parts of the brain that are typically involved concious deliberative reasoning. And these parts of the brains would be active and people would make their choice. And often their choice would be, yeah they should throw the switch, that makes sense. Five lives matter more than one life.

What about, the bridge case? Well here the same part of the brain, was active. Presumably doing the calculations of, five versus one. But also, various other parts of the brain that are involved in conflict and emotion, emotional feelings, light up stronger. And, for these sorts of cases, people say that you shouldn't push the man.

The way Green analyzes this is, it's not that there's some sort of subtle philosophical principle that governs the difference between the switch case and the bridge case. Rather, 

there's sort of two aspects of our moral psychology. There's controlled rational processes. And the controlled rational processes are, under Green's view, largely utilitarian. They just calculate consequences in a very cold-blooded way. But there's also automatic, involuntary, gut feelings.

And so what Green says is, for the switch case you just map. You, and so you have choosing you have one life and five lives to control process, chug away. And you typically say well, you know, better to save five. Even at the expense of one. But for the bridge case, emotions light up. It's not just a cold blooded calculation one and five, but also this gut feeling. And the gut feeling lights up for green. Not because of any principle or structure. It's, it's the idea that this visceral feeling of putting your hands on somebody and shoving, causes emotional response. That's what's driving it.

It has nothing to do with the doctrine of double effect, or anything like that. It's an emotional response to the physicality of pushing somebody to his death.

We also know from other research that people can be influenced in their choices on the switch case and a bridge case by fiddling with their emotions in various ways. So my favorite example of this is, how do you make people more likely to say it's okay to push the man off the bridge? 

Show them something funny.

So they, so, the researchers found some very funny clips from Saturday Night Live, they showed em to people, people laughed, and then they asked bridge case. And they said, now people said, yeah, I'll push em. Suggesting that there, that, that there aren't these abstract emotion, sorry, the abstract rational principles guiding our choices here, but rather, gut feelings played more of a role.

## 1.7: The Big Questions

Is Hume right? Is, is, is really more reasoning just a slave of the passions? What's the proper relationship between emotion and reason in everyday moral life? Is everything emotional? Does reason play any important role?

Emotion plainly affects our morality. But I want to try also persuade you that reason, cold blooded rational deliberation, thinking things through also affects our moral lives.

Second big question is where do morals come from? So, how much of our moral judgments we've
been talking about, are intuitions about trolley problems and murder and rape and, and masturbation and selling your body organs and eating dogs and so on?

How much of this is explained by evolution, so part of our brain structured by our, our evolutionary history, how much of it is explained by personal, individual experience, how much varies from culture to culture, and how much of it is just personal choice?

And then the third question, the big question maybe, is can scientific inquiry - including psychological inquiry - help us with morality? Can it help us be better people?

Some people say it is a fallacy to go from the way the world is, which is what science studies, to the way the world ought to be, which is the proper domain of ethics. But things might be more complicated than that, and we're going to struggle with these questions, throughout.

And for the reading, for the assignments for this week you're supposed to watch their TED talks where they present their view in detail. What I want to do here is, as a way to introduce it, present a snippet from each of their talks.

And what I like about, about this is they're each articulate proponents of a perspective on morality, but the perspectives are quite different. They are, they are, are as close to opposites as you could find. 

Sam Harris argues there's object the facts about the moral landscape. And it, what makes it a moral landscape is, the space has hills where, where things are good, and valleys where things are bad. And there are objective facts. And he argues that many popular moral (mostly religious) views - are just wrong. They're as wrong about morality as they are about, you know, cosmology.

>> When talking about morality, we value differences of opinion in a way that we don't in any other area of our lives. The Dalai Lama thinks that helping other human beings is an integral component of human happiness. Ted Bundy was very fond of abducting and raping and torturing and killing young So we appear to have a genuine difference
of opinion about how to profitably use
one's time.

>> Most western intellectuals look at this situation and say, well there's nothing for the Dalai Lama to be really right about, really right about. Or for Ted Bundy to be really wrong about. That admits of a, of a real argument. That, that, that, that potentially falls within the purview of science.

> Well, you know, that he's like chocolate, he likes vanilla there's, there's no, there's nothing that one should be able to say to the other, that should persuade the other.

> Now notice that we don't do this in science. Whenever we are talking about facts, certain opinions must be excluded. Then, that is what it is to have a domain of expertise. That is what it is for knowledge to count. 

> How have we convinced ourselves that in the moral sphere, there is no such thing as moral expertise? Or moral talent? Or moral genius, even? How have we convinced ourselves that every opinion has to count? How have we convinced ourselves that, that every culture has a point of view on these subjects worth considering? Does, does the Taliban have a point of view on physics that is worth considering? No.

> How, how is there ignorance, how is their ignorance, how is their ignorance any less obvious on the subject of human well being?

> So, so this I, I think is what the world needs now. It needs people like ourselves to admit that there are right and wrong answers to questions of human flourishing. And morality relates to that domain of facts. It is possible, for individuals, and even for whole cultures to care about the wrong things. Just admitting this, will transform our discourse about morality.

> We live in a world in which, the boundaries between nations mean less and less, and they will one day mean nothing. We live in a world filled with destructive technology, and this technology cannot be uninvented. It, it will always be easier to break things than to fix them.

> It seems to me, therefore, patently obvious that we can no more, respect and tolerate vast differences in, in notions of human well being than we can respect or tolerate vast difference in the notions about how disease spreads. Or in the, in the safety standards of buildings and airplanes. We simply must converge on the answers we give to the most important questions in human life.

> And to do that, we have to admit that these questions have answers. Thank you very much.

So Jonathan Haidt in contrast has a very different perspective. Haidt emphasizes a respect for pluralism. In particular, he argues that many moral frameworks including common ones that are grounded in religion, deserve respect.

> You have the markings of, of Vishnu on the left, so we could think of Vishnu as the
conservative god. You have the markings of Shiva, on the right. Shiva is the liberal god, and they work together.

> You find the same thing in Buddhism. These two stanzas contain I think the deepest insights that have ever been attained, into moral psychology.

> "From the Zen master Seng-ts'an. If you want the trust to stand clear before you, never be for or against. The struggle between for and against is the mind's worst disease."

> Well, if you take the greatest insights from ancient Asian philosophies and religions and you combine them with the latest research on moral psychology, I think you'd come to these conclusions. That our righteous minds were designed by evolution to unite us into teams, to divide us against other teams, and then to blind us to the truth.

> So, what should you do? Am I telling you to not strive? Am I telling you to embrace Seng-ts'an and stop?  No, absolutely not. I'm not saying that. This is an amazing group of people, who are doing so much, using so much of their talent, their brilliance, their energy, their money to make the world a better place, to fight, to fight wrongs to, to solve problems. But as you can't just go charging in, saying you're wrong and I'm right. because as we just heard, everybody thinks they are right.

> A lot of the problems we have to solve are problems that require to change other people. And if you want to change other people, the much better way to do it is to first understand who we are. Understand our moral psychology, understand that we all think we're right, and then step out. Step out of the moral matrix, just try to see it as, as a struggle playing out in which everybody does think they're right. And everybody at least has some reasons, even if you disagree with them, everybody has some reasons for what they're doing.

But what again, what I hope to do is, as we talk more and more about the science of morality, talk more about theories, talk more about data. We'll be in a better position, all of us, to better decide, what's the right answer to these big and these very important questions.

## Readings 1.1: The Moral Instinct, Steven Pinker

For most people, Mother Theresea > Bill Gates > Norman Borlaug for who is most admirable. But Borlaug used the agriculture revolution and is credited with saving a billion lives, Gates fights against malaria and diarrhea, and Mother Teresa's patrons were offered prayer but harsh conditions and primitive medical care.

Our heads can be turned by an aura of sanctity, distracting us from a more objective recokning of the actions that make people suffer or flourish.

#### The Moralization Switch

Moralization is a psychological state that can be turned on and off like a switch, and when it is on, a distinctive mind-set commandeers our thinking. This is the mind-set that makes us deem actions immoral (“killing is wrong”), rather than merely disagreeable (“I hate brussels sprouts”), unfashionable (“bell-bottoms are out”) or imprudent (“don’t scratch mosquito bites”).

The rules it invokes are felt to be universal. Prohibiting rape/murder is universal, while hating brussel sprouts is not.

People feel that those who commit immoral acts desever to be punished. "They can't get away with it." "The infliction of cruelty with a good conscience is a delight to moralists — that is why they invented hell." - Bertrand Russell

Moral vegetarians are more likely to treat meat as a contaminant as opposed to health vegetarians. They are more likely to think that other people ought to be vegetarians, more likely to imbue their dietary habits with other virtues, like believing that meat avoidance makes people less aggressive and bestial.

Much of our recent social history, including the culture wars between liberals and conservatives, consists of the moralization or amoralization of particular kinds of behavior. Even when people agree that an outcome is desirable, they may disagree on whether it should be treated as a matter of preference and prudence or as a matter of sin and virtue. When secondhand smoke was discovered, smoking is now treated as immoral: images of people smoking are censored and entities touched by smoke are felt to be contaminated.

At the same time, many behaviors have been amoralized: divorce, illegitimacy, being a working mother, marijuana use and homosexuality. Many afflictions have been reassigned from payback for bad choices to unlucky misfortunes. There used to be people called “bums” and “tramps”; today they are “homeless.” Drug addiction is a “disease”; syphilis was rebranded from the price of wanton behavior to a “sexually transmitted disease” and more recently a “sexually transmitted infection.”

This wave of amoralization has led the cultural right to lament that morality itself is under assault, as we see in the group that anointed itself the Moral Majority. In fact there seems to be a Law of Conservation of Moralization, so that as old behaviors are taken out of the moralized column, new ones are added to it. Dozens of things that past generations treated as practical matters are now ethical battlegrounds, including disposable diapers, I.Q. tests, poultry farms, Barbie dolls and research on breast cancer. Food alone has become a minefield, with critics sermonizing about the size of sodas, the chemistry of fat, the freedom of chickens, the price of coffee beans, the species of fish and now the distance the food has traveled from farm to plate.

Many of these moralizations, like the assault on smoking, may be understood as practical tactics to reduce some recently identified harm. But whether an activity flips our mental switches to the “moral” setting isn’t just a matter of how much harm it does. We don’t show contempt to the man who fails to change the batteries in his smoke alarms or takes his family on a driving vacation, both of which multiply the risk they will die in an accident. Driving a gas-guzzling Hummer is reprehensible, but driving a gas-guzzling old Volvo is not; eating a Big Mac is unconscionable, but not imported cheese or crème brûlée. The reason for these double standards is obvious: people tend to align their moralization with their own lifestyles.

#### A Universal Morality?

The stirrings of morality emerge early in childhood. Toddlers spontaneously offer toys and help to others and try to comfort people they see in distress. And according to the psychologists Elliot Turiel and Judith Smetana, preschoolers have an inkling of the difference between societal conventions and moral principles. Four-year-olds say that it is not O.K. to wear pajamas to school (a convention) and also not O.K. to hit a little girl for no reason (a moral principle). But when asked whether these actions would be O.K. if the teacher allowed them, most of the children said that wearing pajamas would now be fine but that hitting a little girl would still not be.

Though no one has identified genes for morality, there is circumstantial evidence they exist. The character traits called “conscientiousness” and “agreeableness” are far more correlated in identical twins separated at birth (who share their genes but not their environment) than in adoptive siblings raised together (who share their environment but not their genes). People given diagnoses of “antisocial personality disorder” or “psychopathy” show signs of morality blindness from the time they are children. They bully younger children, torture animals, habitually lie and seem incapable of empathy or remorse, often despite normal family backgrounds. Some of these children grow up into the monsters who bilk elderly people out of their savings, rape a succession of women or shoot convenience-store clerks lying on the floor during a robbery.

Though psychopathy probably comes from a genetic predisposition, a milder version can be caused by damage to frontal regions of the brain (including the areas that inhibit intact people from throwing the hypothetical fat man off the bridge). The neuroscientists Hanna and Antonio Damasio and their colleagues found that some children who sustain severe injuries to their frontal lobes can grow up into callous and irresponsible adults, despite normal intelligence. They lie, steal, ignore punishment, endanger their own children and can’t think through even the simplest moral dilemmas, like what two people should do if they disagreed on which TV channel to watch or whether a man ought to steal a drug to save his dying wife.

#### The Varieties of Moral Experience

The exact number of themes depends on whether you’re a lumper or a splitter, but Haidt counts five — harm, fairness, community (or group loyalty), authority and purity — and suggests that they are the primary colors of our moral sense. Not only do they keep reappearing in cross-cultural surveys, but each one tugs on the moral intuitions of people in our own culture. Haidt asks us to consider how much money someone would have to pay us to do hypothetical acts like the following:

Stick a pin into your palm.

Stick a pin into the palm of a child you don’t know. (Harm.)

Accept a wide-screen TV from a friend who received it at no charge because of a computer error.

Accept a wide-screen TV from a friend who received it from a thief who had stolen it from a wealthy family. (Fairness.)

Say something bad about your nation (which you don’t believe) on a talk-radio show in your nation.

Say something bad about your nation (which you don’t believe) on a talk-radio show in a foreign nation. (Community.)

Slap a friend in the face, with his permission, as part of a comedy skit.

Slap your minister in the face, with his permission, as part of a comedy skit. (Authority.)

Attend a performance-art piece in which the actors act like idiots for 30 minutes, including flubbing simple problems and falling down on stage.

Attend a performance-art piece in which the actors act like animals for 30 minutes, including crawling around naked and urinating on stage. (Purity.)

In each pair, the second action feels far more repugnant. Most of the moral illusions we have visited come from an unwarranted intrusion of one of the moral spheres into our judgments. A violation of community led people to frown on using an old flag to clean a bathroom. Violations of purity repelled the people who judged the morality of consensual incest and prevented the moral vegetarians and nonsmokers from tolerating the slightest trace of a vile contaminant. At the other end of the scale, displays of extreme purity lead people to venerate religious leaders who dress in white and affect an aura of chastity and asceticism.

#### The Genealogy of Morals

The five spheres are good candidates for a periodic table of the moral sense not only because they are ubiquitous but also because they appear to have deep evolutionary roots. The impulse to avoid harm, which gives trolley ponderers the willies when they consider throwing a man off a bridge, can also be found in rhesus monkeys, who go hungry rather than pull a chain that delivers food to them and a shock to another monkey. Respect for authority is clearly related to the pecking orders of dominance and appeasement that are widespread in the animal kingdom. The purity-defilement contrast taps the emotion of disgust that is triggered by potential disease vectors like bodily effluvia, decaying flesh and unconventional forms of meat, and by risky sexual practices like incest.

The other two moralized spheres match up with the classic examples of how altruism can evolve that were worked out by sociobiologists in the 1960s and 1970s and made famous by Richard Dawkins in his book “The Selfish Gene.” Fairness is very close to what scientists call reciprocal altruism, where a willingness to be nice to others can evolve as long as the favor helps the recipient more than it costs the giver and the recipient returns the favor when fortunes reverse. The analysis makes it sound as if reciprocal altruism comes out of a robotlike calculation, but in fact Robert Trivers, the biologist who devised the theory, argued that it is implemented in the brain as a suite of moral emotions. Sympathy prompts a person to offer the first favor, particularly to someone in need for whom it would go the furthest. Anger protects a person against cheaters who accept a favor without reciprocating, by impelling him to punish the ingrate or sever the relationship. Gratitude impels a beneficiary to reward those who helped him in the past. Guilt prompts a cheater in danger of being found out to repair the relationship by redressing the misdeed and advertising that he will behave better in the future (consistent with Mencken’s definition of conscience as “the inner voice which warns us that someone might be looking”). Many experiments on who helps whom, who likes whom, who punishes whom and who feels guilty about what have confirmed these predictions.

Community, the very different emotion that prompts people to share and sacrifice without an expectation of payback, may be rooted in nepotistic altruism, the empathy and solidarity we feel toward our relatives (and which evolved because any gene that pushed an organism to aid a relative would have helped copies of itself sitting inside that relative). In humans, of course, communal feelings can be lavished on nonrelatives as well. Sometimes it pays people (in an evolutionary sense) to love their companions because their interests are yoked, like spouses with common children, in-laws with common relatives, friends with common tastes or allies with common enemies. And sometimes it doesn’t pay them at all, but their kinship-detectors have been tricked into treating their groupmates as if they were relatives by tactics like kinship metaphors (blood brothers, fraternities, the fatherland), origin myths, communal meals and other bonding rituals.

#### Juggling the Spheres

America - harm and fairness. Japan - community (fear of nonconfromity). Hindus/Jews - purity (dietary restrictions). Muslims - authority (insulting the prophet.) West hates nepotism/cronyism, but in other parts of the world, family is more important than strangers.

#### Is Nothing Sacred?

And “morally corrosive” is exactly the term that some critics would apply to the new science of the moral sense. The attempt to dissect our moral intuitions can look like an attempt to debunk them. In reality, none of these fears are warranted, and it’s important to see why not. 

“Selfish” genes are perfectly compatible with selfless organisms, because a gene’s metaphorical goal of selfishly replicating itself can be implemented by wiring up the brain of the organism to do unselfish things, like being nice to relatives or doing good deeds for needy strangers.

Nor does reciprocal altruism — the evolutionary rationale behind fairness — imply that people do good deeds in the cynical expectation of repayment down the line.

In his classic 1971 article, Trivers, the biologist, showed how natural selection could push in the direction of true selflessness. The emergence of tit-for-tat reciprocity, which lets organisms trade favors without being cheated, is just a first step. A favor-giver not only has to avoid blatant cheaters (those who would accept a favor but not return it) but also prefer generous reciprocators (those who return the biggest favor they can afford) over stingy ones (those who return the smallest favor they can get away with). Since it’s good to be chosen as a recipient of favors, a competition arises to be the most generous partner around. More accurately, a competition arises to appear to be the most generous partner around, since the favor-giver can’t literally read minds or see into the future. A reputation for fairness and generosity becomes an asset.

Now this just sets up a competition for potential beneficiaries to inflate their reputations without making the sacrifices to back them up. But it also pressures the favor-giver to develop ever-more-sensitive radar to distinguish the genuinely generous partners from the hypocrites. This arms race will eventually reach a logical conclusion. The most effective way to seem generous and fair, under harsh scrutiny, is to be generous and fair. In the long run, then, reputation can be secured only by commitment. At least some agents evolve to be genuinely high-minded and self-sacrificing — they are moral not because of what it brings them but because that’s the kind of people they are.

Of course, a theory that predicted that everyone always sacrificed themselves for another’s good would be as preposterous as a theory that predicted that no one ever did. Alongside the niches for saints there are niches for more grudging reciprocators, who attract fewer and poorer partners but don’t make the sacrifices necessary for a sterling reputation. And both may coexist with outright cheaters, who exploit the unwary in one-shot encounters. An ecosystem of niches, each with a distinct strategy, can evolve when the payoff of each strategy depends on how many players are playing the other strategies. The human social environment does have its share of generous, grudging and crooked characters, and the genetic variation in personality seems to bear the fingerprints of this evolutionary process.

#### Is Morality a Figment?

So a biological understanding of the moral sense does not entail that people are calculating maximizers of their genes or self-interest. But where does it leave the concept of morality itself?

Here is the worry. The scientific outlook has taught us that some parts of our subjective experience are products of our biological makeup and have no objective counterpart in the world. The qualitative difference between red and green, the tastiness of fruit and foulness of carrion, the scariness of heights and prettiness of flowers are design features of our common nervous system, and if our species had evolved in a different ecosystem or if we were missing a few genes, our reactions could go the other way. Now, if the distinction between right and wrong is also a product of brain wiring, why should we believe it is any more real than the distinction between red and green? And if it is just a collective hallucination, how could we argue that evils like genocide and slavery are wrong for everyone, rather than just distasteful to us?

Putting God in charge of morality is one way to solve the problem, of course, but Plato made short work of it 2,400 years ago. Does God have a good reason for designating certain acts as moral and others as immoral? If not — if his dictates are divine whims — why should we take them seriously? Suppose that God commanded us to torture a child. Would that make it all right, or would some other standard give us reasons to resist? And if, on the other hand, God was forced by moral reasons to issue some dictates and not others — if a command to torture a child was never an option — then why not appeal to those reasons directly?

This throws us back to wondering where those reasons could come from, if they are more than just figments of our brains. They certainly aren’t in the physical world like wavelength or mass. The only other option is that moral truths exist in some abstract Platonic realm, there for us to discover, perhaps in the same way that mathematical truths (according to most mathematicians) are there for us to discover. On this analogy, we are born with a rudimentary concept of number, but as soon as we build on it with formal mathematical reasoning, the nature of mathematical reality forces us to discover some truths and not others. (No one who understands the concept of two, the concept of four and the concept of addition can come to any conclusion but that 2 + 2 = 4.) Perhaps we are born with a rudimentary moral sense, and as soon as we build on it with moral reasoning, the nature of moral reality forces us to some conclusions but not others.

Moral realism, as this idea is called, is too rich for many philosophers’ blood. Yet a diluted version of the idea — if not a list of cosmically inscribed Thou-Shalts, then at least a few If-Thens — is not crazy. Two features of reality point any rational, self-preserving social agent in a moral direction. And they could provide a benchmark for determining when the judgments of our moral sense are aligned with morality itself.

One is the prevalence of nonzero-sum games. In many arenas of life, two parties are objectively better off if they both act in a nonselfish way than if each of them acts selfishly. You and I are both better off if we share our surpluses, rescue each other’s children in danger and refrain from shooting at each other, compared with hoarding our surpluses while they rot, letting the other’s child drown while we file our nails or feuding like the Hatfields and McCoys. Granted, I might be a bit better off if I acted selfishly at your expense and you played the sucker, but the same is true for you with me, so if each of us tried for these advantages, we’d both end up worse off. Any neutral observer, and you and I if we could talk it over rationally, would have to conclude that the state we should aim for is the one in which we both are unselfish. These spreadsheet projections are not quirks of brain wiring, nor are they dictated by a supernatural power; they are in the nature of things.

The other external support for morality is a feature of rationality itself: that it cannot depend on the egocentric vantage point of the reasoner. If I appeal to you to do anything that affects me — to get off my foot, or tell me the time or not run me over with your car — then I can’t do it in a way that privileges my interests over yours (say, retaining my right to run you over with my car) if I want you to take me seriously. Unless I am Galactic Overlord, I have to state my case in a way that would force me to treat you in kind. I can’t act as if my interests are special just because I’m me and you’re not, any more than I can persuade you that the spot I am standing on is a special place in the universe just because I happen to be standing on it.

Not coincidentally, the core of this idea — the interchangeability of perspectives — keeps reappearing in history’s best-thought-through moral philosophies, including the Golden Rule (itself discovered many times); Spinoza’s Viewpoint of Eternity; the Social Contract of Hobbes, Rousseau and Locke; Kant’s Categorical Imperative; and Rawls’s Veil of Ignorance. It also underlies Peter Singer’s theory of the Expanding Circle — the optimistic proposal that our moral sense, though shaped by evolution to overvalue self, kin and clan, can propel us on a path of moral progress, as our reasoning forces us to generalize it to larger and larger circles of sentient beings.

Doing Better by Knowing Ourselves

Morality, then, is still something larger than our inherited moral sense, and the new science of the moral sense does not make moral reasoning and conviction obsolete. At the same time, its implications for our moral universe are profound.

At the very least, the science tells us that even when our adversaries’ agenda is most baffling, they may not be amoral psychopaths but in the throes of a moral mind-set that appears to them to be every bit as mandatory and universal as ours does to us. Of course, some adversaries really are psychopaths, and others are so poisoned by a punitive moralization that they are beyond the pale of reason. (The actor Will Smith had many historians on his side when he recently speculated to the press that Hitler thought he was acting morally.) But in any conflict in which a meeting of the minds is not completely hopeless, a recognition that the other guy is acting from moral rather than venal reasons can be a first patch of common ground. One side can acknowledge the other’s concern for community or stability or fairness or dignity, even while arguing that some other value should trump it in that instance. With affirmative action, for example, the opponents can be seen as arguing from a sense of fairness, not racism, and the defenders can be seen as acting from a concern with community, not bureaucratic power. Liberals can ratify conservatives’ concern with families while noting that gay marriage is perfectly consistent with that concern.

The science of the moral sense also alerts us to ways in which our psychological makeup can get in the way of our arriving at the most defensible moral conclusions. The moral sense, we are learning, is as vulnerable to illusions as the other senses. It is apt to confuse morality per se with purity, status and conformity. It tends to reframe practical problems as moral crusades and thus see their solution in punitive aggression. It imposes taboos that make certain ideas indiscussible. And it has the nasty habit of always putting the self on the side of the angels.

Though wise people have long reflected on how we can be blinded by our own sanctimony, our public discourse still fails to discount it appropriately. In the worst cases, the thoughtlessness of our brute intuitions can be celebrated as a virtue. In his influential essay “The Wisdom of Repugnance,” Leon Kass, former chair of the President’s Council on Bioethics, argued that we should disregard reason when it comes to cloning and other biomedical technologies and go with our gut: “We are repelled by the prospect of cloning human beings . . . because we intuit and feel, immediately and without argument, the violation of things that we rightfully hold dear. . . . In this age in which everything is held to be permissible so long as it is freely done . . . repugnance may be the only voice left that speaks up to defend the central core of our humanity. Shallow are the souls that have forgotten how to shudder.”

There are, of course, good reasons to regulate human cloning, but the shudder test is not one of them. People have shuddered at all kinds of morally irrelevant violations of purity in their culture: touching an untouchable, drinking from the same water fountain as a Negro, allowing Jewish blood to mix with Aryan blood, tolerating sodomy between consenting men. And if our ancestors’ repugnance had carried the day, we never would have had autopsies, vaccinations, blood transfusions, artificial insemination, organ transplants and in vitro fertilization, all of which were denounced as immoral when they were new.

There are many other issues for which we are too quick to hit the moralization button and look for villains rather than bug fixes. What should we do when a hospital patient is killed by a nurse who administers the wrong drug in a patient’s intravenous line? Should we make it easier to sue the hospital for damages? Or should we redesign the IV fittings so that it’s physically impossible to connect the wrong bottle to the line?

And nowhere is moralization more of a hazard than in our greatest global challenge. The threat of human-induced climate change has become the occasion for a moralistic revival meeting. In many discussions, the cause of climate change is overindulgence (too many S.U.V.’s) and defilement (sullying the atmosphere), and the solution is temperance (conservation) and expiation (buying carbon offset coupons). Yet the experts agree that these numbers don’t add up: even if every last American became conscientious about his or her carbon emissions, the effects on climate change would be trifling, if for no other reason than that two billion Indians and Chinese are unlikely to copy our born-again abstemiousness. Though voluntary conservation may be one wedge in an effective carbon-reduction pie, the other wedges will have to be morally boring, like a carbon tax and new energy technologies, or even taboo, like nuclear power and deliberate manipulation of the ocean and atmosphere. Our habit of moralizing problems, merging them with intuitions of purity and contamination, and resting content when we feel the right feelings, can get in the way of doing the right thing.

Far from debunking morality, then, the science of the moral sense can advance it, by allowing us to see through the illusions that evolution and culture have saddled us with and to focus on goals we can share and defend. As Anton Chekhov wrote, “Man will become better when you show him what he is like.”

## Week 1 Office Hours

I'm actually personal friends with both of them. They both blurbed my book, Just Babies. And I have sympathies intellectual sympathies to different extents with, with both of them. But it's fair to say that, that is Harris that generates the most heat, because Harris is very explicit.

His view is, that some, the way some religions do it, actually the way all religions do it, possible exception of Buddhism, and the way some cultures do it, live their lives, treat people is just wrong. And when you say that kind of thing, it's going to generate some heat. It is, it is, nobody likes to hear that, the way you do in your country is morally wrong and morally mistaken in how you're living your lives. So I'm not surprised that people are, are bothered by Harris. Why, perhaps offended by Harris. I, I I don't mind it. I think it shows people are, I think, I think people if you have certain issues you should be offended by Harris. But, he's a smart enough scholar and, and, and is gifted at clearly articulating an interesting and important view, that I had to include him. And I'm very happy I did.

Harris is very clearly a consequentalist, a utilitarian actually. He argues that there's a landscape of pain and pleasure. __And that you judge a society by how well it, it, it, it places people on that landscape.__ How it maximizes happiness. In some way, Sam Harris is the most purest incarnation of Jeremy Bentham. However, Harris's style of argument is certainty. Is is sort of declarative and, and argumentative style. You could easily strike somebody as almost Contian, as almost categorical. Drawing sharp lines and so on and that is how he, he makes his arguments. It's how it's, it, it's, it's his rhetorical style but he's pure consequentialist. 

So when Harris says, you guys where, where guys could be Christians. Or Muslims. He says you guys are doing it wrong. What he means is, you're not violating some abstract principle. Rather, you're moral rules are causing suffering. The way you're living your life causes suffering. Causes pain without the accompaniment of pleasure. Does not allow people to flourish. Doesn't allow people to fulfill their lives. And that's consequentialism through and through.

So we'll be reading more, more of Haidt in the course. We'll be reading a chapter, a chapter of his on politics. And Haidt is definitely more pluralist than Harris. Haidt thinks there are many ways to build a moral life here, many different moral values to be maximized, not all of them being consequentialist. And he has more respect for them. He has more respect for a society that tries to maximize values like community purity, divinity, all things that Harris has very little patience for. So he's a pluralist. 

But it's not correct I think to say that, that for Haidt everything goes. In particular, Haidt would say some moral views are just flat wrong. The views he respects, are those that have a long history. And his logic, I think, is that if there's been a moral view that's been around for a long time, centuries, the view has in some way proven itself worthy of respect. It proves that you would have if it's, we're going to flourish in society over hundreds, maybe thousands of years, Haidt's intuition is this is doing something for them and, and we should show some respect for that view. It's fundamentally a conservative argument, I think its a good conservative argument which is, you shouldn't be so quick to reject things that have been around for a long time, because the fact that they have been around for a long time might suggest that they have more utility. 

I think that virtue ethicists have a good point when they say, you know, we should focus instead on how to live one's life. What sort of moral character we should be. so, so it might be a wrong turn. To just put so much focus on what would you do if there's a runaway trolley and there's this and there's that and you can do this and that because in some way that is part of morality. But another part of morality is how to be a good mother, a good father, a good, good son, good daughter, good friend, a good colleague. Not in terms of, sort of, this dilemma, should you do X or Y? And to some extent I think it's because certainly as psychologists, we love boiling things down to, sort of, things where you say, okay what's the right answer, this or this. Then we test 1,000 people and we do statistics and everything like that. 

But what if morality isn't best appreciated that way. What if morality isn't a series of dilemmas or problems but more sort of a way of the kind of person you are and how you live your life. What it is to be a good friend can't be broken down into sort of a series of, do you do this or that, do you do this or that. You know it's, it's, it's not that kind of thing. It's, it's how you deal with people. How you, how you, you, you spend your time. How you, how you think about things. 

If I'm standing near a trolley and, you know, something's going to happen. Some people are going to be killed. Maybe the right thing to do is just not to do anything, because then I won't be responsible for some of the deaths. For any deaths. What do you think about that answer? What do you think of that answer? What would you do? So, so what do you think the right answer is? If not the, not the man on the bridge, but there's a, a runaway trolley and there's a switch, and if, if you throw the switch, it will get diverted from the five, and kill one person. Not asking now what the right thing to do is, what do you think you would do? 

But psychologically there's a big difference between an act and an omission and were not typically held as responsible for omissions. If I live in a big city and there's a homeless person in front of my building and I do nothing to help them and then they, they starve to death or they freeze in the winter. Did I kill them? Well, we're not abs, I, the police won't come to me and arrest me for murder. If I went down and hit him on the head with a hammer, then they'd arrest me. So we have this huge sense of an act versus an omission and this is very different from con, consequentialists say it shouldn't matter. 
But it does matter. And so I, I, I, I understand where it's coming from, the feeling you should do nothing. Because if you do nothing you have clean hands in a certain way. While as soon as you do something, you're responsible for the death that your act would cause. I think moral philosophers like Bentham or Peter Singer who we'll talk about in this week coming up would say that's mistaken, but it feels right. And so I have some sort of appreciation for it. 

And I'm absolutely fascinated by disgust and it's moral effects and so that question's [UNKNOWN] thought of a lot. And, I think the answer is yes. And I think the answer is yes in an everyday sense of disgust. So, take a new parent and a baby and you have to clean up it's, it's diaper or it's vomit and everything. Which new parents spend most of their time doing. And at first it's really gross, but you get used to it. You just get used to it. You, you, it doesn't bother you as much. You learn to, you learn to not focus on it. I would change my kids' diapers and after a while it wouldn't bother me at all. So, I could, could figure out how to do it. I never changed another kid's diaper. I tried it it's awful. But you know you get, you get used to it. And I think it's the same thing for I know we have people who posted, we have some nurses who posted, talking about how you, you get, you get used to it. 

But there's, there's also, I think, a more interesting answer which is I think to some extent other emotions conquer disgust. So there's a literature on, on lust, so so, so I'm not, don't worry, I'm not going to get graphic, but there's, but, but, people who are in sexual passion will often do things and engage in things that would be disgusting if they weren't. 

There's also love. I think that the, the, the treatment you give to your child, to an elderly parent, to a sick friend. If you love somebody, they cease to be disgusting to you. And this is why you have these stories of these saints. Who, who do engage in acts that, that, that would seem to be disgusting to many. And I think that these are meant to illustrate that these saints are filled with infinite love, even to strangers. Great. 

So Kant argues that you should never use never treat people as a means to an end, but always treat them as an end in them, in themselves. Doesn't psychology research treat people as a means? 

Yeah, yeah. It's, it's, it's true and, and I think some people are a little bit upset at this or a lot upset at this. So, there are some experiments including experiments we're going to talk about later on in the course that are, that we would never nowadays. They were done 20, 30, 40 years ago. And they are unethical. They're unethical because they they don't take people's dignity and consent into account because they, they do cruel deceptions and so on. I think we've learned a lot from them, but I think on balance we shouldn't have done them. 

The best interpretation of Kant I think, is that people shouldn't be only a means. That although we might interact with them. We might interact with them from the standpoint of, of getting something from them, getting from this place to that place, getting a meal, buying a product. We should also acknowledge that they're people and treat them with respect and, and, and, and with appreciation for the fact that they're people. 

And so, as a psychologist, I try to do that as well. So, when I do an experiment with an adult, I try to get the adult's consent. I don't want any unnecessary deception. When the experiment is over I, I, I explain to them what we did and so on. And and so in that way I think we, we avoid that worry. 

# Week 2

## 2.1: Caring About Others

Now empathy is often regarded as the source of compassion or source of all morality. And we'll evaluate that claim looking at what empathy is, how it works? What it could do for us? And what it can't do for us? Now, as a starting point, I want you to imagine a perfect psychopath. We are going to real psychopaths pretty soon, but now talk about an imaginary psychopath. 

#### Imaginary Psychopath

This imaginary psychopath is highly intelligent, has a normal set of emotions and desires, but totally lacks compassion, totally lacks fellow feeling. Other people do not matter to him. So, although he's not a sadist, when he wants something he'll try to get it, without any regard for other people's feelings. If he wants money or sex or power, he'll just try to get it, and he doesn't care who he hurts along the way. If the cat is in front of him and he's bored and he feels like strangling the cat, he'll strangle the cat. 

Now, suppose you had this perfect psychopath in front of you, and you wanted to take it upon yourself to convince him to be a good person. You wanted to argue with him that he shouldn't be this kind of person. So you started off by saying look, you know when you harm people, when you do things to people and they hate it, and it hurts them. And he says yeah. And he says well how would you feel if other people did that to you. And he would answer well I, I would hate that and then you say so do you recognize the symetry. 

And he would respond and say, sure, I'm not an idiot, I'm a highly intelligent psychopath. ___I recognize that the two are a lot alike. I just don't care.___ And then you could throw some philosophy at him. So you could talk about a consequentialist like Bentham, who would argue that the right thing to do is to increase the sum of pleasure in the world. And you say to him, look, you, look at your actions, you're decreasing the sum of pleasure. You're increasing the amount of pain in the world. And he could say, I don't care. I understand I'm making the world worse. I just don't care. You could talk about deontological philosophers like Immanuel Kant and tell him about the categorical imperative and he could say, I understand the categorical comparative. And remember, I'm a smart guy. I just don't care. I don't care if I make the world worst. I don't care if my acts are not the sort of acts one would want to extent universally. 

The only way you can get the psychopath to act in a decent way is through threats of punishment or reward. And, you know, this is one reason why we have prisons. __It's one reason why we have, we have fines, some societies executions, because there're some proportion of people in the world where the only way they will act decently towards other people.__ The only way other people's feelings and emotions will count is if they know that if they don't act that way they themselves are going to be hurt. They are going to have their money taken away from them. They are going to be put into a cage. They are going to be killed. 

Now, this is just a way of introducing an idea argued by David Hume and other philosophers that In order to get morality off the ground, in order to be motivated to do good things and not bad things, you need to have some spark of feelings. __You need to have other people have to matter to you. If not, you're no better then the psychopath.__ And we can take this insight and turn it around. And say, look, since we have morality, since most people listen to this. Do have a sense of right and wrong. This means that we must have had some spark of compassion, some of these feelings. We are not inherently psychopaths, and this makes morality possible.

Now, the point, the idea that people have fundamentally kind thoughts towards others, that would regard others with some degree of caring and compassion, is an old one. And it was articulated, I think, most clearly by Adam Smith in, in, in his writings in the 1700s. Now, some of you may know Adam Smith as the founder of modern economics. He wrote this classic book, an inquiry into the, wealth of nations, into nature and cause of wealth of nations. which, in which he argued he defended in part a somewhat free market. He defended the idea that self-interested agents working just for their own benefit can in some societies have things work that things end up for the benefit of everybody. goodness, emerges as through the invisible hand as an emergent property of self-interest and greed. 

But it's easy to misread this as saying that Adam Smith himself thought people were greedy and self-serving. And nothing could be further from the true. So wealth of nations was Adam Smith's second book. His first book which he said was his finest book, was The Theory of Moral Sentiments. And this is a brilliant discussion of our natural inclinations towards sympathy, towards kindness, sometimes towards punishment and justice and vengeance. And he begins this book with a couple of, a few sentences I think eloquently capture a lot about human nature. 

So, he writes. However selfish soever man may be supposed, there are evidently some principles in his nature, which interest him in the fortune of others, and render their happiness necessary to him. That we often derive sorrow from the sorrow of others, is a matter of fact too obvious to require any instances to prove it. So Smith says he doesn't need any examples, and I am not going to provide any examples. I'll ask you to provide your own. So imagine, imagine a person you love in the world, could be your, your child, your boyfriend, girlfriend, husband, wife, your best friend, your, your, there must be somebody. And imagine that person in sorrow, imagine that person is suffering. How does that make you feel? Now, if your answer is meh, I'm fine. Then you're a psychopath, then, then you're one of the small proportion of people who, who may well lack fellow feeling. 

But most of us would say, wow, I don't want that to happen. I don't want somebody I care for to suffer. I want that suffering to go away. And, and so this seems to be sort of a fundamental aspect of ourselves. Now one can reasonably ask, and is a, I think an extremly interesting scientific question, where does this come from? Why do we care about others? What happens to us or has happened to us that causes us to care about others? 

And one common enough view is that we're not born that way. We're born entirely cold blooded. But it's not an idea that I believe is right. I think that right now, enough, enough of, there is by now, enough of a body of evidence from studies and observations of babies and young children, to suggest that, on some degree compassion shows up early. 

So, one finding for instance is a baby's crying. So, how do you make a baby cry? Well, there's a lot of ways to do this. But one way to do it which is pretty powerful, is expose the baby to the cries of other babies. The baby will hear the sound of other babies and then start to cry, him or herself. Now some very cynical psychologists have said, well that doesn't show anything. Maybe babies are so stupid that they hear the sounds of other babies crying, they think they themselves are crying, this panics them, so they cry some more. But then even more clever psychologists did another study, where they expose babies to the sound of crying babies and these were tape recordings, either of their own cries or other babies cries. And they find that babies get upset more at the sound of their own cries than at the cries of others, suggesting it really is some sort of outer directed feeling. And this is supported in different ways. We know that babies when they see someone else suffering as soon as they're able to might pat and soothe the other person to try to make them feel better. And we know that toddlers will start to share and help those around them, particularly those they are familiar with and those that they care about such as their siblings and, and, and, and maybe their friends. It's not it's hard to disagree then, with Adam Smith's claim that some compassion, some fellow feeling is part of our nature. 

Now there are a lot of open questions. You might ask how would this develop over life span. You might ask, okay part of it maybe is hard wired, how could this evolve? Is it shared by other animals like chimpanzees and monkeys? You might arg-, wonder about the extent to which it varies across cultures. Are some people in some societies more compassionate than others? You might you might wonder to what extent is this compassion pure? Or to what extent it sort of regulated by self-interest, by selfish priorities. And those are all great questions. And in fact those are the sort of questions we're going to be dealing with throughout the rest of the course. But I want to turn now in the next lecture to the limits of compassion. So we've talked so far about our feelings towards those around us, what about our feelings towards strangers?

## 2.2: How Do We Treat Others?

I agree with Adam Smith that we have compassion towards those we are close to. I think he's right that you don't need any examples to show that. But when it comes to strangers, the issue is quite a bit more complicated. And actually the theme of how we think about strangers, and the way our moral psychology interacts with strangers, is to me so interesting and is important, that we're going to return to it over and over and over again, in the lectures that follow. But I want to to introduce the idea, here. And I want to sort of, for us to consider how we think about strangers, and, to, to, to introduce this idea, I'm going to give a lecture in four parts. 

So, the first part is an observation, and it's an observation by the primatologist and anthropologist Sarah Hardy. And Hardy, at the beginning of her wonderful book, Mothers and Others, describes being on an airplane. So she had been through security, she had been groped by the TSA agent, she's kind of crabby, she's sitting in a seat, she's, and, and, and the food is coming, you could smell the food, you could hear people in front of you getting it But she's, but it hasn't got to her yet. And somewhere on the plane, a baby starts crying. And people roll their eyes, and they're stuck together. And to pass the time, Hardy writes, I cannot help from wondering what would happen if my fellow human passengers suddenly morphed into another species of ape. What if I were traveling with a plane load of chimpanzees. Any one of us would be lucky to disembark with all 10 fingers and toes still attached. With the babies still breathing and un-maimed. Bloody earlobes and other appendages would litter the aisles. 

Compressing so many, highly impulsive strangers into such a tight space, would be a recipe for mayhem. Yet millions of us, billions of us, fly each year. And it's very rare that the plane lands and then they open up the doors and it's coated with blood and body parts and everything. We behave, we sit quietly, we wait our turn. And this is, this is extraordinary. This is an unusual response to strangers. As Hardy points out, chimpanzees and other primates, our closest evolutionary relatives, are nowhere near as nice. The response to dealing with the seen strangers, if you're a non-human primate, is often panic, is often aggression. But not for us. We are able to cope with strangers, we are able to inhibit our violence, our aggression, our frustration in the presence of strangers, and that's the first observation. 

The second part of this lecture, discusses how it's even better than that. It's not just that we don't want to kill other people who we were not used to. Rather is that, to some extent, we resonate to them, and we want to help them. And I think the, the clearest examples here are the internet. So any of us who spend a lot of time on the internet, and the fact you're watching me suggests you spend some time on the Internet, spends a lot of time dealing with strangers. Spends a lot of time dealing with people who aren't your friends, aren't your family. You never met them before. Yet we often have these productive, complicated interactions with strangers that aren't obviously self-serving. 

Now admittedly some of these interactions are not necessarily compassionate. Sometimes they're aggressive. Many people spend a lot of time on the internet arguing with strangers. This classic XKCD comic indicates the fact that it is extremely frustrating to deal with the somebody on the internet who is wrong. And there's a tremendous impulse to correct them. And the comment section on blogs refelcts this very human implulse. I wouldn't want to call that compassion, but there's a lot of what seems very cleary to be compassion and, and one example of this is sites with reviews. I'm thinking of Amazon and TripAdvisor, Travelocity, Yelp. These are sites that describe things like books, or products or restaurants, and then people come in and they, and they review them. And they tell you what they think of them. 

And, now some of these people may be motivated by gratitude in some way. When there is a negative review, you could say is revenge or vengeance. But for most part, people are going on to say, oh, I really like this show and what they're telling you is, they are, they are doing something for you. They are doing you a favor, but they don't know you. And this is altruism for the strangers, and it's a, it's an extraordinarily interesting fact about human nature.

When giving lists of irrational, not self serving behavior people often describe tipping. So, it's one thing to tip in a restaurant you're going to come back to because the size of your tip could affect your own, how people think of you, how people respond to you. But people leave tips in a restaurant they know they'll never going to go back to. They put money on the table. and, and even though they'll get no benefit from it. Or as an even more extreme case, think about, hotel rooms. And this varies from culture to culture. But there's, th, th, there's a custom in which I was raised in, that you're supposed to leave a tip when you leave a hotel room. So you, you know you pack up and everything and you put some money down. You maybe write a note that says thank you. The interesting thing about this is, this cannot conceivably help you in any way. It's not like the people who clean the room are going to say what a wonderful guy. I'll go back and do him a favor one day. They don't even know who you are. Yet we are compelled to do this. We might feel embarrassed if we forgot. We may feel ashamed of ourselves. We may feel proud of ourselves if we do it. And this goes to show that our morality is plugged in, in an interesting way, towards our interactions with people who we don't know, we will never know, we will never meet again. 

There's charity. People give an enormous amount of money to charity. Now, some of these charities are self-serving in a way. If I give money to support a museum that I myself am going to enjoy. Sometimes, the impulse to give to charity, may be an impulse to enhance our reputation, to show ourselves off as good people. Oh, look at, you know, I am donating this amount of money. I get my name listed in some program and people say, what a great guy he is. But some of our charitable acts are none of these. People give money to international charities to help starving children, and we often do this anonymously? No feedback, nothing. We do it because we feel it's right. We are compelled, we do this because we feel it's right and because we care about other people, again, people we will never see. 

This was this was the topic of a wonderful experiment by Stanley Milgram. And what he did was, he had letters made up. They were stamped, addressed letters. And so he made them up. And they'd say, with a person's name, I forget the name, you know? Joe Smith and an address. And he went through the streets of New Haven, or had his students do it, and would drop them. Or he'd put them up on a windowsill. Or he'd slip them under a door. None, none of them ended up, he didn't put any of them in a mailbox. So here's the question. How many of them would get, would be sent? They knew where they were sending them. They had to check the mailbox where it's supposed to be sent to. How many would be sent? In order for them to be sent, somebody has to pick up the letter, say oh, here's a letter. Go to a mailbox and drop it in. That was well over half. Well over half of these letters arrived at their destination. And this means that people must have picked up the letter and said, oh gosh, this is a letter that somehow went astray and put it in a mailbox. Again, an act which will do, which leads to no self-serving benefit. But it's simply done in some sense out of the goodness of your heart. Now if your cynical you might say maybe there's employees of the city or maybe people just automatically did it. 

But Milgram did something clever. Some of the letters were addressed to a person. Some of the letters were addressed to an organization that he felt people wouldn't like. So some of the letters were addressed to friends of the Nazi party. When they had that address they didn't arrive at the destination. So, it's not that they were indiscriminately looking at it and throwing it in a mailbox. Rather people were making a decision. And if it was for something which they didn't think was good, they wouldn't send it. 

There was even another study done by Dan Festler in California, where he looked at different things. But one of his conditions was, he did the same study as Milgram, except he didn't put a stamp on the letter, he just addressed it. Now most of those letters did not get back. But about 10 to 20% did. Which means people picked up a letter said oh, here's a letter for somebody it has no stamp. They went, they got a stamp, they put on it, and they mail it. And I think this is just extraordinary, I think this says something very interesting with how we work. So call those two stories the bright side of things, that's the positive side of our feelings to strangers. 

But there's also, as you could imagine, limitations about our compassion to strangers. There's, there's limits as to how much we care about them compared to how much we about the people around us. And the third case I'll give you is, is actually part of a comedy routine by Louis C K. This is unusual because it's the only Louis C K excerpt in which he doesn't swear. But he says something very interesting about our relationship to strangers. 

_My life is really evil, like I, there are people who are starving in the world, and I drive an Infinity. That's really evil. There are people who just starved to death, that's all they ever did. There's people who are like born, and they go, I'm hungry, and then they just die.  And that's all they ever got to do. And meanwhile I'm in my car, boom, boom like having a great time and I sleep like a baby. It's totally my fault because I could, I could trade my Infinity for like a really good car like a nice Ford Focus with no miles on it. And I'd get back like $20,000. And I could save hundreds of people from dying of starvation with that money, and every day I don't do it. Every day I make them die with my car._

Now Louis C.K. ends by saying, everyday I make them die with my car. And of course it's a joke. This isn't literally make them die. He doesn't literally kill them. He has no malice towards them. He's not acting to kill them. But in another level, it's not a joke. Another level, it actually reiterates a consequentialist argument that we've seen before. That one should judge actions based on their consequences. And from that point of view, if its true, that by buying a car instead sending the money to a charitable organization, if its true that this leads to the death of some kids, then Louis CK has killed them just as much as if he ran them all over with his car. 

Now this is a radical claim. It's a strong claim. It's in part the view of the philosopher Peter Singer who's a who is a consequentialist and who argues that we should judge our acts based on our consequences, and because of that, we should radically change how we how we treat people and, and, and our charitable giving. And he has a moving philosophical argument of which the conclusion is we should do more to help people in far away lands. And I have a feeling that, that Louie CK in his routine has actually drew upon the insides of Peter Singer. I'm going to present the argument right now. 

What's interesting is this argument, although it's been presented in philosophical journals and elsewhere, it's now presented as a Youtube video. So, this is the fourth and final case of how we think about strangers and it's expressed in this extremely interesting video. That's a political argument, it's a social argument. And, you may not believe it. You may object to it. You may disagree with it. You may endorse it, think it's very convincing. That's not the point here. My point is not to persuade you to do one thing or another. Those are your own decisions. 

But what I like about this video is that it illustrates certain things, certain psychological truths. And one truth it illustrates is that there's a psychological distinction between three categories of people. One category is the stranger in front of us. The girl we see, we know we don't know, but the girl we see drowning in the pond. The second category is an anonymous stranger, the one we don't see, the girl in Africa drowning in a pond. And then the third is the family member, our own daughter, our own mother, father, sister, brother, son um; and these are three categories of people and um; and we think very differently about them. And one insight is, when our natural reaction to them, is that we could care a lot about those in our life. People we love. People we, we interact with. And we are also driven to care a lot about a stranger, a drowning girl in front of us, as if seeing her triggers something. It triggers a sense of obligation. If I told you that I, I he'd, Singer never tries to make the argument we should help the girl in the pond. He just assumes it. And he's right to assume it. If I told you, I was rushing to work and there was a girl drowning, but I was kind of in an hurry, so I let her drown. You'd think I was a monster, and you'd be right. So you have on the one hand your feeling towards family members, your feelings towards people suffering for any. And then your feelings towards anonymous strangers. That's very different. We don't have the same pull. If I told you I knew about children in far away lands who were starving to death, who needed medical care, and I still bought a nice car, well, you might think I shouldn't be doing this, but you wouldn't think I'm a monster. In fact, most of us do stuff like that all the time. 

So you have these psychological distinctions. And this helps explain our moral reaction to a case we talked about in the very first lecture. So remember I told you the story, true story of these two guys who go in to the casino and one of them molests and kills the child, and the second one doesn't do anything. He just observes it, but he doesn't stop it. And later on he's interviewed on this, because they don't press charges, not a crime to just not help a stranger. If I walk past that drowning girl in the pond, I might end up saying morally wrong, but I haven't done anything legally wrong. And then he's asked, so what was up with that? And he says, the simple fact remains I don't know this little girl. I don't know people in Panama or Africa who are killed every day, so I can't feel remorse for them. And, you know, he's missing something. 

So he's actually right in his second claim. The people in far away lands if you're not in Panama, if you're not in Africa, you're not typically going to care about people who suffer there. It's okay not to do anything to help them. But that girl in front of you, the person in your vicinity, that person you should care about. Now, Peter Singer uses these psychological facts to make a moral argument. So he starts by saying he would help the little girl whose in front of you, and people watching you and say, yeah of course. Well, isn't that just the same, as if she was drowning in, in, in Africa? And then later on he says, oh, well maybe you think the girl in Africa is just a drop in a bucket. But what if she were your daughter? Isn't that the same? She's somebody's daughter. And so what you see here is an appreciation of our gut instincts. Singer is well aware that you don't normally think of the girl in Africa as we're saving, as we're sacrificing for. But he tries to argue through analogy that there's no real difference Between her case and the case, the cases where you do think you'd be right to intervene. And, among other things, this shows us the limits and the scope of compassion but it also illustrates moral argument. It illustrates how people could try to use reason, to try to use arguments, analogies, examples to change the way you think about the world. And I think this is deeply significant and it's another topic which we're going to continue to discuss, as these lectures develop.

## 2.3: Empathy and Concern

So, why would people matter to us? Where does compassion come from? You can imagine different possibilities. You can imagine people have compassion of a sort, just out of selfishness. It might be that your pleasure matters to me because in some way we're in the sort of a relationship where you being happy leads to be being happy. Maybe we're sort of business partners working together or something or we're in some sort of mutual benefit system, where your benefit is my benefit and your suffering is my suffering. I'll leave it for a question for later whether this even counts as compassion, but it's one source of nice behavior towards others. 

We might care about other people because of our religious code. You could imagine we care about other people because we believe that God wishes us to. We might care about other people because we are committed to some philosophical theory of morality of the sort we discussed earlier like consequentialsm or Kantian theory in which other people's happiness and feelings and goals matter to us. But many people have argued that a lot of what of goes on in compassion comes from our gut, comes from our heart. It is not a, it's not for self-serving benefit, nor is it because of our belief system. But, rather it's because we're wired up to care about other people. And the specific proposal as to what could drive compassion, and some people argue drive morality more generally, is that empathy plays an important role. 

So, let me define empathy. Empathy is based on a German word. The term is a new term, it was coined in the early 1900s, and it means to feel one's way into and when you think about empathy, you can think of it as being in someone else's shoes, putting yourself in someone else's shoes. 

Now, the idea that empathy plays a big role in, our morality and our compassion, is something again, you find in Adam Smith. So, Adam Smith argues that sort of foundation for caring about other people, is imagining yourself in their shoes. And he gives an example of how this can be, can be done. He says when, when we see a stroke aimed and just ready to fall upon the leg or arm of another person we naturally shrink and draw back our own leg or arm and when it does fall, we feel it in some measure, and are hurt by it as well as the sufferer. Now, once you start looking for examples of how empathetic connection, affects you, you can see them all over the place. 

Here's one of my favorite examples. It's, It's a picture from a wonderful book called Emotional Contagion and you can see the guy is tensing up in anticipated feeling of the pain of the needle of the child he's holding. And you know, I saw the movie Casino Royale, the James Bond movie a little while ago. And there's a scene where the character James Bond is shackled naked to a chair and then whacked in the testicles. And me and I think just about every other male in the theater is going oh, in vicarious pain. But it's not just pain, it's also pleasure.

Why would anybody enjoy watching another person laugh? Well, because somehow the happiness of the kid jumps from him to us and so it's hard to watch a video like that without being sort of cheered up a bit because we're naturally primed to take on the perspective and feeling of others. And in fact, when people develop theories of empathy, theories drawing upon psychology and neuroscience, they often see it as related to a more general, propensity to imitate other people, to be the people we are interacting with. Here is an example of the imitation. A soccer player has just missed a big kick and he, he puts his hand on both sides of his head. But now, look at the people around them. We imitate each other all the time. __There are studies showing that, when you have two people who are talking to each other, they'll unconsciously start to imitate the, the, the behavior of the other.__ My wife, when she's with her Texas relatives, she starts to drawl. And in fact, whenever you're talking to somebody with an accent, there's this irresistible temptation to start speaking that accent too. It's part of how we respond to other people. 

And it shows up like a lot of what I'm talking about, even in babies. __So, the developmental psychologist Andrew Meltzov, many years ago, found that, that babies are natural mimics.__ Here is a clip of him making different facial expressions and a baby making those expressions back at him. And you watch a mother or father with a baby, where you'll see is this sort of dance as it were, where one of them will make an expression other one will do it back and so on. Some people have argued that there's a specific neural system that underlies this imitation, underlies this empathy, known as mirror neurons. And mirror neurons were first discovered with, non human primates. And what they are is they're activated when you do an action like reach for something. But they're also activated, when you observe another individual do the same action. And this suggest that, that at some neural level there's no distinction between us and them. There's no distinction between you and another person. As we experience the, the, imitate the motor movements of another person you could feel a connection to them and this imitation could itself drive, drive empathy. 

So, one demonstration of this involves facial expressions and here the excellent works been done by the psychologist Paul Ekman. So, Paul Ekman points out there's certain universal facial expressions. Humans all around the world have them. And I've shown some of them here. They're, you go around, the list there, anger, fear, disgust, sadness, happiness, and surprise. These are universal. But what's interesting is two things. One thing is you'll naturally mimic someone's facial expression. So, if you're sitting across from me and I'm frowning. You'll start to frown. Also when you imitate the expression, due to the facial feedback that, that, that ensues you'll start to feel the same feelings that I'm feeling. So, if I'm really happy and I'm grinning like a idiot, you'll start to grin like an idiot and if you grin like an idiot it'll make you happy. Some of the most annoying advice you can tell a depressed person is you should smile more. This is incredibly annoying but it's true. It's true for two reasons. One is, if you smile people will smile back at you and they'll like you more. But the second one is, and there's, there's laboratory studies on this, the very act of going like this, of moving the corners of your lips upwards triggers the feelings typically associated with smiling, that is, happiness and smiling in some small way, boost your mood. It might be parenthetically that that is mirroring of, of others and, and our propensity to do so and the pleasure we get from doing so, could exlpain some mysteries of human psychologies. 

And these are mysteries that go quite a bit beyond the questions of morality we are interested but I can't resist talking about it here. So, I am going to show you a little clip. I am going to show it's, I'll show you one minute of this clip, and it's from a series of videos called, Where the Hell is Matt. Where this sort of non-descript guy dances to music with different people across the world. So, I show you this clip, the last like, minute, minute five seconds and as your watching it, monitor your own, for example monitor what your doing. And second, monitor your own feelings. We were all dancing here, me, the camera guys, everybody. That's one thing. One thing is upon seeing this, you'll be tempted to move with it. This is most extreme in children. My sons and I, when they were younger, we'd watch a lot of kung fu movies together. And they can't watch a kung fu movie without leaping up and kicking people and things, and so on. It's just irresistible. But second, not only are you tempted to move with it, but often there's some sort of warm feeling associated with it, some human connection. And this illustrates how other people's movements and your movements, and your propensity to imitate these movements lead to sort of connections of feelings, and connections of positive feelings. And this could be viewed as a manifestation of empathy. 

So, let's step back. You have concern for others, other people matter to you. And you have empathy which is putting yourself in other people's shoes. And you can do empathy through an act of imagination. You could think I wonder what it's like to be her and think about that. I wonder what, what his experience is like. But you could also do it viscerally by seeing another person, act in some way. The theory worth taking seriously then is that empathy is a spark for compassion. And it's not hard to see how this could work. 

Let's assume, because it's true, but it's kind of obvious, that I don't like feeling pain and so if I feel pain, I'll want to stop that. But let's also assume that if I see you in pain I'll feel your pain empathy, and I'll want to stop that. Because by stopping you from feeling your pain, I'll stop me from feeling, my pain. Suppose I see you happy and that makes me happy, I'll want more of that because I like being happy. You can say that empathy dissolves the boundaries between yourself and another person. And so, this predicts that when you are in empathetic state with somebody, when you are taking their persperctive, you will adopt their interest. You will care about them. You will feel compassion and concern. And there is a fair amount of evidence that this is true. 

A lot of work comes from the psychologist Dan Batson. And Batson has done dozens of studies, perhaps hundreds of studies by now, where he, he gets people in a situation where they have to choose whether to help somebody or whether to care about somebody. And he finds that if he can get them to feel empathy, to see it how they feel, to see it how, how the other person sees it, to feel it as the other person feels it, the odds of them being kind and caring go up. So, for instance, you could tell a story about a girl who is in line for a life saving operation, and there's other people ahead of her, and then if you just ask the person, ask your experimental subject, try to take this girl's perspective, try to see it as she seen it. That raises the odds your willing to take that girl and move her up to the front of the line, that you're willing to rescue her. Because the shared feelings motivate compassion. They motivate caring. In general, this effect, the fact that empathetic connections with individuals boost up your feelings towards them is the spark of what sometimes called the identifiable victim effect. 

__The identifiable victim effect is the idea that we care a lot more when there's a person in front of us than some numbers.__ And, and this is something which has been observed by many people. Joseph Stalin apocryphally said, a single death is a tragedy. A million deaths is a statistic. Mother Teresa said, if I look at the mass, I will never act. If I look at the one, I will. And there is actually experimental work done demonstrating this, so, there's, a series of wonderful studies done by Deborah Small and Paul Slovic and George Loewenstein, where you give people the facts, you give people data about a crisis, involving numbers and hard facts and you see how much they care. And, and how much they'll donate. And in this example where they throw out a lot of statistics at people, your average person hearing it will give about a dollar. But then another group, you tell about an individual, an individual with a name and with a face. And this bumps it up considerably. There are some studies that find that you will care more and give more to save one person with a name and a face, than five people who you are not told their names and you are not shown their faces. And this I think shows the power of empathy. 

Now, nothing that I'm saying would be a surprise to those who spend their lives trying to get people to give to charities. __So if you look at the, at the ads for charities, they don't say, okay, here's our charity, here's the statistics, here's the data, here's the graphs, and so on. They'll show you a picture. They'll tell you about an individual.__ I know this from personal experience. When I was in graduate school, I was extremely persuaded by Peter Singer's argument which I talked about in a previous lecture. That we need to give much more to charity, that, that we are doing something wrong by not, by, by spending money on luxuries instead of giving the money to save people's lives. I was very persuaded by this and still am kind of. And I would tell this to my friends. I tell this to my fellow graduate students, and, and you know, we'd be out for a beer and we'd be drinking a beer and I would say you know that beer could save a child's life. And, and you are murdering a child, and me too, by drinking these beers. And at one point one of my graduates, one of my friends who was a graduate student, a philosopher actually, got really sick of me. And he said, how much do you give to charity? And I was sort like well, dude, it's a philosophical argument here. But I thought, well nothing, actually. And I was poor graduate student, but I was much richer than the people I was concerned about. So, I decided I should give money to charity. 

So, I sent away, and this is pre-internet, so I sent away a postcard to an organization, Child Reach and asked for information. And I remember getting the packet and I remember opening up the packet. And I remember expecting to see a lot of information about what their charity does and how they work and where the money goes and so on. But they were much smarter than that. I open up the packet, and there in it was a picture wrapped up in plastic of a small child. And the letter said, Dear Mr. Bloom, we know, we know you have not commited to giving us any money. We know, we know you're just asking for information and that's, that's fair enough. But, but we have enclosed a pictrure and then he told me that this is, and he told me the child's name. And they said, we know you are not committed to giving us money. But if you do give us money, this is the life you will save. 

And that is psychologically so much more powerful than, than data and then facts. And, and, and actually my family's still sending money to that, to that child and his family many, many years later. Now you, you could argue further that the kindness the boost we get from empathy is, can motivate kind behavior not just to individuals but to the groups that the that those individuals belong to. And this is a claim defended by the philosopher Martha Nussbaum. So, Nussbaum writes, talking about Greek tragedies, although all of the future citizens who saw ancient tragedies were male, they were asked to have empathy for suffering of many whose lot could never be theirs, such as Trojans and Persians and Africans, such as wives and daughters and mothers. And her argument is that one of the things fiction can do, fiction, also journalism and stories, movies, T.V. shows, is they can put you, get you to have empathy. Get you to put you in the shoes of those who you wouldn't otherwise be, be with. And by doing so, you might care not just about, about that individual, that fictitious individual, but rather the group that the individual belongs to. 

My own bet is that feelings in America towards, homosexuals were radically affected by situation comedies like Will and Grace, which showed gay people in a positive way. Made you root for them, made you care for them, put yourself in their shoes. Attitudes in America towards African-Americans, I think, were transformed by shows like The Cosby Show, which again put people in the shoes of these, these African-Americans who were perfectly fine and fun and enjoyable, and people you could sympathize with. And then the sympathy expanded to the group as a whole. 

Now, this is largely speculation. But we do know, historically, that there are cases where fiction has caused interesting and important moral changes. And one example has to do with Harriett Beecher Stowe. The story goes that, Abraham Lincoln invited her to the White House at the beginning of the Civil War and said to her, so you're the little lady who's caused this great big war. And he was talking about Uncle Tom's Cabin, and Uncle Tom's Cabin is not a book of great philosophy or legal reasoning or, theology or morality. It's it-, it, it's fictional. But what it does is, it get, it got the readers who were predominantly white people, some of whom were slave owners, to put themselves in the shoes of of slaves and see what their experience was and by doing so, served as a catalyst for moral change. So, I have argued that empathy could be a force for morality, both at a individual level but also maybe as at the group level too. 

In further support of this, I think we could look now at precisely what's wrong with people who don't care about other people. People who lack compassion. And this brings us back to psychopaths. So, psychopaths also known as sociopaths, you can use what ever term, they're not sensitive. They're typically male. To be a psychopath is defined by all sorts of characteristics. A clinical psychologist named Hare developed a psychopathy test. If you're curious about yourself you could take it online. Psychopaths tend to be selfish, they're callous, they're impulsive, they're promiscuous and have a deficit in normal feelings. They have a deficit in love and loyalty and guilt and shame and anxiety. They tend to be cold blooded characters. Psychopathy comes in all sorts of flavors. In some extreme cases you have these cold blooded psychopaths who are also very violent people. And these people cause so much of the misery in the world. 

I'll give you a few quotes to give you a feeling for psychopathy. you, by the way when you think of a psychopath you may well think of Hannibal Lector. Who is a classic Silence of the Lambs psychopath. But I tend to think of James Bond to show you that they're not all necessarily bad guys. Some of the psychopaths might be on our side. But James Bond also fits many of the characteristics. The Daniel Craig James Bond, not the Roger Moore James Bond. So, so, how do psychopaths talk? How do they think? Well you have to use extreme examples one of them which was reported by Damon in his book on morality is of a 13 year old who who would mug blind people. And he'd mug blind people because he figured they couldn't identify them, him later. And he was then asked later on, so you know, don't you care about the people whose lives you destroy, the people you assault? What about this woman you just attacked? And his response, I think, perfectly captures what a person is like without compassion. 

He said, what do I care? I'm not her. And in some way that's a good argument. You're not her, why should you care? Well, because humans normally are usually wired up to care, but it's hard to figure a logical argument, why you should. Ted Bundy, who was a serial killer, was once, once in a, in an interview while in prison, expressed surprise at the fuss that was made, on, that all of his murders. He said at one point, you know there are so many people, he was kind of puzzled why people were so concerned. And, one of the creepier examples, and this is from Jon Ronson's excellent book The Psychopath Test, is a guy named Peter Woodcock. And and this guy he he had raped and murdered 3 children and ended up in a psychiatric facility for the rest of his life. But he did get a three-hour leave to walk around the grounds after some years of good behavior. In the course of this, he invited a friend of his who was also on this leave to join him for a walk, and then killed his friend with a hatchet. So, he was asked, interviewed later about this event. And, and here's how he described it. So, the interviewer says, asks, what was going through your mind at that time? This was somebody you loved. And the psychopath answers, curiousity, actually, an anger, because he had rebuffed on my advances. And why did you feel someone should die as a result of your curiosity? I just wanted to know what it would feel like to kill somebody. And the interviewer asks, but you had already killed three people. And Woodcock replies, yes, but that was years and years and years and years ago. 

So, what's wrong with psychopaths? __Well, one answer is, that among their many deficits, they don't have normal empathetic feelings, towards others.__ They don't feel other people's pain, they don't feel other people's pleasure. And because of that the suffering that they caused doesn't come back at them, it doesn't resonate. Some people have argued that along with all of their deficits including empathetic deficits there's something very specific, very specific that's wrong with them. And this comes from the work of the psychologist Abagail Marsh. So Marsh did a series of studies where she took psychopaths who were in her lab and she showed them a series of faces. And the idea is you have to identify the face. What emotional expression, you, correspondents to that face. So, they would look at the face, on the, on the upper left and say, boy that woman looks angry, and they look at the face of the guy in the middle bottom and say that's one happy guy. __But there was one sort of face, that they had a lot of problems recognizing. That is, they would look at that face and they wouldn't have the foggiest idea what the person was feeling, though for a normal person, it was it was obvious. So, the face I'm talking about is in the top middle. It's fear.__ And Marsh argues that psychopaths have this specific deficit, empathizing with the fear of other people. She tells a story of, of, of a study, an interview, with actually a female psychopath, who identified all of the faces easily, except could have no idea what fear was. And then, finally, it came to her, and she said,' I don't know what that expression is called, but I know it's what people look like, right before I stab them. And I'll end with that.

## 2.4: Empathy and its Limits

We began by talking compassion, about other people mattering to us. And what we did in our last lecture is we looked at empathy. Putting yourself in another person's shoes. And we explored the extent to which empathy can drive compassion, and can drive morality more generally. And I actually think any complete theory of our moral life has to draw upon empathy. Has to draw upon this putting ourselves in another's shoes? But I also think it's a lot more complicated than that. I think that there are limits to empathy. There are limits to empathy which make it unreliable and untenable as a source for morality. To put it differently, to the extent we're good people and we live good and moral lives. Sometimes we will rely on empathy but sometimes we'll reject empathy. So, why do we want to do that? 

Well, one thing is, empathy is biased. we, we feel a lot more affection, a lot more empathy for a, a, a kitten than for a piglet. We feel a lot more empathy for a panda than for a chicken. This is not because of a deep reason moral argument about suffering and pain and intelligence and feelings. It's because some things are adorable, some things trigger our emotions. But part of what it is to be a moral person is sometimes overriding the fact that, that we feel warmly towards this but not that and ask ourselves deeper questions having to do with suffering and pain. Maybe you're not convinced. Maybe you think we should rescue the kitten, no matter what. 

But what about people? So, I don't think there are many people who will defend this, which is that in the courtroom, ju-, juries are particularly biased in favor of defendants who are physically attractive and who are baby-faced. Because our emotional response to attractiveness and baby-facedness, the looks of youth, is innocence, is innocence and sweetness and compassion. But surely somebody who is ugly and kind of griseled deserves just as fair a treatment. So, it seems there's an unfair world in which a young Leonardo DiCaprio would be acquitted of any crime, because of how his face resonates to us. More generally I think part of what goes on when we make a correct moral decision involves overriding our empathetic feelings. And in some cases, it's pretty clear that empathy could drive us not just to the incorrect choice, but actually to a straight-out immoral act. 

In part because it could pull our attention towards the one and away from the many. so, so, remember the study I told you about before saying, that we could more about one person than about five people. Particularly one person if you could see that person. But that's crazy. That's morally crazy. We shouldn't be swayed. Everyone has a face. Everybody has a name. Providing a name and a, and a, and a face sways us, but that's not the way it should work. If you think for minute that, that, that the way to be a good person is try to help the most people, then will often lead you astray. 

And actually one of the studies by Dam Batson illustrates this. So remember, we talked about his study where there's a girl, and she's waiting in line for an operation and if you take her perspective you move her up the line. But as Batson points out nobody think's it's the right thing to move her up the line. Nobody thinks, say for a list of people waiting in line for a heart transplant, you should walk and look at all of them and whoever inspires your feelings the most you should give em the heart transplant first. That's not right, it's not right because what inspires your feelings has to do with things like attractiveness and baby-facedness and whether the person's the same color, whether the person same background as you. What you want to do to have a moral system is, you have a system that, that, that doesn't take certain things into account. That is based on, on reason and not, and not gut feelings. 

Now, these are examples where empathy is biased and empathy could lead you astray. But there's also another argument, which is that for a lot of what's core to our morality, empathy is not enough. Empathy is limited. And I'll give you a few examples of this. One is example is sort of is, is kind of particular, but I think it's telling. It, it, it is something pointed out by William James. So James talks about our relationships with our dogs. Many people have dogs as pets. They feel very affectionate towards them. They, they, they love them and they care about them. But James points out, this is not a relationship that's founded on empathy. If my dog, I don't know whether my dog ever tries to take my perspective. Here's here's me and my, and my, my dog. I don't know if she ever tries to take my perspective but I don't think she does. And if she does, I don't thinks he would have any understanding of what I do all day which is mostly sit in front of the computer and go like this. And I don't really take her perspective very much either because her life is a mystery to me. She seems to spend all of her voluntary time sniffing at disgusting things and trying to eat disgusting things and it's just strange. And yet, and yet I care a lot for her. And I'd like to think she cares a lot for me. 

And James' point is, that you would have a, you know, a personal relationship, relationships founded on love and compassion without empathy. Consider again, as maybe a more salient example, ones relationship with ones baby. Soon empathy emerges and, and, and, and there's a synchrony and so on, but from the get go there's none of that. But still there can be an enormous amount of love. A lot of this sort of personal ideals, that matter to us most, don't have as much to do with empathy as one might first think. Now empathy is a particular, sorry, is particularly weak, when it comes to our finest moral ideals. When it comes to more general policy, and particularly when it comes to our treatment of strangers. And some of the weaknesses of empathy are nicely summarized by Steven Pinker, in his wonderful book Better Angels of our Nature, which we'll talk about later on in the class. So Pinker writes, I can't say that it's empathy that prevents me from taking out contracts on my critics, getting the fistfights over parking spaces, or threatening my wife when she points out I've dong something silly. My mind doesn't stop and ponder what it would be like to be the victims of these kind of violence and then recoil after feeling the victim's pain. Rather, my mind never goes in those directions in the first place. Pinker goes on to say that, you know, the Old Testament says you should love thy neighbor. The New Testament says you should love thy enemy. But frankly, he doesn't love either one of them. He loves the people he loves. But most of the world, his neighbors, his enemies and so on, he doesn't love them at all. And I, I don't love my, most of my neighbors and my enemies either, but we are moral towards them, we don't kill them. In some situations we will help them, we will sacrifice to help them.

And this shows that feelings have their limits. That, that sometimes our morality is grounded in, not in gut feelings, but in moral principles. And the importance of moral principles, the importance of moral reason, and the limits of gut feelings, are actually nicely illustrated in a story told by, yes, by Adam Smith. And I'm going to present his story. I'm going to modify it slightly for a more modern age. Imagine you learn about a death of sa-, thousands of strangers. Imagine you learn it, I mean Smith wrote in the 1700s, but imagine you learn yourself, right. You open up your computer, you put on your computer browser, and out comes some new stories. And one of news stories is in a country that you don't belong to. India, Argentina United States you know, Australia. Some place you don't know about. Some place that is not where you are. Thousands of people died. They died of a salmonella epidemic, they died of an earthquake, they died of, of a factory fire. How would you respond? Well, this actually isn't so strange to you, because if you open up your browser every day, thousands of people often die. So how do you respond? Well, I bet, I bet you, you know you say, oh, well that's too bad. That's unfortunate. Then you go about your business. 

And Adam Smith says that, that when exposed to the death of thousand of strangers. We will remark our disapproval, and say, oh, how what a terrible world, and then we will go on our life, and that night we will sleep with the most profound serenity. Now, imagine something different. Imagine instead, you were to learn that tomorrow you are going to lose your little finger. You can't see, so this is Smith's example, that tomorrow there going to chop off your little finger. You would say wow. You would say, wow, you would say, that's terrible. That's, that's, how am I going to, are they going to anesthesia? Which finger, which? How are they going to, why? What? And that night you wouldn't sleep a wink. So plainly, from a gut feeling, from an emotional response, the loss of your little finger matters more than the death of thousands of strangers. So this raises a question then, and a question is this: Since it matters so much more, this loss of a finger than the death of a thousand strangers. Would it follow that someone would sacrifice thousands of lives to save his little finger? 

And Smith writes, human nature startles with horror at the thought. His answer is no, nobody would do that. Look I'll even change the example. If you're extremely fond of your little finger maybe you would do that. I'll change the example. You discover that thousands of people are going to die, you say, oh, how sad, they've died, how sad, but also you notice your computer is slow. Your browser is slow. It's very frustrating. It's slow, it's unreliable, maybe your connection's fading in and out. It does not seem implausible, in fact it seems true, that that slow connection's going to bother you a lot more, than learning by the death of thousands of people. But still, if somebody, if you were offered then to speed up your connection, but thousands of people would die, you would say that's insane. 

So, here's the question then, and this is a question asked by Adam Smith. When our passive feelings are almost always so sordid and so selfish, how comes it that our active principles should often be so generous and so noble? And Smith continues, it is reason, principle, conscience; this calls to us, with a voice capable of astonishing the most presumptuous of our passions, That we are but one of the multitude, in no respect better than any other in it. And this last phrase sums up morality. What a sophisticated morality is goes beyond gut feelings and selfish urges and desires to help people. But it also includes an understanding that we are but one of the multitude, in no respect better than any other in it. 

__And what you see in moral systems all around the world, from religion, from philosophy, is an appreciation that a moral code doesn't care about you as special.__ A moral code says, you're not special. It says that we have to figure out how to live our lives such e-, e-, in a way that would somehow apply to everybody. So this shows up in all of the versions of the golden rule. And all of Confucian statements about impartiality. It shows up in the consequentialism that we talked about, where the, the right way to live is to try to increase overall amount of pleasure and decrease overall amount of pain. It shows up in in Kant's categorical imperative. Where you should have a principle that applies to everybody that would make the world better all around. It applies to theories like John Rawls' Veil of Ignorance or Adam Smiths own Impartial Spectator. Now, it might sound like this is some sort of technical idea that, that only, you know, gurus and, and, and great intellects could think about, but in some sense, this is, this is a common sense that's accessible to all of us. We all appreciate that the right thing to do is often not about appealing to our gut and appealing to our immediate feelings and prejudices, but, but also to, to take the bigger view. 

And my favorite summary of this is from Rick Blaine, the character played by Humphrey Bogart in Casablanca. And so the movie ends, sort of spoiler alert because I'm going to show you a clip. The movie ends with him talking about a sacrifice he must make, he and his, and his lover must make and why they must make it.

> But it doesn't take much to see that the problems of three little people don't amount to a hill of beans in this crazy world.

That is an astonishingly rich philosophical statement. And the fact that we could understand it, that we could understand that the problems of three little people don't amount to a hill of beans, compared to everything else that's going on shows that we're moral creatures. And making this sort of argument and extending this sort of argument back and forth to each other, is an example of how reason could play a role in our moral lives. So I started off, in the last week, talking about the power of gut feelings, the power of emotions and morality. Providing demonstration after demonstration after demonstration of how emotion shapes our moral reasoning and our moral action, and yet all of that's true. But now we're starting to encounter the power of reason. The power of reason that says that, yeah I know I favor this over that. I know I'm empathetic towards that, this rather than that. I know my selfish desires go for this rather than that. But I recognize that it's wrong. I recognize that there are higher moral principles at work, there are higher moral principles at stake. I may be happier if I save my little finger and a thousand people could die and but know that, that's wrong. I know that that's wrong because I know the people, the, the thousand other people are sons and fathers and mothers and daughter just as much as I am and the people I love are. And a appreciation of both the power of the emotions and the power of reason and rationality leads us to I think a more sophisticated understanding of what goes on in our moral lives. And I think now focusing on the interplay of emotion and reason, makes moral psychology a lot more interesting.

## [Readings: The baby in the well](http://www.newyorker.com/arts/critics/atlarge/2013/05/20/130520crat_atlarge_bloom?printable=true&currentPage=all#ixzz2s2suukaX)

Obama said that it is important to be able “to see the world through the eyes of those who are different from us—the child who’s hungry, the steelworker who’s been laid off, the family who lost the entire life they built together when the storm came to town.” He went on, “When you think like this—when you choose to broaden your ambit of concern and empathize with the plight of others, whether they are close friends or distant strangers—it becomes harder not to act, harder not to help.”

__Batson has found that simply instructing his subjects to take another’s perspective made them more caring and more likely to help.__

Some of the same neural systems that are active when we are in pain become engaged when we observe the suffering of others. Other researchers are exploring how empathy emerges in chimpanzee and other primates, how it flowers in young children, and the sort of circumstances that trigger it.

This interest isn’t just theoretical. If we can figure out how empathy works, we might be able to produce more of it. Some individuals staunch their empathy through the deliberate endorsement of political or religious ideologies that promote cruelty toward their adversaries, while others are deficient because of bad genes, abusive parenting, brutal experience, or the usual unhappy goulash of all of the above. At an extreme lie the one per cent or so of people who are clinically described as psychopaths.

Emily Bazelon writes, “The scariest aspect of bullying is the utter lack of empathy”—a diagnosis that she applies not only to the bullies but also to those who do nothing to help the victims. Few of those involved in bullying, she cautions, will turn into full-blown psychopaths. __Rather, the empathy gap is situational: bullies have come to see their victims as worthless; they have chosen to shut down their empathetic responses.__ But most will outgrow—and perhaps regret—their terrible behavior. “The key is to remember that almost everyone has the capacity for empathy and decency—and to tend that seed as best as we possibly can,” she maintains.

Empathy has been the main driver of human progress, and that we need more of it if our species is to survive. Ehrlich and Ornstein want us “to emotionally join a global family.” Rifkin calls for us to make the leap to “global empathic consciousness.”

This enthusiasm may be misplaced, however. Empathy has some unfortunate features—it is parochial, narrow-minded, and innumerate. We’re often at our best when we’re smart enough not to rely on it.

Why do people respond to these misfortunes and not to others? The psychologist Paul Slovic points out that, when Holloway disappeared, the story of her plight took up far more television time than the concurrent genocide in Darfur. Each day, more than ten times the number of people who died in Hurricane Katrina die because of preventable diseases, and more than thirteen times as many perish from malnutrition.

There is, of course, the attention-getting power of new events. Just as we can come to ignore the hum of traffic, we become oblivious of problems that seem unrelenting, like the starvation of children in Africa—or homicide in the United States.

The key to engaging empathy is what has been called “the identifiable victim effect.” 

The number of victims hardly matters—there is little psychological difference between hearing about the suffering of five thousand and that of five hundred thousand.

In the broader context of humanitarianism, as critics like Linda Polman have pointed out, the empathetic reflex can lead us astray. When the perpetrators of violence profit from aid—as in the “taxes” that warlords often demand from international relief agencies—they are actually given an incentive to commit further atrocities. It is similar to the practice of some parents in India who mutilate their children at birth in order to make them more effective beggars. The children’s debilities tug at our hearts, but a more dispassionate analysis of the situation is necessary if we are going to do anything meaningful to prevent them.

A “politics of empathy” doesn’t provide much clarity in the public sphere, either. Typically, political disputes involve a disagreement over whom we should empathize with. Liberals argue for gun control, for example, by focussing on the victims of gun violence; conservatives point to the unarmed victims of crime, defenseless against the savagery of others. Liberals in favor of tightening federally enforced safety regulations invoke the employee struggling with work-related injuries; their conservative counterparts talk about the small businessman bankrupted by onerous requirements. So don’t suppose that if your ideological opponents could only ramp up their empathy they would think just like you.

On many issues, empathy can pull us in the wrong direction. The outrage that comes from adopting the perspective of a victim can drive an appetite for retribution. (Think of those statutes named for dead children: Megan’s Law, Jessica’s Law, Caylee’s Law.) But the appetite for retribution is typically indifferent to long-term consequences. In one study, conducted by Jonathan Baron and Ilana Ritov, people were asked how best to punish a company for producing a vaccine that caused the death of a child. Some were told that a higher fine would make the company work harder to manufacture a safer product; others were told that a higher fine would discourage the company from making the vaccine, and since there were no acceptable alternatives on the market the punishment would lead to more deaths. Most people didn’t care; they wanted the company fined heavily, whatever the consequence.

Too often, our concern for specific individuals today means neglecting crises that will harm countless people in the future.

Rifkin and others have argued, plausibly, that moral progress involves expanding our concern from the family and the tribe to humanity as a whole. Yet it is impossible to empathize with seven billion strangers, or to feel toward someone you’ve never met the degree of concern you feel for a child, a friend, or a lover. Our best hope for the future is not to get people to think of all humanity as family—that’s impossible. It lies, instead, in an appreciation of the fact that, even if we don’t empathize with distant strangers, their lives have the same value as the lives of those we love.

That’s not a call for a world without empathy. A race of psychopaths might well be smart enough to invent the principles of solidarity and fairness. (Research suggests that criminal psychopaths are adept at making moral judgments.) __The problem with those who are devoid of empathy is that, although they may recognize what’s right, they have no motivation to act upon it. Some spark of fellow-feeling is needed to convert intelligence into action.__

Putting aside the extremes of psychopathy, there is no evidence to suggest that the less empathetic are morally worse than the rest of us. Simon Baron-Cohen observes that some people with autism and Asperger’s syndrome, though typically empathy-deficient, are highly moral, owing to a strong desire to follow rules and insure that they are applied fairly.

Where empathy really does matter is in our personal relationships. Nobody wants to live like Thomas Gradgrind—Charles Dickens’s caricature utilitarian, who treats all interactions, including those with his children, in explicitly economic terms. Empathy is what makes us human; it’s what makes us both subjects and objects of moral concern. Empathy betrays us only when we take it as a moral guide.

Newtown, in the wake of the Sandy Hook massacre, was inundated with so much charity that it became a burden. More than eight hundred volunteers were recruited to deal with the gifts that were sent to the city—all of which kept arriving despite earnest pleas from Newtown officials that charity be directed elsewhere. A vast warehouse was crammed with plush toys the townspeople had no use for; millions of dollars rolled in to this relatively affluent community. We felt their pain; we wanted to help. Meanwhile—just to begin a very long list—almost twenty million American children go to bed hungry each night, and the federal food-stamp program is facing budget cuts of almost twenty per cent. Many of the same kindly strangers who paid for Baby Jessica’s medical needs support cuts to state Medicaid programs—cuts that will affect millions. Perhaps fifty million Americans will be stricken next year by food-borne illness, yet budget reductions mean that the F.D.A. will be conducting two thousand fewer safety inspections. Even more invisibly, next year the average American will release about twenty metric tons of carbon dioxide into the atmosphere, and many in Congress seek to loosen restrictions on greenhouse gases even further.

Such are the paradoxes of empathy. The power of this faculty has something to do with its ability to bring our moral concern into a laser pointer of focussed attention. If a planet of billions is to survive, however, we’ll need to take into consideration the welfare of people not yet harmed—and, even more, of people not yet born. They have no names, faces, or stories to grip our conscience or stir our fellow-feeling. Their prospects call, rather, for deliberation and calculation. Our hearts will always go out to the baby in the well; it’s a measure of our humanity. But empathy will have to yield to reason if humanity is to have a future.

## [Jon Ronson: Strange answers to the psychopath test](http://www.ted.com/talks/jon_ronson_strange_answers_to_the_psychopath_test.html)

It was a man called Brian who runs a crack team of Scientologists who are determined to destroy psychiatry wherever it lies. They're called the CCHR. And I said to him, "Can you prove to me that psychiatry is a pseudo-science that can't be trusted?" And he said, "Yes, we can prove it to you." And I said, "How?" And he said, "We're going to introduce you to Tony." And I said, "Who's Tony?" And he said, "Tony's in Broadmoor." Now Broadmoor is Broadmoor Hospital. It used to be known as the Broadmoor Asylum for the Criminally Insane. It's where they send the serial killers and the people who can't help themselves. And I said to Brian, "What did Tony do?" And he said, "Hardly anything. He beat someone up or something, and he decided to fake madness to get out of a prison sentence. But he faked it too well, and now he's stuck in Broadmoor and nobody will believe he's sane.

And then Brian said, "Here's Tony." And a man was walking in. And he wasn't overweight, he was in very good physical shape. And he wasn't wearing sweatpants, he was wearing a pinstriped suit. And he had his arm outstretched like someone out of The Apprentice. He looked like a man who wanted to wear an outfit that would convince me that he was very sane.

Tony said that it's a lot harder to convince people you're sane than it is to convince them you're crazy. He said, "I thought the best way to seem normal would be to talk to people normally about normal things like football or what's on TV. I subscribe to New Scientist, and recently it had an article about how the U.S. Army was training bumblebees to sniff out explosives. So I said to a nurse, 'Did you know that the U.S. army is training bumblebees to sniff out explosives?' When I read my medical notes, I saw they'd written: 'Believes bees can sniff out explosives.'" He said, "You know, they're always looking out for non-verbal clues to my mental state. But how do you sit in a sane way? How do you cross your legs in a sane way? It's just impossible." And when Tony said that to me, I thought to myself, "Am I sitting like a journalist? Am I crossing my legs like a journalist?"

He said, "You know, I've got the Stockwell Strangler on one side of me and I've got the 'Tiptoe Through the Tulips' rapist on the other side of me. So I tend to stay in my room a lot because I find them quite frightening. And they take that as a sign of madness. They say it proves that I'm aloof and grandiose." So only in Broadmoor would not wanting to hang out with serial killers be a sign of madness. Anyway he seemed completely normal to me -- but what did I know?

And when I got home I emailed his clinician, Anthony Maden. I said, "What's the story?" And he said, "Yep. We accept that Tony faked madness to get out of a prison sentence because his hallucinations that had seemed quite cliché to begin with just vanished the minute he got to Broadmoor. However, we have assessed him. And we have determined that what he is is a psychopath." And in fact, faking madness is exactly the kind of cunning and manipulative act of a psychopath. It's on the checklist: cunning and manipulative. So faking your brain going wrong is evidence that your brain has gone wrong. And I spoke to other experts, and they said the pinstriped suit -- classic psychopath. Speaks to items one and two on the checklist -- glibness, superficial charm and grandiose sense of self-worth. And I said, "Well, what, he didn't want to hang out with the other patients?" Classic psychopath -- it speaks to grandiosity and also lack of empathy. So all the things that had seemed most normal about Tony was evidence, according to his clinician, that he was mad in this new way. He was a psychopath.

And his clinician said to me, "If you want to know more about psychopaths, you can go on a psychopath spotting course run by Robert Hare who invented the psychopath checklist." So I did. I went on a psychopath spotting course, and I am now a certified -- and I have to say, extremely adept -- psychopath spotter.

So here's the statistics: One in a hundred regular people is a psychopath. So there's 1,500 people in his room.

Hare said the reason why is because capitalism at its most ruthless rewards psychopathic behavior -- the lack of empathy, the glibness, cunning, manipulative. In fact, capitalism, perhaps at its most remorseless, is a physical manifestation of psychopathy. It's like a form of psychopathy that's come down to affect us all.

I emailed "Chainsaw Al" Dunlap, the asset stripper from the 1990s. He would come into failing businesses and close down 30 percent of the workforce, just turn American towns into ghost towns. And I emailed him and I said, "I believe you may have a very special brain anomaly that makes you special and interested in the predatory spirit and fearless. Can I come and interview you about your special brain anomaly?" And he said, "Come on over."

And he looked intrigued despite himself, and he said, "Okay, go on." And I said, "Okay. Grandiose sense of self-worth." Which, I have to say, would have been hard for him to deny because he was standing underneath a giant oil painting of himself. (Laughter) He said, "Well, you've got to believe in you!" 

And I said, "Manipulative." He said, "That's leadership." And I said, "Shallow affect: an inability to experience a range of emotions." He said, "Who wants to be weighed down by some nonsense emotions?" So he was going down the psychopathic checklist, basically turning it into "Who Moved My Cheese?"

I realized that becoming a psychopath spotter had turned me a little bit psychopathic. Because I was desperate to shove him in a box marked psychopath. I was desperate to define him by his maddest edges.

When I got back to London, Tony phoned me. He said, "Why haven't you been returning my calls?" I said, "Well they say that you're a psychopath." And he said, "I'm not a psychopath." He said, "You know what, one of the items on the checklist is lack of remorse, but another item on the checklist is cunning, manipulative. So when you say you feel remorse for your crime, they say, 'Typical of the psychopath to cunningly say he feels remorse when he doesn't.' It's like witchcraft. They turn everything upside-down."

So I went to his tribunal. And after 14 years in Broadmoor, they let him go. They decided that he shouldn't be held indefinitely because he scores high on a checklist that might mean that he would have a greater than average chance of recidivism. So they let him go. And outside in the corridor he said to me, "You know what, Jon? Everyone's a bit psychopathic." He said, "You are. I am. Well obviously I am." I said, "What are you going to do now?" He said, "I'm going to go to Belgium because there's a woman there that I fancy. But she's married, so I'm going to have to get her split up from her husband."

And then he phoned me. And you know what, I think it's right that Tony is out. Because you shouldn't define people by their maddest edges. And what Tony is, is he's a semi-psychopath. He's a gray area in a world that doesn't like gray areas. But the gray areas are where you find the complexity, it's where you find the humanity and it's where you find the truth. And Tony said to me, "Jon, could I buy you a drink in a bar? I just want to thank you for everything you've done for me." And I didn't go. What would you have done?

## [Upside of Irrationality Chapter 9: On Empathy and Emotion](https://www.youtube.com/watch?v=DlzHxULncNM)

Why is it the case that we don't care about malaria? Could it be because it's just a big problem?

Tsunami/9-11, could it be because it's closer or it's more shocking?

How much we care vs. magnitude of the problem doesn't matter. It's all about activating the emotions. So how do we get people to care?

American cancer society: The word "cancer." The word "survivor." People are asked to recruit friends and families, so people get connected.

__The key to action is not thoughtful deliberation, it's emotion.__ If we think in a calculated manner, we will be selfish. The activation of emotion will get us to care about the problems.

## 3 - 1 - 3.1 - Moral Diversity - 9_32

Now in this third lecture, we're going to start at the origins of morality. The origins of moral rules and moral principes and moral feelings. Where do they come from? How is it that we have them? 

So, in this first lecture, I'm going to spend the rest of the lecture talking about moral diversity, that it's differences in moral feeling and moral judgments. The second lecture we'll talk about moral universals that is aspects of morality that are shared across all humans. The third and fourth lectures we'll deal with evolution and morality. Looking at morality from a biological, Darwinian perspective. Asking how the amoral force of natural selection could give rise to creatures like us, which have moral capacity for moral judgements, altruistic behavior and all sort of other directive, all sorts of sweeter kinder emotions and feelings. The fifth lecture is a guest lecture by professor Lori Santos, who's a colleague and a friend of mine. And she'll be talking about primate morality. Then we'll go back and the sixth lecture will be about morality in babies. And, finally we'll end with some open questions, some puzzles, some things that honestly we have not, solved yet, and maybe we, we're not ready to solve. 

But, I want to be honest in this course and sort of lay out what we know and sometimes what we don't know. So, diversity, many people are skeptical of moral universes. So, when you say I'm interested in morality, one, one, one reasonable response is, well, morality differs all over the place. There's nothing universal about morality. We have one moral system, but people in another country might have another, and people at another time might have another. And, this idea of moral diversity, is something which has been in the air a long time. 

One classic example is, from, comes from Heredades who wrote in his histories about 2,400 hundred years ago. And, Heredades tells a story of Darius, King of Persia. So, to make a point, Darius brings in a bunch of Greeks. And he says to them, so how much would I have to pay you to eat the dead bodies of your fathers? And, the Greeks are horrified. They would never do such a thing. What a, what a grotesque proposal! How wrong can you be? And then, in a Presidents of the Greeks, Darius brought in some members of an Indian tribe, but a very different custom. And, ask them, how much would I have to give you to burn the bodies of your fathers? And, the Indians were horrified. How could we do such a thing? The only thing you do to respect one's dead father would be to eat him. You don't burn him. And, and the point that Darius is making to his audience was, that what seems natural to one is unnatural to another. What seems right to one is wrong to another. Haradus goes on to write, if anyone were given the opportunity from choosing amongst all of the nations in the world, the set of beliefs which he thought best, he would inevitably, after careful consideration of irrelative merits, choose that of his own country. Everyone without exception believes his own native customs and the religion he was brought in to be the best. 

Now, many contemporary psychologists, philosophers, anthropologist would agree with the point that Horradis is making, which is that there's significant variation And morality around the world. And, my favorite example here is from the University of Chicago anthropologist Richard Shweder, who provides a very nice list. So, he's talking about moral attitudes and moral feelings. And, he notices that people have found it quite naturally to be spontaneously appalled, outraged, indignant, proud, disgusted, guilty, ashamed of all sorts of things. And he has this list that you could see. Masturbation, homosexuality, democracy, capitalism, meat eating, divorce, romantic love, marriage, long hair, women being allowed to work, women not being allowed to work, and the range is dazzling and it's correct. For each of these items you could find some people in the world who find it monstrous and other people in the world who find it important, and significant, and valuable. 

One could see these differences, without going to an anthropological text or without reading history books, is open up the newspaper. So, one story, that, that I found in the New York Times as I was thinking about these issues and writing about these issues, was, was this, this very sad case in Afghanistan. So, you have two teenagers, and they're of different ethnicities, different groups, and they fall in love. And they, they start to date, they start to talk to each other. One day, in the middle of the day, they're sitting in a car together and their talking, and a group of men see them and approach them and demand to know what their doing there. What's up with them, are they involved, what's happening here? And, pretty soon people gather and 300 people gathered, and they decide that these 2 teenagers are adulterers. They're, they're, they're involved in a, in a sexual relationship outside of marriage. And they decide to, to kill them, to kill them through stoning. And, then security forces come, the police comes and there's a riot. Police come, they rescue the teens, they put them in custody for their own protection and there's a riot and one person dies. Now, after the event all sorts of people came and express their moral attitudes. But, their moral attitudes weren't necessarily what one would expect. so, the father of the girl says, well, this is terrible, this is a horrible thing, both people should be killed. Both the teenagers should be killed for what they did. the, the, the family members of the man who was killed in the riot says, it's the teenage girls responsibility, and here's what she can do to make good, what she can do is, marry one of their remaining sons, and then the debt will be paid. 

Now, from how I was raised, I, you know, I was raised in Montreal, Canada. I was, I now, now, now live in the United states. These are very alien moral sentiments. I was raised in a, in, in a community in a world where romantic love was prized. Romantic love was seen as a, as a precious and important thing. One might object to it in some case and not others, but nothing inherently wrong with it. And, so it's shocking to me to see how people are different. In fact and contemporary Western society, many could argue we are going to opposite extreme where there are sort of a celebration of sexual debotury, hardcore pornography is rampance. Some would argue that the objectification of women as sexual objects is rampant. And, and this is which, and, and these are, are, things that are viewed as morally okay in the West but shocking and repellent to many people around the world. So, it's clear enough that people at different places in different times have very different moral views. This leads the question, what if anything, do we have in common? And that's the topic of the next lecture.

## 3 - 2 - 3.2 - Moral Universals - 13_23

So we ended in the last lecture by talking about diversity, the sort of diversity pointed out by Herodotus, the sort of diversity cataloged by Richard Shweder and other anthropologists. But, now we can kind of shift gears a bit and think about things in a different way, looking now at what places and people have in common. And the first thing to realize is that the examples provided by Herodotus and by Shweder and others actually illustrate a sort of commonality. 

Because, although cultures have different attitudes about how to treat the dead, about how parents should interact with their kids, about romantic love, about sexuality. Although they have different attitudes, there are no cultures that don't care. These are all examples of, of moral differences, but they're also examples of moral commonalities, and these are the very domains which are imbued with morality. So, so, you know, you might have to. You, you. The right thing might be to eat your dead father. The right thing might be to burn your dead father. It might be to, as in our culture, many of us, to bury your dead father. But you're not going to find anybody who says, I don't care. Whatever, you know? Dead bodies? Who cares. Humans care about dead bodies. Humans care deeply about the moral status of dead bodies, of loved ones, and what one should do about them. 

You may find societies that treasure romantic love. That view this as a high moral ideal. Others that view it as very disturbing and wrong. Well, you're not going to find cultures that say love, that doesn't really matter from a moral point of view, couldn't care. These are things that matter. More to the point. It's not the case that everything's up for grabs. 

So, we're naturally fascinated by moral differences. And we're actually fascinated by these in part because they matter to us as we travel and as we interact with other people. When I go to a foreign land, I'm very interested in in how they think, and I'm particularly interested in how they think that's different from how I think. Is the way I raise my kids going to be shocking to them? Are they going to be offended by something I do? Are our customs different? Are our, you know, rules for interaction different? We want to know that because we're people, and when we're interacting with other people it's the differences that matter. I don't want to open up a travel guide and say, you know this far away place you're going? The people there, they have noses, and they age over time. Well. And they often have two arms and two legs. I don't want to hear that. That's not humanly interesting because I know it's true. It's just obvious. 

Arguably, you see the same thing with language. So, the linguist, Noam Chomsky, has pointed out that the thing that captivates us with languages are their differences. If I go to a foreign land, and they're speaking French or Thai or Choctaw or Russian, or what have you, I don't understand any of those languages. And the difference between what they're doing and what I do, speaking English, barely, is, is, is, is it humanly relevant? And Chomsky points out though, that it turns out languages have deep universals. The deep universals underline language and may in some way be the sort of much more important from a scientific point of view than their superficial differences. But it's not the universals we focus on. It's the differences, and you might say the same thing with morality. So, there are moral universals that show up culture after culture after culture. We tend not to think of them or talk about them because they aren't as humanly relevant. In some sense they aren't as exotic. They aren't as interesting. 

But what am I talking about, when I talk about human universals? Well, here we could draw upon the work of scholars like, like Shweder himself. Like his his student and a psychologist, Jonathan Haidt. Psychologists like Pinker and, and, and anthros, anthropologists like Fisk who have, who have sort of broken up the moral the moral world into different parts, and without putting too much weight onto this I want to suggest you can think about five categories when it comes to morality. 

So one category is harm. Harm is a critical universal aspect of our moral systems, and in particular, wherever you go, there's the belief in the wrongness of intentional assault. You gotta have a reason. To put it differently. Wherever you travel, anywhere on this planet, if you walk up to somebody and punched them in the face, you better have a good reason. You better, you better, you better have an excuse. There better be a justification. Because otherwise the people are not going to stand for that. You will have done something wrong. 

There's reciprocity. Humans are social beings. We find ourselves in, in, in relationships where we share, where we cooperate, and there are norms of sharing and cooperation saying how you should do it, who you should do it with and so on. 

There's also corta, correspondingly a universal notion that it's wrong to cheat. It's wrong to say you'll do something and not do it. It's wrong to to, to, you know, weasel out of things. It's wrong to free-ride. Well, free-ride is a bit of a, a technical term. To, to be a free-rider means you mooch off the hard work of others. There is a hunt, for instance, and everybody in the community is doing the hunting. And you're sitting back. And when the food comes you eat as much of it as everybody else. Well, there is no place on earth where if they notice, people notice this, they won't think that you're a jerk. That sort of free riding is universally disapproved of. 

There's hierarchy, and this is actually a domain which we probably know a little bit less about than some of these other domains. But the idea is, wherever you look, there's some respect for authority, some notion of honor and dignity and respect. And, now this could be very rich. So in a society where I live in, there is all sorts of hierarchies. I'm supposed to respect the president, I'm supposed to respect my boss. My, my students are supposed to respect me to varying degrees. but, but everywhere, there's something like this. At minimum, within the family. Where our sort of expectations and requirements about how a child is supposed to deal with his or her parents, and the parents are supposed to deal with his or her children. 

There's purity. Purity is extremely interesting and, and, and one way to put this, and this actually comes from, from Shweder, to some extent. Is that wherever you are you find it morally important to protect yourself and others from contamination, physical or spiritual. I know it's a little bit vague. And, and this is something which I find interesting enough I want to devote more time to it later but now just, just to, to sort of zoom in a little bit. Wherever you go there's going to be moral restrictions having to do with food and sex and death. It's not just like oh, we like to eat this and not that or, or we think this sexual position is particularly fantastic or, you know, don't step on the corpse. Rather, it's. It is wrong to eat this. It is right to eat that, or it's wrong to eat this on that day of the week or that time of the year. This sort of sex is forbidden. This sort of sex is morally out of bounds. When somebody dies you should do this and that and this and that, and not do this and that and this and that. The details, of course, as we've discussed differ but there are to my knowledge from anything I've read, there are no societies who are indifferent about these matters of purity. 

And finally, there's some issue, there's always a morality of community. We make a moral, we make a distinction between in-groups and out-groups, between us and them. And this isn't just a psychological distinction, this isn't just that we notice it, but rather this distinction has moral significance. There's a value given to loyalty to your group. We condemn people who betray their group. We condemn heretics. We condemn people who, who defect to the other group. And a lot of our sort of group dynamics, a lot, a lot of the way the world works. Turns on the critical and natural moral distinctions they make between themselves and other people. 

So, you have these universals and in, in fact we, we could now, just, just to look at in a somewhat different way, forget about the categories and, and think of specific examples. So these are specific examples, which I would suggest are true everywhere. There's a ban on arbitrary assaults. No punching somebody wihtout a good reason. You should keep promises. When you make a, a promise to someone, you say you'll do something, you should. If you just, you know, don't do it, then something's gone wrong. Some degree of sexual modesty. Now this of course, varies hugely. There are parts of the world where a man, you know, if, if he's not going out with a vest and a nice jacket and a tie, he, you know, he's doing something horribly wrong. There's other parts of the world where he just has to have a penis pouch, and that's it. 

But, there's always rules. There's rules on some degree of, of modesty. Regarding how much of your body you show, and also regarding where you urinate and defecate, and where you have sexual intercourse. It doesn't, you're not going to find any people for whom this doesn't matter. Some obligation to share. At least share with those with your children. With, with your friends. Anger towards cheaters and free-riders. Anger towards those who for whatever reason have chosen to violate the moral rule that you would hoped that they would do. And they don't share. Protection of children. Just like there's no society, where you can't punch somebody just at will, there's no society where it's fine to kill children. A taboo on incest. So, there's a particular sexual taboo, that gets sketched out in different ways, but but wherever you go for instance brother-sister incest is considered morally wrong. It's not just oh we don't like that, we don't typically do it but rather it, there's something wrong with it. If, if, if it was believed, if you came into this country and you said, oh this is what I do all the time I have intercourse with my siblings, people would look down on you. There are rules about appropriate foods. There's obligation to family, and finally, to go back to Herodotus, there's special treatment of the dead. 

Now, you have these universal moral principles, these universal moral ideas and it might be very tempting to say wow, so that must be hardwired. That must be innate. That must be a part of how our brains work. That must be the product of natural selection, of biological evolution. But it doesn't necessarily follow. All sorts of things that are universal could arise in the course of cultural evolution, not biological evolution. That is, they could be cultural solutions to universal problems. So take the, the restriction against hitting. It might be an effect, I think I will argue that, that, that it is. That there's some built in mechanism that, that, that kicks in when you see one person arbitrarily assault another one. 

But, to be fair, there are other theories for why all societies have some sort of ban on hitting. The idea being that even if you didn't start off with any instinctive desire not to be hit or not to have somebody hit another person, still the culture couldn't survive if you would just hit each other. So imagine two societies side by side. One society, people just smacked each other whenever they felt like it. The other society, where it was viewed as wrong to do so. It's clear the society which views it wrong to do so would be a better society will, will, will work better, will be better at, at battle, will be better at everything. Then a society where people were just simply smacking each other. 

The philosopher Jesse Prinz, put this quite nicely, quite succinctly, when he wrote how would society work if you could punch your neighbor regularly? __Well, not very well. so, we should, as we consider the origins of these universals, we should have on the table that some of this morality might arise as cultural solutions to universal problems.__ At the same time, though, what I want to suggest is that some of morality has a different origin. In particular, some of morality may have evolved through natural selection. And how this can happen, how this can work, is going to be the topic of the next couple of lectures.

## 3 - 3 - 3.3 - Evolution of Morality - 20_19

So I want to turn now and talk about morality from a evolutionary perspective. Now I'd like to assume some familiarity with the theory of natural selection. And if people want to get more of a background, as part of the supplementary readings I linked to an excellent video that outlines the logic and, and, and some examples of how natural selection works. If you're not familiar with the evolutionary theory behind it, it's absolutely fascinating and you should delve into it. I would actually also recommend reading Origin of Species. Actually the first edition, Darwin's first edition. Darwin was among so many other things, a lovely writer. And he wrote for a broad audience. And this is an accessible and interesting book. 

If you want something more contemporary, I would suggest Richard Dawkins's wonderful book, The Blind Watchmaker. I think this is the British cover. I read this when I was much younger and it actually totally entranced me. And largely transformed my intellectual life, getting me to take very seriously evolution and evolutionary theory, later on influencing my own work as a psychologist. It just, it's just a, a wonderful read. 

But in case, in case, you don't have the background. A very short summary of the theory which has a sort of surprising simplicity and surprising elegance goes like this. It involves three parts. There are three three conditions that are needed for natural selection to take place. You have to have variation. You have to have differential reproduction, meaning that some of the variants do better at reproducing than others. And you have to have heredity, where the offspring resemble their parents. 

And Darwin's extraordinary insight is, you take these three simple facts when they occur. __Variation, differential reproduction and heredity.__ And under those conditions such things can give rise to the most complicated and extraordinary systems in the universe. It could give rise to biological life. It could give rise to animals, and parts of animals and organs and all sorts of good things like that. 

So, a very simple example, a sort of toy example, would be like this, which is, you could say you could ask yourself, Why is it that all? Imagine, it turns out to be the case, that the beetles are brown, and, and birds don't eat brown beetles. They can't see them, or whatever. Say, wow, how did that work out? How did that happen? Well, one argument would be, one, one explanation is that maybe beetles started off both green and brown, so you get this variation, some are green, some are brown. But, there is differential reproduction, there is differential reproduction because birds eat the green beetles. And so the green beetles leave behind fewer offspring than the brown beetles. Now there is also, as a third component, heredity. So the brown beetles give rise to offspring that tend to be brown. They resemble their parents. If you iterate this over and over again, and this is actually simple example, you're not going to need a computer model to, you to see it. Pretty soon all the beetles going to be brown. Pretty soon in a condition where there's variant x and variant y, and x does better than y, leaves more offspring. Pretty soon, x will win and the whole population will be, will be x. 

And this is a screamingly simple example, but, you know, the project, so much of the project of evolutionary biology is wrapping this up. So forget now about a single color difference and think about camouflage. And and, and the same evolutionary explanation can explain why animals, why some animals are so extraordinarily good at blending into their environments. They're good at blending into their environments because, variants, you go back into the past. Variants that were better off at blending in got eaten less by predators. And then, and so on and so forth and so on, until through, you gradually converge on animals that are almost invisible, because they got to be invisible because those invisible variants, those variants that perfectly blended in reproduced the most. And then you get to, to, to sort of detailed analyses of how this sort of increasing, step by step by step, each step leading to some, perhaps a minuscule, but a real advantage in reproductive success. Leads to a, a, a new stage of development. 

And then so they're biological theories well grounded in data on how the eye could evolve. How the how the leg of a horse could evolve. How whole animals could evolve, how the spine could evolve. And and so this is all the biological part. But it slides into psychology because one of the, the, the organs that have evolved, that has evolved through natural selection is of course, the brain and in particular, organ we are most interested is the human brai, human brain. And if you see the human brain as a biological adaptation, as something which has risen through natural selection. That's just quite a new way of looking at things. And this was something Darwin himself was sensitive to. 

So one point he writes, that as a result of evolutionary theory, psychology will be based on a new foundation. That of the necessary acquirement via evolution of each mental power and capacity by gradation. That is, you look at the cluster of mental capacities we have and each one we can see as an adaptation that has sort of gradually developed through increased reproductive success. 

Now this is a certain view of the mind. It doesn't say the mind is a huge all purpose computer or the mind is a general associative network as many philosophers would argue. And some modern day computational theorists would argue. But rather, the mind is a cluster of different capacities. Each one has evolved for a different purpose. Also, they've evolved to work in concert with one another. This is, again, an old idea. The most one of the most famous psychologists of all, William James, expressed it quite nicely. William James wrote. It is often said that man is distinguished from the lower animals by having a much smaller assortment of native instincts and impulses than they, but this is a great mistake. 

James's point is it's very tempting just to say, oh, animals are the product of biological evolution. There's a bunch of instincts that they possess that guide them to, to various behaviors. But humans are special. Humans, we don't have instincts anymore, we're just very smart. We're cultural creatures, say. And to some extent we are very smart and to some extent we are cultural creatures. But the approach that Darwin and James recommend, an approach which is pursued by many evolutionary psychologists. An approach which, you know, guides my own research is that in addition to any general smartness any cultural proclivities that we posses, we also have an assortment of, of instincts, call them mental organs, call them modules. For language, for mate selection, for rudiment, rudimentary mathematics, for social interaction. These may be in different parts of the brain. They may be re, re. They are clearly related to one another and they each have their own evolutionary history shaped by natural selection. 

So, you, you, you think of the human brain now as a product of natural selection as a set of instincts or organs. And, and, and, and it's easy enough to explain, to see how this approach can explain certain appetites, like food and sex. So why do we get hungry. Well, you get hungry because it motivates us to eat, and any ancestors we had that was that weren't motivated to eat would die and wouldn't reproduce, this is why animals get hungry. Why do we eat this and not that? Well that gets a little bit more interesting. We can kind learn about the details of our appetites. Details of what we like to eat and what we like to drink by looking at evolutionary benefits that, that exist when we eat this and not that. 

What turns us on? What about sex? Well, same thing. Any animal that wasn't actively involved in the project of reproduction, wouldn't reproduce. And it for the most part for the most there's a lot of competition for reproductive resources. Either getting to reproduce at all, or getting to reproduce with the best possible mate to get the best possible genes. And so, and this is not the topic of this course but it would be a great other course. So any serious inquiry into the psychology of human sexuality will be guided, at least in part, by a clear headed look at how evolution would have shaped us sexually. How it would have shaped our desires, our strategies, and our behaviors. But, you might worry, and through history a lot of people have worried, that this evolutionary approach is perfectly good when it comes to sort of so-called selfish desires. 

You know eating, and having sex, and protecting yourself and so on. But morality isn't about the self primarily. Morality is about the welfare of others. And how could a evolutionary process driven by survival and reproduction lead to caring about the welfare of others? So some people say about, about animals that according to natural selection, according to evolutionary theory, we're survival machines. And it's hard to think of anything more amoral than that. Or well, okay, how about survival of the fittest? Which is, which is you know, a sort of savage, amoral, perhaps immoral doctrine. Nature red in tooth and claw. An idea here is that if you think about human nature from a, you know, a clear headed, cold-blooded biological, natural selection point of view, there's no place for morality. So to the extent that we are moral creatures, to the extent we can do right and wrong, we can think about right and wrong, that has to be separate from morality. 

Maybe it was instilled within us by God. Maybe, it was a cultural invention that we came up with with our powerful intelligence, but it cannot be natural. Now, I don't think these worries are entirely mistaken. I think certain claims about our moral nature, certain idealistic views about what morality could be. As part of us, are really precluded by the facts of biological evolution. So, imagine genes that gave rise to an indiscriminate altruist. 

So I'll describe my terms. I'll define my terms. Altruism is the act of giving to somebody at a cost to yourself. An indiscriminate altruist is someone who gives to everybody. Doesn't care, just gives to anybody. How would this indiscriminate altruist do? Well, if there's a community of indiscriminate altruists, we all just give indiscriminately to everybody else, we could do pretty well actually. There's all sorts of things in life where you could use somebody's help watching over a child. Moving something that's heavy, collecting food. And if everybody helps everybody else, it's really to the sort of mutual benefit of the whole society. 

But here's the problem. Imagine such a society of indiscriminate altruists and now imagine a mutant. Imagine another creature pops in who receives but never gives. So, takes any food anybody gives to it you want to watch your kids that's fine, but itself is not implying to, to do anything to help other people. To help other members of its species. It's not hard to see that this mutant would have a huge advantage. Suppose every time, suppose take a, take a concrete example warning cries. So some animals give warning cries when a predator approaches, so a predator's in the distance, I see it and I scream warning, warning. I don't scream warning warning, I scream some sort, I can't, I can't imitate a warning cry that any animal would do. A human warning cry. Hey, warning. Suppose I'm an indiscriminate altruist. So I just do this no matter what, whoever is around me. Now, imagine this mutant. And everybody benefits from me. Even though when I shout out the warning cry, it raises my own risk because it calls my attention to the predator. So, the benefit to everybody is great, but there's some risks, risks to myself. And, if everybody was like me, the trade off would work out well. But now again, a mutant comes in, who gets all the benefit. He listens to warning cries and runs away. But, when he sees a predator, he just runs away. Doesn't do a warning cry at all. He would do better. He would live longer. He would reproduce more. Which means is nice guys finish last. Pure kindness of an indiscriminate sort can't evolve. 
Okay but now we get a little bit more subtle. What about genes that give rise to a discriminate altruist? A discriminate altruist is somebody who, who acts in a way to help others, and takes cost to help others. But is discriminating, helps some but not everybody. 

Well we actually know that discriminate altruists. exist. We know animals are discriminate altruists. Take the simplest case of caring for your children. So animals, mammals, for instance, take care of their offspring. Sometimes female mammals will feed their offspring from their own bodies. Mammals will watch over them, will take care of them, will, will, provide them with food once they're born, before they're born and so on. And this is, they don't do this to everybody. They do this to, to their offspring. So you know, one example is as everyone uses cute animals but one example is vampire bats. So vampire bats, when a vampire bat will fly out of its cave, find a horse or something, bite the horse get in a lot of blood. More blood then itself needs. Fly back to the cave and then regurgitate this blood into the mouths of its baby vampire bats. And, and you could see this sort of altruism being beneficial and, and it's a kindness, but it's not the sort of pure, indiscriminate kindness. 

One way to think about this, the term people use to describe the phenomenon that I've been introducing is kin selection. And the idea is this, you have a specific gene for something, what's going to make that gene a winner? What's going to make the gene such that it's going to spread through a population. And before you know it everyone's going to have the gene. Well one answer is, it might increase the chance that the bearer of that gene will survive and reproduce. If there is a gene that makes me resistant to a disease like malaria, and my next door neighbor does not have that gene I will do better. I will reproduce more. My neighbor will reproduce less. And over the fullness of time everybody will have this gene because this gene just leads to an advantage. 

But a gene could also spread if it increases the chance that other individuals who possess that gene, genetic relatives, will survive and reproduce. So. Imagine gene A makes animals care for its siblings and gene B makes animals only care for itself. Since if you only care for your siblings, your gene A your siblings also have some chance of having gene A in them. And so by active sort of caring for your kin, genes get to replicate themselves. And so the, the logic of this was, was presented in a somewhat comical way by the biologist Haldane. Haldane was asked presumably, it's one of these stories that, that sounds apocryphal but may well have been true. He was asked in a bar, just casual conversation, would you lay down your life for your brother? Made a few quick calculations and responded, no, but I would gladly give my life for three brothers or five nephews or nine first cousins. 

Now what he was doing in a whimsical way, we never do this consciously, was making reference to to the degree of genetic relatedness. So as you can see in this chart over here different relatives are related to you to different degrees. And related to you in this sense means what are the odds that for any gene you possess that they also possess that gene. So with me and my identical twin. If I were to have an identical twin, it'd go up to about 100%. For me and my sibling, about 50%, and so on. So we could unpack Haldane's answer. Would you lay down your life for your brother who has 50% of your genes? No. But, I would give my life for three brothers, because that's 150%. Or five nephews, 125%, or nine first cousins, 112.5%. Nobody actually, again, nobody does these calculations in their heads but the idea is that the logic here, the fact that these strategies. Lead the strategies of, of a certain form of discriminate altruism towards close genetically related kin, lead to greater success of genes has shaped our psychologies and it's this psy, these shape psychologies that leads to, sort of, moral sentiments. Towards people close to us. 

This is if you defended, at great length again by Richard Dawkins in his wonderful book, The Selfish Gene. And The Selfish Gene is one of these books that people always misunderstand. And, and the people who misunderstand are often the people who simply look at the cover. And, and, and, and, and misread things. So often, they say, oh, Dawkins is saying people are selfish. But actually, Dawkins is actually saying exactly the opposite. He's saying genes are selfish, in the metaphorical sense, he's very clear it's a metaphor, that all they want to do, metaphor again, is make copies of themselves, replicate themselves, spread through the population. But, because genes are selfish people aren't selfish. That is to the extent that evolution operates at the level of the genes there's no hard and fast distinction between oneself and another. Before you think of things in terms of genes you might think you're one individual with its own interests. And everybody else is their own individual with their own interests. But from the genetic point of view, there's no sharp line. Your interests are, are the same, genetically, as two of your brothers'interests. Genes cross-cut things in different ways, and a genetic perspective on human nature, interestingly enough can provide our first understanding of where morality can come from.

## 3 - 4 - 3.4 - Reciprocal Altruism - 18_56

But, what about kindness to non-relatives? So... Humans at least, and probably other creatures. Are not only altruistic to those, who we're related to. We're also altruistic to those we aren't related to, those we hang out with. People we, we're in constant interaction with. arguably, this may be somewhat controversial. But vampire bats might do the same. So, the may not only regurgitate blood into the mouths of their offspring. But, also, in, in the mouths of other vampire bats who live in their cave. And then, they may get involved in a sort of reciprocal relationship. And this is, the, the explanation for where this kindness. To to others, others, who you aren't related to. Is sometimes described as reciprocal altruism. And this is a theory developed in it's most. by, by many scholars and including, Robert Trevors. 

An idea is, if you scratch my back, I'll scratch yours. The idea is that we could all benefit, if we help one another. If we if for instance I would benefit if you watch my kids, when I go. In return, I'll watch your kids, when you're off. And, you could see, how in any society, any community, any group. Everybody is better off, if you form these cycles of mutual benefit. Now, there's, of course, a problem with this. And, it's a problem we saw in the last lecture. When we talked about indiscriminate altruists. Which is that, if we are just kind. Without recip, without expecting any reciprocation, without expecting anything back. This it will never work, because cheaters could emerge, free riders. People who will accept your help, but not help you. And, if the free riders have an advantage. Then, the genes that give rise to kindness, would get wiped out of the population. They'd be mal adaptive. They'd be beaten out, by individuals, who accept kindness but don't give it. 

So, the project that needs to be explained then. Is how can, sense we know we get into these reciprocally altruistic relationships. We know we get along with people, we, we, we're kind to those around us. How could this evolve? How could this evolve, under the concern, that people could cheat and free ride? 

Now, one way to think about this. Is through a classic game, a classic problem. It's known as the prisoner's dilemma. The prisoner's dilemma has been studied, a million times. By economists, by philosophers, by biologists, certainly, by psychologists. 

Now, this might seem like a crazy and bizarre and arbitrary sort of example, with, with, all fixed up and everything. But, it turns out that prisoner's dilemma show up, all over daily life. All over interactions with other people. I'll give you a few examples, just to illustrate this. Divorce thing, hiring a lawyer = more expense. Countries investing in war over education. Buying drugs you can bring a gun to a meetup regardless if you're the dealer or the buyer.

By the logic of the prisoners' dilemma. So, this seems terrible. It seems like a situation, which shows up over and over again, in the real world. Where brute logic, sort of, forces you to a conclusion that is less than optimal, for everybody. 

What if individuals could play each other, over, and over, and over again? How would that change things? So, what if it's not life and death, but you gain something and lose something. But, you can play people over and over again? How would that change things? Well, it turns out that, one way to explore this was, was developed the 1980s. It was a famous competition. And, the idea would be, people would create computer programs. That play prisoner dilemma games. And, the prisoner dilemma games, would play against each other. I'm sorry, the programs would play against each other. And, the question is, who would be the winner. What strategy would lead to the most benefit, if you have to play prisoner dilemma games over, and over, and over, again, with other individuals? And, 63 programs competed. 

And, the winner, was one developed by the scientist, Anatol Rapoport. And, it's called Tit-for-Tat. And, what was amazing about this is. Many of the programs were very complicated. Random strategies, all sorts of weird complexities. That the program that Rapoport presented was extremely simple. It, basically, had, just two rules. The first time you meet a new program, cooperate. After that, do on each trial, what a program did, on a previous trial. So, think about it, that a bit and see why this is smart. 

The world's worst prisoners' dilemma program. Would always cooperate. because, then, people would just defect, and there would always be a sucker. This is not a sucker. But, it's forgiving. So, we're defecting. You know, you defect on me, I defect on you. Defect, defect defect. Then, you decide to be nice and you say, okay, I want to cooperate this time. Then, the next game, I'll be nice right back. And, it's transparent, what I'm doing is not rocket science. You can see what I'm doing. And, if you're a smart program or a smart person, you could figure out how to work together for mutual gain. 

Now, a lot has happened since the 1980s. And, there are more clever and more complicated programs for. Playing the Prisoner's Dilemma and interacting. But, the insights of this sort of tit for tat logic seem to capture, in a rough sense, human psychology. And, the human psychology of how we interact with one another. So, we can think about now, some of the emotions. Including, the moral emotions. And, how their emotions might guide us to do an interaction. 

Not unlike Tit for Tat, which could turn out for mutual gain. We feel gratitude and liking, for those who cooperate with us. Indeed, this feelings makes us want to cooperate with them. That's an, in a, in a, in an extremely simple way. A lot of what friendship is about. You're nice to me, I feel I want to be nice to you, and we get along. We have this mutual trading back and forth. We feel anger and distrust towards those who betray us. Which, motivates us to betray them, or avoid them in the future. You defect, you screw me, you, you put me in a bad position? The next time we play, I'm going to do that you. Or, in some other games, where, where, I would have the option, I won't play with you anymore. And, we feel guilt, when we betray somebody, who we cooperate with. And, that motivates us to behave better in the future. 

So, this gets us a bit far from Tit for Tat. But, if I defected on you, and you were nice to me, I'd feel really bad. And, I would try to make amends in the future. And, and Trivers has argued, that the logic of the solution to the prisoner's dilemma game. The logic to how people can interact over multiple times and lead to mutual benefit, has led to the structuring of our moral emotions. That is, we are naturally inclined in our sentiments to act towards others, as if we are going to play repeated game of social interactions. And, our moral emotions are tailored. So as, so that... To guide us to behave in such a way. That these actions, will be mutually beneficial. But, also to have an eye out, so that we. We can be discriminate altruists. We are nice to those, who are nice to us. We are not nice to those, who are not nice to us. 

In the last two lectures, we've talked a bit about evolution. And, we've talked about the, sort of, mainstream evolutionary theories. As to have some moral sentiments. Could, possibly, be wired into us. We talked about kin selection. And then, we talked about reciprocal altruism. But, at this point, we haven't actually argued it's true. We haven't given any evidence that people actually do have these sentiments wired into them. As opposed to having them emerge, through the course of development. And, we don't have any evidence from other sources, like looking at other creatures. So, the next two lectures are going to fill this gap. 

The next lecture, which is a long one. And, a very, very good one. Is by my colleague and my friend Professor Laurie Santos. It is a classroom lecture, she presented, when I gave this morality course as as a class. At Yale. And so, you'll see her on the podium, giving her lecture. And, I you know. And, and the video was going to include my introduction to her, I wont repeat in here. But, what it is, is it will give you a feeling, for what we know. The strengths and limitations of morality in non human primates. Then, after this, my next lecture is going to to be a very different domain. It's going to ask to what extent are these moral sentiments and moral capacities present in human infants. And, this is a topic, which, I think, is also quite interesting.

## 3 - 5 - 3.5 - Guest Lecture, Laurie Santos - 1_10_14

I thought I'd start with a little bit of a historical perspective today. So imagine if you will with me, you are a resident of New Haven, but not a member of the modern day. Somebody who lived back, back in the days, so back about 350 years ago in a New Haven colony, back in the 1600s. Now, you'd find New Haven looking a lot like you expected to look today back when there were still the nine squares. There was still the New Haven Green that you could go visit and so on. But, you might find a few things that, from our modern perspective, seem a little bit out of place. So, imagine that on this fateful day, you happen to be walking along the Greens with friends of yours, maybe off to grab lunch and so on. You might have been surprised to see what was happening on the New Haven Green that day because the New Haven colony was actually taking part in a public execution of a few criminals who were actually on trial that day. 

So, you know, not just people playing frisbee, there are actuallygallows out there, people being put to death. And on this particular fateful day it was especially exciting because it just wasn't one bad individual who was being put to death, they were actually putting to death nine diabolical conspirators who the report said had committed a wretched crime against God and man. So this sounds really bad. What did these folks do? 

Well, you get a bit of a sense of what these folks did by looking at the individuals who were accused. So if you look to the records of what happened this day you see this list involved. This one guy who's enlabeled here as Mister. Potter. We're told that he's 50 years of age. Less information, though, about the other eight conspirators who were involved. They're just listed as a cow, two heifers, three sheep, and two sows. You might be thinking, what on earth crime did the set of nine conspirators commit, and then you look to the crime that's listed and you say oh, yep, makes a little bit of sense. But these are individuals who put on crime for the damnable crime of bestiality. Now, if you're like me with my modern eyes, you might be looking at this sort of crime and all the conspirators who are put to death. And you might look at the list and think you know, I bet of the nine conspirators there's sort of one mastermind of the whole bestiality thing. 

Another set of individuals that went along for the ride, but you would in fact be wrong according to the records, because if you look at the records, they're very detailed about the lives of these individuals that were involved. And of Mr. Potter, they say the following things: he was a good dude, he was devout in worship, gifted in prayer, he was zealous in reforming the sins of other people, apparently not of other animals, but he was, you know, a totally honorable guy. It was the other eight conspirators who folks thought, that were an issue here. They, it is said, were of, they were unclean devils, and they were in fact diabolically possessed. So diabolically possessed it's thought that they used their, their demonic possession to sort of convince, and seduce and tempt this otherwise innocent guy who had to be put to the gallows because he went along with this damnable crime. 

And so, this strikes our modern eyes as very, very funny. But it shouldn't, in part because you think this is some sort of rare event that I pulled out of the terrible annals of weird New Haven history. In fact, fact of the matter is, back in the 1600s, pre-Enlightenment, there were lots of odd cases of animals being put on trial. Put to death and so on. So this wasn't an unusual thing back 300 years ago. But it strikes us as really unusual. And so today, we want to contemplate why. What changed that made this feel really weird? 

Well, I want to submit that it's, it's not the reason you might suspect. It's not because animals have all of a sudden become much more angelic, and less tempting, right? You know, they're, if you have a dog or cat at home, you know they're just as diabolical, perhaps, as, you know, animals 300 years ago. I also want to submit that it's not the other reason that you might think. Which is that we've become a little bit less barbaric in our ways of capital punishment. Because, as many of you know, in fact, at least in this country, this is not something that we've become less barbaric about. In fact, one of the current moralities of everyday life that I think folks struggle with is what to do with this and whether this is morally appropriate. And just as a sort of editor's note aside, if you're an undergraduate who cares about these issues, you might want to talk to the Yale democrats who are petitioning Connecticut to get rid of their death penalty which is still on the books. 

But, that's just my my little aside. Getting back to the real matter at hand, what was it that changed that makes capital punishment of animals on the New Haven Green seem weird? Well, what I want to submit is that one of the things at least that's changed is that we seem to have a slightly different post enlightenment view of the moral status of animals. And, I want to submit that the view that we have is, in some ways, a little bit worse then what we had before.

Because, the view that we have now is incredibly conflicted. At times we seem quite confused about what we think the moral status of animals really actually is. And when I speak about the moral status of animals, I'm actually not talking about one status that you might be thinking of, which is animals in the status of moral patients. Organisms to whom we might want to decide whether to give moral concerns. This is of course, a controversial and very conflicted issue for us, we can debate about whether it's okay and permissible to use animals as food, as experimental subjects, and so on, but that's not the confusing issue I'm going to deal with. 

The confusing issue I am going to try to deal with is our perception of animals as moral agents, individuals not necessarily who can be punished or so on, but individuals like us who might have moral concerns. In particular who might have psychological maybe neuromechanisms to actually deal with questions of whether something is appropriate or good or permissible or punishable. And these are the kinds of concerns I'm going to ask about today, and the view that I'm going to develop is that we seem to today have a somewhat conflicted view about what we think animal's moral concerns are, if they have any. 

And I'll start with this confusion by sort of turning to Charles Darwin, who was one of the first to sort of think about this issue, this idea of whether animals have moral concerns, and what they might look like, because he and his first writings on this sort of bears the hallmarks of some of these contradictions. 

So he starts his treatise on this in The Decent of Man, by knowing that you have all the differences between man and the lower animals. The moral sense is by far the most important. I mean, Darwin was quick to submit that we are the only species who are doing, the kinds of things we're all doing right now. Right? Sitting in a school of law, that's trying to figure out, what the different moral concerns of society should be. Right? Hanging out in a classroom where we're talking about ethics and moral considerations. We are alone in the animal kingdom in doing these kinds of things. 

And Darwin, of course, recognized that. But as Darwin would go on to say, it seems like if you look carefully, you might expect, you know, any old animal that had these well-marked social instincts, if you're a social creature, you might inevitably acquire something like a moral sense, or a conscience. 

And here's the rub. We seem to think, of course, we're very different from other animals. But based on the fact that natural selection works in the same way in us as it does in other species, you might expect other species with social concerns to develop relatively similar moral senses. And the question, I think, gets even worse when you start looking at the natural behavior of animals, because what we see when we look to other animals are all these examples where it looks like the animals are paying attention to things that seem like moral concerns, where they're worried about other individuals getting harmed, helping other individuals, perhaps enforcing social norms. 

It really raises this question of do other animals have moral concerns, are they a lot like our own and in particular for purposes of this class, what can we actually learn about the human moral sense from terming to the moral senses of other animals? And those are the kind of things I want to sort of submit to you today, and I'm going to try to do this in two different parts. Q

First, I'm going to ask the question of whether or not non human animals share some of the kinds of moral concerns that you might think, are pretty hallmarks of our, our own species, and I'm going to focus specifically on some of the moral concerns you guys talked about a few weeks ago. These are ones that people like Jonathan Haidt and others have submitted that there might be some universal aspects of the human moral sphere. 

And I'm going to focus on a couple different domains. Suffering and harm, domains of hierarchy and authority, and also this question of reciprocity and fairness. And what we're going to see is in all of these cases, we're going to see hallmarks of human-like moral concerns in non-human animals and also some important differences. And so that's going to be the bulk of the talk today but then I thought I would end with a sort of special section or a part two, where we really zoom in on the evolutionary tree and try to take a pick, a peek specifically at our closest living relatives and try to see what, what their moral lives actually say about our own moralities. And one of the things that we're going to see is that when we take that peek and sort of zoom in on our branch of closest related primates, we see some hints that the kinds of immoral actions humans are capable of, seem to be different than the rest of the animal kingdom, but similar to some of the immoral acts of other closely related species. And for that we'll turn to this issue of chimpanzee violence, and sort of what our own chimp legacy says about ourselves. 

And finally if we have time we'll have some big sweeping conclusions, I'm sure we'll solve all the problems of human morality from this approach, you know, and so on. But, First, before jumping to that we're going to sort of start with these universal moral constraints.And I thought I'd start here with this idea of whether a non-human animals share concerns about issues related to the suffering and harm. And the reason for this is I think here's a spot where you might think that nature wouldn't build creatures that care about morality in the same way that we do, right? We have these lay notions of nature that in fact, nature's not at all concerned with suffering and harm. In fact, it kind of promotes it. Nature is sort of read in tooth and claw. We expect to kind of look out at the animal kingdom and see, you know, individuals going for the jugular, you know, sort of Chuck Norris-style, all over different taxa that we look at. But the fact of the matter is is that when you really look at the natural behavior of animals, you find strikingly little of this. Of course, you know, animals do eat each other, and they do eat other animals for food and so on, but so do we. If you actually look at how individuals interact within their own species with other con specifics, you find remarkably little aggression and violence. Or in cases where you do see it, it's rather checked. So it, turning to the kinds of species I wanted to talk about today consider the examples where you might expect to see the most kind of jugular, Chuck Norris style stuff. These are critters out there that have, have weapons that are built, seemingly specifically for the purpose of doing these kinds of aggressive acts. I've just picked, you know, out of a set of animals I could have chosen, these bull elk here, these guys, as you can see, have incredibly impressive weapons that natural selection devotes lots of effort to making sharp and scary and big. But if you look at how often bull elk actually, you know, literally rip each other to shreds with these weapons, what you find is that it's actually not very much. Instead if you look at their natural behavior you see a number of different behaviors that are aimed at showing restraint when using these kinds of weapons. So this, incident that you are seeing here is actually an escalation of about, a couple of different steps. Normally bull elk wouldn't even ever face each other with their weapons so poised to actually hurt each other. First, they do very sensitive things like assess each others' size by walking in parallel with each other. Then, they actually assess each others'strength through the use of vocalizations. Only if that doesn't work, do they escalate to actually measuring sort of antlers versus antlers who's of the right size. And it's only in very rare cases that those sort of attempt don't work, that they actually get to fighting. But even then you don't see them using these impressive weapons in the way that you might expect, through lethal levels of aggression. When natural selection builds in weapons, it often also builds in restraint in which to deal with them. This raises the question about, you know, is this just a funny feature of animal weaponry, or is it the case that animals really are trying to prevent unnecessary harm, perhaps even trying to help each other. And that's where we're going to go with this sort of question about suffering and harm. We're going to explore whether non-human animals actually care about the suffering of others. Do they feel pain when others feel pain? Do they actually feel a motivation to help others? And you've seen some of the stuff in the domain of sort of feeling the pain of others in the readings that you've done this week. Frans De Waal I think does a really good job of articulating these anecdotal cases in which you see animals doing things to each other that suggests they don't like it when a con-specific is feeling pain. So this is a case of, in chimpanzees, when you see individuals like this little guy here actually reaching out and trying to caress individuals who were involved in a fight. You see all kinds of post conflict behavior like this suggesting, at least anecdotally, animals don't like to see others in pain and will act to sort of remedy that. But is there any experimental evidence of something like this? Can you actually see this if you put animals into an experimental situation that will do things to help others. Well there's not much recent work on this topic, but there actually was a lot of early work on this back in the 1960's, I think when the ethics of doing studies with animals were a little bit different. But Rice and Gainer did a first study on this, actually looking at whether rats would be willing to help other rats. And the way they did this was to first train a novel rat on this sort of, weird contraption. The rat learns that every time he presses this he's actually able to lower this sort of rig up there, this sort of rope with a block hanging onto it. And the rat learned that actually at different times the lever would be differentially hard to do. So sometimes it was hard to do it. Sometimes it was easy. All this was, this was the prelude to the experiment in question, which was to ask if the rat would be more motivated to push the lever if it wasn't a block. But a very helpless little rat, sort of, you know, squeak, squeak, help, you know. But this is a question, this, you know, rat may or may not know this other rat in question. Is it motivated to work extra hard to actually help this other rat out? And what Rice and Gainer found was that, in fact, rats would do this. They worked much harder than when it was not a, another rat that was sort of harnessed up by this rig. And they actually seemed to need an actual other rat who was there squealing in pain. If you give them a situation which they can press a lever just to shut off an auditory version of a bunch of rat screams. Just the auditory information they were getting. What you find is that rat's won't normal do that. But seeing an actual other rat in distress caused them to take action. Question is what is the rat representing? How are they doing this? You don't know the answer to these kinds of questions. But you do see the same kinds of helping behavior to relieve stress in a bunch of other species. Masserman and colleagues did this with a famous set of experiments with rhesus monkeys, something very similar. They actually allowed rhesus monkeys to earn the food that they would get during the day by pulling a lever like this one. So a rhesus monkey learns every time he pulls this chain he gets food. But then again on the fateful day of the study the monkey comes in and realizes hey there's a conspecific there. I wonder what happens when I pull the lever. Turns out when he pulled the lever he also got food just as before, but this time every time he pulled the lever he would also shock the other monkey with a series of pretty awful electric shocks. A sort of Peter Gabriel, you know, sort of Shock the Monkey, you know, back in the 1960s. You guys don't know 80s music. It's okay. But anyway, the question is, what does this poor monkey do? He's getting his food from the act of pulling this lever. That's how he get's his food. Will he refrain, knowing that it's actually hurting a con-specific? And the answer trialed out to be, yes. What you find is that most of the monkeys that Masserman tested actually would refrain from pulling the chain that shocked another individual. And in some cases these researchers found that monkeys would forgo getting food for up to about 12 days, which is the point where they stopped the study. Just so long as they could avoid hurting another monkey in the study. And the problem with this work is that because it was done back in the day, I think we have little understanding of what was really going on in these monkey's minds. You know, what were they trying to achieve? Did they just not like the stimulus? Did they really empathetically feel for this other money who was being shocked? . But I think that it is important to point out how impressive this behavior is when you compare it with the kind of thing that humans would do in similar studies because as many of you who have taken Intro Pysch know, this exactly the kind of experiment that Milgrim and is colleagues did with human participants. And if there is a scary authority figure there, human participants are happy to shock another con-specific, sometimes to the point of giving pretend fatal shocks. So, especially impressive when you look at what other humans are doing. Now how about the question whether other animals are motivated to help other individuals. And here you've already seen that there are ways that we can ask non-verbal creatures whether they're willing to do this. The work of Felix Warneken that I think you've seen before has shown that very young human children are willing to do this. It turns out non human animals, particularly chimpanzees, are also willing to do this. [SOUND] Warneken also did a study where a human was trying to do something, namely scrub this block for some reason, and lost her sponge. And what you see is that chimpanzees are actually quite willing to help the human there. This is helping humans, how about helping other chimpanzees? Well, Warneken also did a set of studies where chimps could help other chimps. This is the chimp who's in need. He's actually trying to get into this side of the room because there's some food that he wants but the door is locked. And what Warneken found was that this other chimpanzee on this side will actually work to open the lock so that the second chimpanzee can get in and get the food. Incidentally, the chimpanzee who's helping isn't getting any food here, he seems to be just doing this out of a motivation to help others. So we seem like this helping behavior seems to be shared as well. How about cases of real sorts of helping, not just helping somebody achieve a goal but really giving other individuals sustenance as we do in the case of donating food. Well, this has been a long line of studies in primates with a little bit of mixed results, but there's some species that seem to show evidence of actually wanting to share and donate food to other individuals. And I'll tell you about one of the studies in this regard by Frans De Waal and colleagues in part because it involves as a co-author one of your TS for the class, my grad student Kristie Leimgruber back in her life, back with Frans. But what Christie's project tried to do is to ask, if you give capuchin monkeys the choice to something pro-social or to do something selfish, which do they do. And they gave capuchins the options to pick one of two tokens to trade with a human experimenter. One of the tokens was a selfish token. The capuchins learned that it meant that they were going to get food, and nobody else was going to get food. The second token though was a pro-social token. And what the capuchins learned was that every time they picked this, they actually get a piece of food themselves, but the same piece of food they got, was given to another individual. So it's certainly no skin off their back to go either way. They get food just the same. Are they willing to help another individual out? And when they're given the choice and another individual's standing in there with them, will they actually pick the pro-social token to hand back to the experimenter or will they go for the selfish one? This is just sort of science report showing cute capuchins chewing on tokens and stuff. But, here are the real data, right. What I'm plotting here is how often the capuchin picks the pro-social option so bigger bars equals more pro-social behavior. And what you find is that strikingly across a bunch of conditions when they're faced with their group mates and their kin, capuchins are actually incredibly pro-social, willing to give food to another individual, at least in cases where it's kind of no skin off their back. There were two conditions though in which the capuchins chose not to be pro-social. And I think those are interesting for what they say about the limitations of the moral sense in other animal. One of them is that capuchin monkeys did not act pro-socially when the other recipient was an individual that they didn't know. Somebody from a different group or a different enclosure. In that case what the capuchins did was just sort of choose at chance. They didn't necessarily give the good one. They didn't give the bad one. They just kind of didn't care. So it seems like the donation circle for the capuchins is relatively limited. Perhaps more-so than us, where we often times give food to strangers, perhaps more so than our own family in some cases. But there's a second case that I think is even more striking, which is the case of when the other individual is actually anonymous. In other words, you are playing in this game, but the other individual with whom you're playing can't actually see you, and they don't actually know which choice you're making. Here it's not that the capuchin monkeys were indifferent, they were actually statistically antisocial, so you notice that that bar is actually lower than you would expect by chance. This is capuchin monkeys strategically being a jerk as soon as they're in a position where other individuals don't know what they're doing. I think this suggests perhaps a striking limitation of what you see, at least in human kinds of economic games like you talked about last week, where people tend to be relatively pro-social in dictator games, at least to the extent they think they're anonymous, and we could quibble about whether folks think think that. But the upshot is that when we look at this domain of suffering and harm we see some similarities and some important differences between the human moral sense and that of other animals. In the domain of feeling others' pains, we do see that animals are sometimes motivated to reduce others' pain. You know, again, much more, much shocking from the perspective of thinking about animals as, sort of, being read in tooth and claw and so on, they seem to care about others' pain. But we don't yet know empirically whether they're really feeling others' pain in the way, introspectively, it feels like I might feel others' pain if I watched someone suffering and being harmed in this way. In the domain of kind of being motivated to help, we see lots of examples, at least within the order of primates, that non-human primates are motivated to help others, willing to do, to go out of their way to help another individual achieve the goal. But it also seems like there are important limitations on who they're going to do it for, not for strangers. And when they're going to do it, perhaps not in situations in which they're anonymous and they might not be able to get some positive feedback for it. So that's the domain of suffering and harm, and now I'll turn to the domain of hierarchy and authority. And here is a spot where our lay-intuitions might suggest that we're actually going to see some similarities. Because, as most of you know, human society is very hierarchical and we have status and so on. But the same is true for a number of different animals species. You can look out at, across a bunch of different tacks and see the sort of setup of the same kind of thing you see in human corporations and societies. You know, there's the guy on top, who's proverbially, you know, doing not as nice things to the guys on the bottom. Can poop on the guys on the bottom. That's the, that's the joke. But the act of studying these kinds of things in animals is not actually very new. Because it turns out that a lot of the organizational behavior work that studies how hierarchies work in humans and how hierarchies organizes themselves actually started through studies on animal behavior. And, in fact, they started with a set of Norwegian scientists who had worked out how things like pecking orders work in chickens. Those principles and dynamics worked out for chickens were then directly applied to cases of human hierarchies. So here's a spot where we might tend to see some really close similarities. Problem is that we still don't know, even though animals have these hierarchies. Do they moralize them in the same way that some cultures moralize human hierarchies and human status? Do they think it's a moral violation to not respect a high-ranking member of their group? And, and these are the things that are tricky to actually get at. The kinds of questions about whether animals care about status and dominance is a surreal moralizing sense. And whether they respect authority in these sort of moral terms. I think here's a spot where we don't have great answers in the domain of non- human animals. Nobody's done the right experiments to kind of get at this. But I'll tell you some of the stuff we do know. And what we do know suggests, again some important similarities that we might not have expected between humans and other animals. One of the things we do know is that there's lots of evidence that animals seem to care about status. But my favorite experiment on this is asking the question whether animals really pay to get information about other individuals who are of higher status. Now, we in our species do this all the time. You know, how often I've been at the airport and bought a stupid magazine so I can learn about the goings on of Will and Kate, you know, I don't like to admit in public company. But the fact of the matter is we care about high status individuals, we want information about them and we're willing to pay for it. And so Deaner and colleagues asked the same question. They asked are rhesus monkeys willing to pay for information about high status individuals? And here was the task they set up, so they gave rhesus monkeys the option to choose one of two different targets that would give them juice. So the rhesus monkeys started by kind of fixating here and then they get this choice between target one and target two. And rhesus monkeys get to learn that when they choose target one what would happen is that, after they make the choice they get some amount of juice as a reward. All well and good. Question is what happens when they pick target number two? And what they learn over time is that picking target number two gives them some other amount of juice that can vary over time. But they also get to see an image of another monkey. And the researchers varied whether the image was of a high ranking individual, someone of status, a kind of Will and Kate of the monkey world or someone of low status. Someone that they, they couldn't care about because they were under them in the hierarchy. And what they were able to measure, because they were changing amounts of juices, are there pictures that the monkeys will pay in juice to see. In other words, they'll choose less juice plus the picture over more juice. And there, there are other individuals that the monkeys would have to be paid to see? In other words, they would only choose the option with the picture if they got extra juice to see those individuals. So, that was sort of the set up and here are the data. It's a little bit complicated but what Deaner and colleagues are plotting here is this normalized amount of juice. So bars that go down from the zero, means the monkey has to be paid in juice to see those pictures, so there's negative juice. And the bars that go up are actually the ones that the monkeys were willing to pay in juice to see. In other words, they take less juice to see those pictures. And what you can already see is a trend where monkeys seem to care a lot about status, so all these green bars on the left here are cases where the monkeys had the option to see low ranking faces. And what you can see is that the monkeys had to be paid in juice to see some of these faces. And, some cases a real large amount of juice they had to take just to look at this face. In contrast, in the cases of some of the high status faces, the monkeys were actually willing to pay a lot in juice to actually look at this. They're to willing to take a cost just to see information. And just to put this cost in perspective, I didn't tell you about one other image that these researchers gave the monkeys. These are images of monkey perinea, which is a nice way of saying monkey pornography. These are images of monkey reproductive areas. And what you can see is, yes of course, those are the ones the monkeys are willing to pay a lot in juice for. [LAUGH] you know, they're no Different than some humans. But look, if you look at high status individuals, they're not all that different from this incredibly reproductively relevant stimulus for these monkeys. So it seems like, seeing high ranking faces is very, very important to them. They put a lot of effort into doing this. The other thing that we know is that monkeys actually also put a lot of effort into respecting the kinds of hierarchies they find themselves in. The monkeys that you see in the hot spring are just a small group of the monkeys in any group that's come upon the hot springs. Because the hot springs are kind of an exclusive club, only the high ranking individuals get to go in. And this means that the low ranking individuals have to stand out on the side in the cold, often in


the snow, Waiting there, while the kind of
relaxing, sort
of, royalty of the monkey world gets to go
in them.
And the question is, why don't the low
ranking
individuals just kind of fight this or
jump in?
We don't know exactly the answer to that
question, but what we see
is tremendous respect for the hierarchy,
even in cases where it could mean
a low ranking individual could freeze in
this sort of situation, or not
get the kind of comforts to which it feels
it should be accustomed.
But it's hard to actually measure what
this really means for the monkeys.
How much do they think they need to toe
the line when they're
dealing with high ranking individuals who
tell
them what they should and shouldn't do.
And Horner and colleagues tried to get at
this in a
slightly different way.
What they were trying to do is to ask
whether
in this case chimpanzees, would be willing
to actually toe
the line when they saw information about
how one is
supposed to get food, in a sort of, simple
tool task.
And so I'll show you what this looks like.
This work was actually conducted out at
the
Yurkey's Field Center, which looks
something like this.
So chimpanzees live all in this big group
over here.
And the way they were able to teach them
about this new tool was to sort of,
set up this sort of funny tool set up on
the side of the cage over here.
And chimpanzees in this tool setup were
allowed to put
different tokens into one of these objects
to get out food.
Now all of the, the objects that you could
put tokens into would actually work.
But the chimpanzees were given a choice of
which one they wanted to use.
And they varied, of course, the kind of
object that you set up.
Sort of the different look of the
different objects.
All of them are going to work just as well
to get food out of.
Question is, who did you see using each of
the two objects before you came?
And they varied the particular individuals
that
the, the chimpanzees got to have access
to.
One of the individuals was the highest
ranking female, the alpha female of the
group.
She was using the weird object on the
left, the black one.
The other individual was a low ranking
member of the group.
She was actually using the object on the
right.
Question is, the subject knows both of
them work.
He gets to see these individuals
use the objects, and the question is,
which of
the object is the subject himself choose
to act on?
They both give food, but what you find
is that the chimpanzees don't treat them
that way.
What the chimpanzees do is about 90% of
the time, they're imitating the other
high-ranking individual.
Suggesting they either feel that that
one's more valuable,
they're trying to be like the high-ranking
members, maybe they
think they're supposed to do it this way,
maybe
they think it's sort of the moral thing to
do.
We don't know
exactly the reasons why, but what we do
see is that in their behavior,
the chimpanzees are paying a lot of
attention to what the other individuals
do.
And they're conforming to what they see
the high status individuals doing.
In much, at least the same behavioral ways
we see humans doing in a lot of societies.
So that's what we know about hierarchy
norms
in, in nonhuman animals and what we've
seen
is of course, lots of individuals seem to
care about hierarchy, this sort of pecking
orders across
all kinds of different taxa.
And we also see that some individual
species,
in this case the rhesus monkeys, care
about status.
They're willing to pay for information
about it and they
also seem to act in ways that are like it.
What we don't yet know if nonhuman animals
also have some of the features that we
have in our own society where they really
moralize this authority structure.
Not as something
they sort of have to do because they'll
get punished if not, but as
something they, they think they ought to
do and other individuals ought to do.
These are really open questions in this
domain,
but the exciting thing is that researchers
now have
some methods where they can start tweaking
these
things apart and potentially asking some
of these questions.
And so, I'll turn to the last domain here.
And this domain of fairness and
reciprocity.
And again, like suffering and harm, this
might be one where you think,
okay, this is a spot where
humans are completely different than
nonhuman animals.
Of course, again, we're sitting here in a
law school in a classroom.
No other species are doing these kinds of
things.
Probably no other species would be willing
to take
the kinds of costs over equity that we
see.
This is the Occupy Wall Street folks that
are off in New York right now.
We're inside not in the rain, these guys
are sitting outside in the rain over
things
that they perceive as violations of
justice and
equity that are going on in Wall Street.
And no matter what you think about this
you might think that humans
are doing some pretty costly things when
it
comes to dealing with their own equity
norms.
Question is, do we see these kinds of
things in other animals, too?
Do animals even care about reciprocity?
Do they have these intuitions about
fairness and how it works?
And perhaps most importantly, do, will
they take a
cost like we will to punish those who
behave unfairly?
And so you've already seen in the course a
little bit about the fact that non-humans
care about equity.
I think that Professor Bloom
talked before about the case of vampire
bats who seem to
reciprocate in their, sort of, blood
barfing to one individual or another.
I'm showing you this image to show that
seems
like these guys care a little bit about
cheating.
This is an individual diagram, which is
showing a vampire bat
behavior where one bat is actually rubbing
the tummy of another bat.
What he's doing is to check and see if the
tummy is distended, because, you know, you
might lie about what you ate for dinner,
but
your tummy doesn't, and so if the tummy's
big,
then there's some expectation that this
guy's going to vomit.
But clearly some, something like
reciprocity going on behaviorally.
Also see other asp, other examples of
things like
tit for tat and reciprocity in the animal
kingdom.
This is the case of the black hamlet fish.
This is actually black hamlet fish in
flagrante delicto.
So if you're don't want to be looking at
black hamlet fish porn you might turn
away.
It's even more a little bit scandalous in
that
these guys are actually hermaphrodites.
So one of the problems when you're a black
hamlet fish and you want to mate
is that you have to decide who's going to
be the male and who's going to be the
female.
It's not just a problem for sort of social
reasons, it's actually more of a
reproductive problem, because
it's bad to be the female in the sense
that your reproductive effort is giving up
an egg.
Which is very large, it's very
reproductively costly.
It's much easier to be a male and just
give up a single sperm
for your reproductive effort.
So what black hamlet fish do is that they
turn-take, they do
a little bit of a tit-for-tat about who is
the female first,
and then the next one will do it, and then
as soon
as an individual defects, you can see that
both individuals will swim away.
And choose not to mate with each other in
the future.
So we see these kinds of cases of
reciprocity in
animals, but can we really see examples of
true fairness empirically.
Not just the kind of anecdotes of
behavior, but real cases where we ask
animals about fairness.
And again Franz De Waal and his colleagues
were able to ask
this in the species that I work with here
at Yale, capuchin monkeys.
They were able to capitalize on a
phenomenon in which
capuchins are actually somewhat willing to
share food with each other.
So, if one individual has this kind of,
whoops, this
big bowl of food there, and there's
another individual without food,
sometimes that individual will choose to
kind of eat next to
the other guy sort of dropping crumbs of
food so that
the other guy can take it.
Again, rather than sort of sit all the way
on the
other side of the enclosure so that you're
not near another individual.
What Frans said is, well, maybe we can
capitalize on this food
sharing to ask if the monkeys really care
about fair payment for labor.
And they did that by setting up this
sort of bar pulling task that was slightly
tricky.
Both capuchins had to work together to get
access to food, but only one of
the individuals, the guy on this side, was
going to get any food in his little bowl.
And so he set up
two different kinds of conditions to see
whether these capuchin
monkeys first would share and whether they
would share fairly.
One of the situations was cooperative.
So in one of these cases the two capuchin
monkeys had to work together.
The subject monkey who got the food got
helped by the other guy.
The other condition was solo.
The other guy didn't help at all, he just
kind of
sat there and the first guy did all the
work.
The question is does the capuchin monkey
take that
into account when he decided how much food
to share.
And the answer is in fact that he does.
These red bars are cases where the two
capuchins worked together, and
then what I'm plotting is the number of
food pieces that got shared.
What you can see is that in both cases,
even over trials capuchin monkeys
were wiling to share more in cases where
the other guy helped them out.
The sort of sense of perhaps something
like fair payment for labor.
De Waal and colleagues also actually
looked
at whether or not capuchin monkeys, an
individual
capuchin monkey might expect that he's
going to get pair, paid fairly.
And this is in a series of studies by
Brosnan and De Waal trying
to look at whether monkeys expect to get
paid the same amount as another monkey.
In this setup, they did something similar
to Christy's experiment that I showed you
before.
The monkeys are actually going to be
trading tokens for
pieces of food but they are going to in
different amounts.
One of the monkeys, this monkey who's the
stooge, who's not the subject of interest
is actually
going to get paid something yummy.
He's going to get a grape or something
delicious.
The other monkeys going to get paid
something
that's worthy, something he would
ordinarily find okay.
But it's just kind of okay.
It's not like super great.
It's something like a green pepper, a
piece of cucumber or a monkey biscuit.
And the question is, even though we know
ordinarily monkeys would find these kind
of meh
foods okay, do they react negatively to
them
when they know another individual is
getting paid more?
And what Sarah Brosnan and
colleagues found, I'm going to sort of
skip this slightly weird video here, but
what they found is that capuchin monkeys
do care about this a lot.
In the cases where they got the lower
award, when another
individual got more, you saw situations in
which monkeys actually refused
to exchange, so they just through the
token they were supposed
to trade out and wouldn't trade it with
the other experimenter.
You also saw situations in which they
refuse to accept the reward.
This is an otherwise good
piece of food that a capuchin won't like,
but
as you can see in this picture the monkey
sort
of throwing it on the floor because it's
not
nearly as good as what the other guy got
before.
It seems that monkeys care about cases
in which they get less than another
individual.
But it seems that this is true not just
of, capuchin monkeys, it
seems to extend broader, more broadly
across
the taxon than we might have, thought.
In fact, Range and colleagues actually
looked at whether pet
dogs were able to show the same kind of
aversion to inequity.
And they did it for, by paying the dogs
not to trade But to do this,
sort of, simple kind of handshakey gesture
that,
maybe many of your dogs know how to do.
First they did the handshakey gesture with
this border collie,
who is the subject, she got paid a very
low reward.
Then the dog to the right did the
handshakey
gesture and she gets a very good piece of
food.
You can see this border collie on the left
is looking like, wait a minute, what's
going on?
Question is, do we see the same kind of
thing, a refusal to
participate, or a refusal to eat their
rewards, and in fact you do.
I won't show you the data I'll just
show you this lovely picture of a border
collie,
like aw, like that is like the biggest
border
collie dis in the history of border collie
disses.
But the upshot is that you see these
kinds of behaviors where within the animal
kingdom, you
see an aversion to at least one kind of
inequity, kind of inequity I'll call here
disadvantageous inequity.
These are cases where you yourself, the
subject, are
getting worse than someone else and you
react negatively.
But this is the limit of it.
It turns out, if you look across the
animal kingdom, you don't
see cases of a different kind of inequity
aversion that you might expect.
And that's a case that you might call
advantageous inequity aversion.
This is a case where there is inequity,
but you are benefiting.
Somebody else is getting less than you,
but it's not fair.
And this is the kind of thing we do all
the time.
I mean, these are what
the folks who are out at Occupy Wall
Street are worried about.
Many of them are people like Cornell West
or Russell Simmons.
you know, they're not hurting and getting
their houses foreclosed on, but they still
think
something's unfair, even though they might
potentially
be benefiting from the folks on Wall
Street.
They're still willing to protest.
And this, it turns out is something it
turns out we don't see in other animals.
If you look at the two cases I showed you,
you can get hints of this right here.
you know, check out the dog who is getting
the bigger
one, you know this other dog is reacting
in horror but he,
the second dog's kind of like well I'll
trade with you, if you're willing.
you know, he's not sort of stomping off
and starting a protest, he's totally
happy to go along with the situation where
he's getting more of a reward.
Sarah Brosnan reports the same kind of
thing in capuchin monkeys.
She reports that sometimes when this
monkey throws the reward
away, the second monkey will reach down
and take it.
you know, like well, if you're not taking
the scraps, you know, I'll take them
myself.
Right.
These aren't the hallmarks of advantageous
inequity aversion
like we'd expect to see in humans.
And so this seems to be a big difference
between
what we see in our own species and other
species.
But there's another difference in the
domain of
equity and fairness that I think is really
important.
And that's cases of whether animals are
willing to punish these violations of
equity.
And you've already seen, I mean, of course
you know
from lay behavior that humans do this all
the time.
You've seen cases experimentally in which
humans are willing to do this.
Like in the case of the Ultimatum Game.
So if Professor Bloom was pan, playing
this game with
you guys in class, and your partner had
all this
money, and he was only giving you two
bucks of
all that wad of cash, you might reject the
offer.
And say you won't take it.
You'll take a cost, to deliver this
punishment to another individual.
And a group of researcher in Leipzig,
Germany were
able to do the same kind of thing with
chimpanzees.
The way he did it was with a similar sort
of pulling setup.
This guy over here would be the proposer
chimpanzee.
And he gets to make
the first selection of a couple different,
different reward distributions.
So this one at the top looks like it's
pretty fair for both individuals.
you know, the proposer's going to get this
one, the other guy gets this one.
This one looks a little bit unfair, you
know, he's only going to get two.
But this guy makes the first selection.
But he only gets to pull it a little bit.
It gets stuck.
At that point, the second guy has to chime
in and do the complete pull.
What this means is it's exactly like the
setup of the
ultimatum game you guys played.
One of you is making an offer, but the
other guy chooses to accept and reject.
The capuchin, the chimpanzee in this case,
can choose
to reject just by not doing that second
pull.
So he could reject the offer if he chose
to.
The question is, does he do it, and under
what situations does he accept?
And what the critical cases in the study
were, were cases
where the proposer chimp had the option to
do something fair.
He could choose a distribution of raisins
that
was five or five Or he could do something
unfair,
he could choose eight and just give the
other guy two.
And the question is, which did the
proposer choose?
Turns out proposers in this case were
relatively unfair, but
the more interesting question is what did
the receiver do?
And what you find is that chimpanzees
don't play like humans, they play like
economists.
Because what they do is that they actually
never reject the unfair offer.
As long as the other chimpanzee offered
them something
that was above zero, they were willing to
accept it.
They rejected the zero offers, but they
took any amount of food that was
there, suggesting they're not willing to
inhibit this urge to take this bad payoff.
They can't sort of stand up and punish the
other individuals for their unfairness.
In fact if you look across human
populations, the chimpanzee performance
looks only like one
other population of humans, and that's
populations
of humans who have lesions in their brain.
Fact Ernst Fair and his
colleagues were able to study this by
actually
creating temporary lesions in normal human
brains, so you'd
bring undergrads into your lab, and you
introduce them
to this wonderful device Called a
transcranial magnetic stimulator.
I won't get into the details of how this
works, but basically it creates
a magnetic pulse that develops a small
and temporary lesion wherever the coil is
positioned.
So you put the coil in front of this spot
in undergraduates' frontal cortices,
gave them an unfair offer in the ultimatum
game, and what he found
was that none of the folks he did this to
actually showed any rejections.
They could say, yeah, it was unfair, but
they took the two bucks anyway.
And, this is the hint that I think is
really important
from studying animals is we see maybe the
spot where we
start to see some differences in the
behavior of animals and
humans, maybe our inhibitory control in
this is actually quite helpful.
And so in terms of reciprocity and
fairness what
have we learned?
Well we've seen lots of animals do things
that
are reciprocal, they perform actions that
seem very tit-for-tat.
Not always clear what the psychological
mechanisms are.
In the same case we see lots of examples
of
animals in this case rejecting some of
these unfair payoffs.
But little evidence that they care about
advantagous inequity.
They just care about their own stake in
equitable situations.
And we see strikingly little evidence of
costly punishment
across other animals.
This might be something that's truly
unique to our own species.
So now I've gone through all these other
cases,
in the short time I have left I actually
want to turn to these issues of what we
can actually learn from studying our
closest non human relatives.
And when I was thinking about developing
this lecture, I
really wanted to stay true to the goals of
the course.
So I could've shown you more studies on
different moral concerns in animals, but I
thought I would sort of think more about
at least some of the goals that were
stated in the syllabus of this course.
And if you look at the syllabus, hopefully
some of you have, you
know, looked at the syllabus, probably
important to do, you would just see
is that goals of thinking about morality
in humans, of course, is to
understand some aspects of transcending
kindness and all the good things we do.
But also these era, areas of unspeakable
cruelty.
And most of the time, when we're
looking for moral concerns in animals,
we're thinking
about the kindness part, we're thinking
about
stopping harm and helping and all this
stuff.
But we really might get more insight into
our own nature,
or at least the part of our nature that we
really
need to come to grips with if we take
seriously this
idea of trying to study the principles
that underlie unspeakable cruelty.
And what I mean here are these cases where
humans can
be aggressive and violate the moral norms
of, of societies in
ways that are completely egregious and
involved lots of lethal aggressive
harm often to individuals who are a part
of different out groups.
you know, if I had to put my finger
on the biggest moral atrocities of human
culture they
would all have this flavor of a large
scale
violence, group on group, often pretty
aggressive and pretty lethal.
And so if you want to take a look at where
this
stuff comes from, you might say okay,
let's take a broad swash.
We'll take the whole animal kingdom, and
we'll ask,
where do we see this stuff in other
species?
you know, it's in us, we do these awful
immoral things, gotta be all over the
place, right?
No.
If you look
at all the species out there, the only two
species in which
you see lethal aggression are those two
little red points over there.
And if we scroll in, we see that it's
just us, and one of our two closest living
relatives.
Not both of them, just one of the two.
So here we can scroll in at a slightly
different
version of that tree, looking at the other
ape relatives
that we have, and we're really scrolling
in on the
branch that includes just us, and our two
closest living relatives,
chimpanzees and bonobos.
And as you've seen from some of your
readings,
we can course unfortunately see lethal
violence in us.
We also see this sort of hallmark in
chimpanzees, but we don't actually
see it, in bonobos, who are equally
closely related to us as the chimpanzees.
So what's going on?
I thought I'd end the lecture today by
kind of
scrolling in and seeing if we can get some
insight.
And the insight starts by sort of looking
at chimpanzee society and what we know
about it.
And the great thing is that we know a lot
about
chimpanzee society, mostly from the
starting
pioneering work of Jane Goodall and
colleagues.
We start to look at what chimpanzee
society was really
like and they learned lots of great things
about chimpanzee society.
They learned lots of information about how
chimpanzees use
tools and were more cognitively
sophisticated than we thought.
But they also learned lots of negative
things that chimpanzee society
isn't the kind of idealic bliss that we
might have thought.
And I'll give you a little quick video to
give
you a sense of what what some of this
actually involves.
See if this works here.
>> In the tree of life.
>> Can you guys hear?
>> Are often occupied by species that
look poles apart.
But sometimes, what separates species is
more social than physical,
as it is with our closest relatives,
chimpanzees and bonobos.
[MUSIC]
[SOUND] Chimpanzees and bonobos live in
similar jungles
in equatorial Africa.
They look alike, live in the same
size communities and eat similar foods.
Yet.
[SOUND].
Violence is a fact of life for
chimpanzees.
Battles between neighboring communities
are common.
[SOUND].
So is the physical abuse of females.
>> Oops.
It got cut off.
But you can basically get the point here.
What we're dealing with is a species that,
if you look at its natural behavior,
of course it looks nice sometimes, but it
bears a hallmark to a relatively violent
species.
Lots of intragroup violence.
Individuals who are beating up on
individual females.


There's cases of infanticide.
It doesn't look very pretty, but it
actually gets worse if you look
at how the intergroup violence among
chimpanzees
actually plays out, because we see lots
of hallmarks of a species that cares a lot
about what's going on
in the other community and whether you
can resources potentially from that other
group.
So what you're looking at here is a
picture of chimpanzees who are giving pant
hoots.
These are vocalizations that are useful
for keeping the chimpanzee communities
together.
And the idea that chimpanzee communities
range over a big
amount of space, as you saw in the Jane
Goodall article.
The goal is that they have to keep tabs on
where everybody is, not because there
are other predators for chimpanzees out
there, although
man is a pretty bad predator for
chimpanzees.
The biggest issue is potentially violence
from other individuals, and the pan,
who is, is worth hearing, I don't have a
vocalization, but it goes something like
this, is like, [SOUND] and so that's, you
know, if you hear that, you're like,
[SOUND] you know, this is a scary-ass
thing, yeah, you're, yeah, this is good.
[SOUND] But see, my pant hoot is not that
good because if you were a
community of chimpanzees that didn't know
me, you
would react, not with clapping but like
this.
If you were a male you would drop the food
out of your mouth, literally,
reach over and grab the penis of the guy
next to you and just say,
you know, are you with me man, because
there's another chimpanzee over there,
he's pant hooting so.
[LAUGH] Maybe next year I'll get good
enough.
That, you know.
But the point is is that
inter-community, inter-community
interactions are incredibly scary.
Why?
Why do they have mechanisms to sort
of promote and worry about where everybody
is?
Well, the reason is because of what you've
already seen, which is that
the way that communities typically
interact is one that involves a lot of
lethal aggression.
This is the case of chimpanzees being much
more quiet than they're normally used to
being.
They're sort of hunched down and engaging
in a border patrol, where they're
leaving their own confines and going to an
area that's outside their territory.
Why are they doing that?
Well, you know, there's lots of
speculation but what do they
do when they get there and they find a
lone individual?
They often do horrible things like this,
where the individuals
together will gang up on an individual
chimpanzee, often one
that's weaker and smaller than them, so
it's
not like they're doing this in self
defense.
And when they're done, you see images of
chimpanzees that look like this.
This is a little bit gory, so turn away if
you're scared.
But they look like chimpanzees that don't
look very good when they're done.
What you can see is this chimpanzee has
gash wounds all over his body.
If you look here, his testicles are
actually missing.
In this case of this chimpanzee, they were
found down the road.
So this doesn't result in very pretty
things for chimpanzees.
You can look
back, the gory chimpanzee is gone.
But in cases where this has been studied
in detail, where you can document across
communities how this plays out, we
sometimes
get very scary answers to what we've seen.
And you guys read in the case of Jane
Goodall's report, what
happened in Gombei over the course of four
years in the 1970's.
Basically what happened was that there
used to
be two communities of chimpanzees, and
over time
if you look back four years later, it
ended up just as one community of
chimpanzees.
What happened to the other communities?
Well you guys saw it, I'll depict it a
little bit here,
not with, photos of the chimpanzees
because we don't have them, but by,
what I think is a really fabulous artistic
exhibit by a photographer named
Allison Raton who did a photography
project on the four years at Gombei.
And the way she did it was to depict what
happened not with chimpanzees
but with humans which I think is sort of
far more compelling if only disturbing.
But what Jane Goodall described as you saw
as
a case where these two communities used to
be one.
They used to all be kin and then they
slowly split over time
into being sort of separate communities
that were a little bit more
individualized.
And this was all well and good, until the
researchers started
seeing more and more of these kinds of
late night border patrols.
Cases where individuals went over, and as
they started seeing more and
more of these border patrols, they also
ended up finding more and
more kahama Chimpanzees who were killed in
often very, very brutal ways.
And as time went on and the researchers
paid more
attention, they could actually see
instances of what was actually happening.
Where chimpanzees were, as I showed you,
very quietly, in this
border patrol getting together and
seemingly ganging up on another
individual.
Often one that was less strong than them
and less helpless.
And as this happened over time, more and
more members of the kahama community died
until
all the males in that community were in
fact, dead.
The females left and transferred into the
northern
community, and that was that for the
kahama community.
So I think we see it with human terms,
that often feels more compelling.
But what are the similarities here?
We a lot of similarities in the chimpanzee
legacy with what we see in human warfare.
We see this lethal coalitionary
aggression, what does this mean?
This means deadly force on the part of
bodies of individuals who
leave their group and go to a neighboring
group,
seemingly for the purpose of causing
warfare, or causing aggression.
There's also the hallmark that happens not
within the group but between groups of
individuals.
And it typically, as Richard Raynom often
points
out only involves males and that the
targets
of these things are mostly males or at
least, they seem to be targeted towards
individual males.
And there also seems to be something like
the spoils of
war, where the victors in these cases get
access to more
land, more resources, in this case even
more females.
So, this is our legacy and it's a hallmark
of something we should find very
disturbing because there's
a lot of similarities in terms of what's
happening
in chimpanzee lethal violence and what's
happening in humans.
But of course, there's this other case I
was talking about, the case
of the bonobo, our equally closely-related
relative,
who doesn't show any of these hallmarks.
Can we figure it out if some sense what
went okay with
the bonobos to cause them not to have some
of this stuff?
And so for them, we sort of turn to bonobo
social structure and
bonobo social structure looks a lot more
laid back than you see in chimpanzees.
And its in part because they don't seem to
have the
kinds of violent society that we see in
the chimpanzee society.
You see no inter group violence.
No lethal rating.
In fact cases of inter group interactions
are
always quite pleasant with individuals
behaving very socially.
You see extremely little intragroup
violence.
Males just aren't as mean to females as
they are in chimpanzees.
And as I said finally, little male
violence towards females, no
evidence of infanticide, it just seems
like a very chill, happy society.
Well, what is going on?
Well, it seems, as researchers have put
forward,
that if you study bonobo social behavior,
the
bonobos are in part, not violent because
they seem to choose to make love not war.
Seems that socio-sexual behavior
in the bonobos seems to be a really
important mechanism by
which they get around a lot of these
problems of violence.
And I'll leave it to Amy Parish in this
video to tell you a little more about
that.
>> For the past decade, Amy Parish has
been
observing bonobo behavior at the San Diego
Wild Animal Park.
She's seen them go at it in every way
imaginable.
[MUSIC]
>> This gets a little dirty, so you can
hide your eyes.
>> [LAUGH]
>> You get standard heterosexual
interactions which are often
face to face, the way they are in humans.
You also see what we call ventral upright
matings where a male and
a female will hang together out of a tree
suspended and have sex.
Males have sex with other males in what we
call
rump-rump rubbing, where they stand and
rub their scrotums together.
We also see something
among males called penis fencing, where
males will suspend off of
branches by their arms and rub their erect
penises back and forth.
[MUSIC]
>> And then a very remarkable behavior
in which two
females rub their genital swellings
together in rapid sideways motions.
[NOISE]
>> So, what's allowed bonobo females
to establish such peaceful relations with
males?
[NOISE] Parish believes the answer is
female solidarity.
[NOISE]
>> By cooperating with each other and
solidifying
their bonds and reducing any tension that
does exist, they're
able to form alliances with each other and
cooperatively dominate males.
And this changes the whole balance of
power and the whole
social dynamic in the group and makes it
radically different from chimpanzees.
>> And why bonobo females evolved this
strategy when chimpan.
>> Whoops, we'll get to that part
later.
But the upshot is that Paris's hypothesis,
and
the hypothesis of others, is that it seems
like some of the violence gets cracked
down
upon in part because females have these
strong bonds.
The males can't co, form coalitions to
get, against them because
the females have their own sorts of bonds
and coalitions themselves.
And so this raises the kind of
million-dollar question in the field of
primatology right now, which is, why is
it that female bonobos can develop these
bonds,
but bonobo why is it that bonobo females
can develop these bonds but chimpanzee
females cannot?
And this leads to I think the ongoing
hypothesis that Richard Wrangham has been
pushing with, which has a book of
the same title, called The Demonic Males
Hypothesis.
The idea is that something about the
coalitionary
behavior of males that's due to ecology
drives
these kind of patterns.
And again, I'll leave it to Richard to
tell you himself.
>> And why have the noble females
evolved a strategy and chimpanzee females
haven't?
>> It looks as though a relatively
simple change in the feeding
ecology is responsible for this dramatic
difference in sexual
behavior.
They, the nobles live in an environment.
Where you have herbs much more
continuously on the ground.
And there are chimpanzees that live in
similar forests, but wherever
those forest are occupied by chimpanzees,
they're also occupied by gorillas.
>> The gorillas eat the food on the
ground, leaving the chimpanzees heavily
dependent on fruit trees.
To get their share, the female chimps
forage alone.
>> The mothers with babies ranging in
age from one
to about five, can't move as quickly as
the males.
I mean, one infant is up here playing in a
tree, and a couple
are nibbling slowly and the mom has had to
sit and wait for them.
So its absolutely typical that the males
reach the big feeding ground first.
And the males have finished all the food
by the time
the mothers arrive.
So the mothers, disperse, away from each
other and away from the males.
And that means they can't have much
opportunity to form bonds with each other.
>> The simple fact that there was food
available on the ground
appears to have been the force that drove
the evolution of bonobos.
Wrangham believes the catalyst was a
long-lasting drought
two million years ago in what is now
Zaire.
The plants and the gorillas that depended
on them died.
It was tough on the chimpanzees, but they
could live from the fruit in the trees.
When the rains and the plants returned,
the gorillas didn't.
[MUSIC]
Now the chimpanzees can get to the food on
the ground.
In time, they evolved into bonobos.
It's been suggested that, that same
drought forced our
ancestors out of east Africa's forests and
onto the plains.
>> And once you had drying in
a Savannah area, then conditions became
quite harsh.
It was impossible, for early humans to
travel
around in groups together in the ways the
bonobos do, and therefore, for females to
form
alliances and dominate the males in the
way that
happens in bonobos.
But a little bit different climatic
history.
A little bit different in our food history
and we might of
evolved to be a totally different,
more peaceful, less violent, more sexual
species.
>> More sexual species is what he's
ending on there.
But, but this is the idea behind the
demonic males hypothesis and it's one
of the few reigning hypothesis that we
do have for the difference between
chimpanzees, bonobos
and the idea here is that, because
chimpanzee females
weren't able to form bonds together, they
develop psychological
mechanisms that prevented them from sort
of clamping down
on the violence in the same way that
bonobos can.
And this has led to the kinds of violence,
the kind of inner group violence you see
among chimpanzees.
The sort of run away selection on the
coalitions between males
that can't be clamped down by females
because of feeding ecology.
The claim is that the same kinds of
mechanisms led to
the kind of inner group violence that we
see in humans.
Something of the same kinds of mechanisms
that led
to the inner group violence that we see in
chimpanzees are probably in us too to the
extent
that our feeding oncology was pretty to
similar to chimpanzees.
Question is what are the psychological
mechanisms?
And you know, how can we kind of deal with
them or sort of clamp them down?
And these are big questions that we don't
have big answers
to but we get good hints by studying the
similarities and
differences between us and our closely
related primates.
And folks are now trying to look at these
sorts of issues.
But, rather than talk about that, since we
don't have good answers to these kinds of
puzzles,
I'll sort of talk a little bit about,
well,
what are some of the conclusions we can
make?
What are some of the moral insights we can
get about humans from turning to animals?
And I'll kind of return to where we
started, which is this idea
that even since Darwin, we've known that
we have this conflicting view of animals
as moral agents.
This idea that like, of course we're
different from the lower
animals, of course our moral sense is the
important thing that separates
us, but on the other hand we expect
animals to have something
of a moral sense and the question is, what
is that sense?
And what we've learned is that, at least
some of the
universal hallmarks of human moral
concerns, some of the universal domains
in which we care about moral issues, we
see those same
kinds of domains cropping up in animals
where they care about hierarchy.
They care
about helping others to feel better.
They care about sharing inform, food and
information, about where things are.
And they care about actually doing nice
things for others.
We also see important limitations in all
of these different domains.
What we've seen is that, in the case of
capuchin monkeys, it matters to
whom you're doing these nice kinds of
things, and to whom you care about equity.
It matters what situations under which you
show it.
And in the case of equity specifically,
we've seen that other animals care about
equity, but only in
these do, in, in the cases where it
actually applies to themselves.
They care about disadvantageous
situations, but not advantageous ones.
And finally, I think we've seen perhaps
the
most important difference which is that
even though
animals have all these hallmarks of what
it
means to have a moral concern, we see no
evidence that they, step up to the plate
when those moral concerns are violated and
are
willing to take a cost to punish other
individuals, as in the case of the
ultimatum game.
Seems like we alone may do this, and
we alone may do this for this interesting
reasons.
Which is that we have brains capable of
inhibiting
prepotent desires like, oh, just take the
two bucks.
Or oh, just do the easy thing.
We can step up to the plate in part
because we have these
mechanisms that allow us to inhibit
desires
that we would normally want to fulfill.
And in the second half we sort of switched
gears from these
universal moral concerns, all these
aspects of kindness that we see to
try to see if we could get some insight
into the unspeakable cruelties that our
species are capable of.
And what we dealt with was that we really
need to come to grips with the fact
that we share a chimp legacy of
inter-group
violence, one that's not shared throughout
the animal kingdom.
But it is shared between us and
chimpanzees.
And what we realized is that we might be
able to turn to cases of chimpanzee
inter-group violence and to the
evolutionary pressures that
led to that, to get some insight into
what's
going on in our own inter-group violence.
And the scary thing that I think we
learned is
that whatever those pressures were for
chimpanzees, they seemed to
most likely be the same pressures that led
to our
own psychological mechanisms and our own
cases of inter-group violence.
Again, we don't have great insight into
what
exactly those mechanisms are, but we know
that they're
the ones that are shared with chimpanzees
and
perhaps no other creature out there on the
planet.
And sort of that's where we are, and I
want to
end with sort of some of the implications
of some of this
stuff, because I think there's another
worrying part of this evolutionary
story that we need to deal with, which is
that chimpanzees have
all the psychological mechanisms, and, and
devices that they have, their
own strength and size, but we go beyond
all of those things.
Because part and parcel of our own human
evolution is developing our own forms of
weapons,
and these weapons are way more awesome
than
weapons we see in the other animal
kingdom.
I mean, they are capable of real
lethal coalitionary aggression.
You know, in nuclear holocaust, we can do
these things with the weapons that we have
developed.
The especially scary thing is that, unlike
the weapons of the
animal kingdom, we've developed these
things really quickly in evolutionary
time.
Absolute blink in evolutionary time.
And we've gone from just being humans with
sticks to humans with nuclear weapons.
And what that means is that we probably
haven't
done the evolutionary work that other
animals with weapons
have done to develop restraints through
natural selection that
deal with the behaviors under which we use
these weapons.
These bull elk aren't willing to use their
weapons.
They go through really careful
trajectories to decide when they're
appropriate, and they're always
restraining from what they could do.
It's not clear that humans have build the
same evolutionary mechanisms to deal with
our own weapons.
And that I think is the scariest
evolutionary message.
The hopeful message though is that what
we've seen is that some of
the differences between the moral senses
of us and
other animals should be the ones that give
us hope.
Because what I'm telling you is that one
of the things that
we have that it seems like animals might
not bring to their,
on their own moral concerns, are really
rich processes, we're inhibiting our
own desires and sort of curbing what we'd
really like to do.
We also have a lot of cognitive
flexibility that we can bring to bear.
Basically, taking the old mechanisms that
he
have for kind of coalitionary aggression
and maybe
switching them around in positive ways.
It's not clear what the policy messages
are for these kinds of things.
But I think a few quick things come to
mind.
One is we should use in our, our,
inhibitory
control to stop the proliferation of
really bad weaponry.
Given that we don't have the good bull elk
skills of curving these things we
might, use, need to use our frontal lobes
to cut some of these things down.
The other thing we should probably do is
get creative with our coalitionary groups.
One of the cool things about hum, being a
human is that
we form groups on the fly.
We can be Americans or Red Sox fans or
Yale Students, and so on.
We can create these groups de novo.
And one possibility is to start creating
coalitionary groups that
actually make sense from the perspective
of limiting lethal inner-group violence.
Making new kinds of coalitions across old
separate groups that
can actually promote, being a more
peaceful, more moral species.
And finally and this is Richard Wrangham
and not
exactly me, you ask Richard Wrangham what
you would
need, what we as a species need to do to
develop a moral utopia, what he says is
that
you just have to get rid of all the males.
And then we'll be a moral utopia.
He's that, slippery slope about his
species, but, I think that
this isn't exactly the wrong kind of idea
because perhaps thinking
about ways to make political power a
little bit more equal,
not just across the sexes, but across
different nations and so on,
is probably a worthy goal, for an
equitable species like
us and hopefully can allow us to achieve
our hallmark.
Of being the true moral species that I
know we can be.
And with that I will shut up and just
thank you guys for listening.
But also, end with an advertisement
because, if you want to learn more about
all of these topics, I invite you to take
my class in the spring.
You'll see lots more of bonobos doing
dirty things.
And if you're interested
in studying these topics yourself you can
come join my lab where Christie and others
are focusing on all these issues.
Thank you so much.
[SOUND]

